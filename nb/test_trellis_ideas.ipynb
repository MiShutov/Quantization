{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f40639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msst/Utils/miniconda3/envs/qenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/home/msst/repo/Quantization\")\n",
    "from qlib.quantizers.trellis_quantizer import TrellisQuantizer\n",
    "DEVICE = 'cuda:0'\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827f8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trellis elems: 1024\n",
      "Viterby bs: 1024\n"
     ]
    }
   ],
   "source": [
    "quantizer = TrellisQuantizer(\n",
    "    values_type=\"LUTFREE_FP8\",\n",
    "    T=1024,\n",
    "    V=4,\n",
    "    K=2,\n",
    "    viterbi_batch_size=1024, # rtx5070ti\n",
    "    # viterbi_batch_size=512, # rtx3060\n",
    "    use_kernel=False\n",
    ").to(DEVICE)\n",
    "\n",
    "print(\"Trellis elems:\", quantizer.T)\n",
    "print(\"Viterby bs:\", quantizer.viterbi_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f34b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QTIP MSE tensor(0.0746, device='cuda:0')\n",
      "NEW MSE tensor(0.0755, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# MSE + warmup\n",
    "x = torch.randn(2048, 2048).to(DEVICE)\n",
    "quantizer.weight_shape = x.shape\n",
    "\n",
    "trellis = quantizer.quantize(x)\n",
    "x_q1 = quantizer.dequantize(trellis)\n",
    "print(\"QTIP MSE\", ((x_q1 - x)**2).mean())\n",
    "\n",
    "trellis = quantizer.quantize(x, fast_tail_bite=True)\n",
    "x_q2 = quantizer.dequantize(trellis)\n",
    "print(\"NEW MSE\", ((x_q2 - x)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4acadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"QTIP speed\")\n",
    "# t0 = time()\n",
    "# for s in 4*[4096,] + 3*[11008,]:\n",
    "#     x = torch.randn(4096, s).cuda()\n",
    "#     quantizer.weight_shape = x.shape\n",
    "#     trellis = quantizer.quantize(x)\n",
    "#     # x_q = quantizer.dequantize(trellis)\n",
    "#     # print(\"QTIP\", s, ((x_q - x)**2).mean())\n",
    "# print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653dacc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW speed\n",
      "54.3755087852478\n"
     ]
    }
   ],
   "source": [
    "print(\"NEW speed\")\n",
    "t0 = time()\n",
    "for s in 4*[4096,] + 3*[11008,]:\n",
    "    x = torch.randn(4096, s).to(DEVICE)\n",
    "    quantizer.weight_shape = x.shape\n",
    "    trellis = quantizer.quantize(x, fast_tail_bite=True)\n",
    "    # x_q = quantizer.dequantize(trellis)\n",
    "    # print(\"NEW\", s, ((x_q - x)**2).mean())\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb09a81",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "\n",
    "# x = torch.randn(2048, 2048).cuda()\n",
    "# # x = torch.randn(quantizer.viterbi_bs, quantizer.T).cuda()\n",
    "# quantizer.weight_shape = x.shape\n",
    "\n",
    "# trellis = quantizer.quantize(x)\n",
    "# x_q1 = quantizer.dequantize(trellis)\n",
    "# print(\"QTIP\", ((x_q1 - x)**2).mean())\n",
    "\n",
    "# print()\n",
    "\n",
    "# trellis = quantizer.quantize(x, fast_tail_bite=True)\n",
    "# x_q2 = quantizer.dequantize(trellis)\n",
    "# # x_q2 = quantizer.quantize(x, fast_tail_bite=True).reshape_as(x)\n",
    "# print(\"NEW\", ((x_q2 - x)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QTIP tensor(0.0746, device='cuda:0')\n",
      "\n",
      "NEW tensor(0.0755, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "x = torch.randn(2048, 2048).cuda()\n",
    "# x = torch.randn(quantizer.viterbi_bs, quantizer.T).cuda()\n",
    "quantizer.weight_shape = x.shape\n",
    "\n",
    "x_q1 = quantizer.quantize(x, return_reco=True)\n",
    "print(\"QTIP\", ((x_q1 - x)**2).mean())\n",
    "\n",
    "print()\n",
    "\n",
    "x_q2 = quantizer.quantize(x, fast_tail_bite=True, return_reco=True)\n",
    "print(\"NEW\", ((x_q2 - x)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad6b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0743, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((x_q1.reshape(-1, quantizer.T)[:, :4] - x.reshape(-1, quantizer.T)[:, :4])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce2d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0487, device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(((x_q2.reshape(-1, quantizer.T)[:, :4] - x.reshape(-1, quantizer.T)[:, :4])**2).mean())\n",
    "print()\n",
    "# ((x_q2[:, :4] - x[:, :4])**2).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf7993",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba8056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0746, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "trellis = quantizer.quantize(x)\n",
    "x_q = quantizer.dequantize(trellis)\n",
    "print(((x_q - x)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b7386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0755, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "trellis = quantizer.quantize(x, fast_tail_bite=True)\n",
    "x_q = quantizer.dequantize(trellis)\n",
    "print(((x_q - x)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef1b679",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f52d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2265, -2.0781, -1.9297, -1.7812, -1.6328, -1.4844, -1.3359, -1.1875,\n",
       "        -1.1133, -1.0391, -0.9648, -0.8906, -0.8164, -0.7422, -0.6680, -0.5937,\n",
       "        -0.5566, -0.5195, -0.4824, -0.4453, -0.4082, -0.3711, -0.3340, -0.2969,\n",
       "        -0.2598, -0.2227, -0.1855, -0.1484, -0.1113, -0.0742, -0.0371,  0.0000,\n",
       "         0.0371,  0.0742,  0.1113,  0.1484,  0.1855,  0.2227,  0.2598,  0.2969,\n",
       "         0.3340,  0.3711,  0.4082,  0.4453,  0.4824,  0.5195,  0.5566,  0.5937,\n",
       "         0.6680,  0.7422,  0.8164,  0.8906,  0.9648,  1.0391,  1.1133,  1.1875,\n",
       "         1.3359,  1.4844,  1.6328,  1.7812,  1.9297,  2.0781,  2.2265],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_lut = quantizer.codebook.get_training_lut().cuda()\n",
    "training_lut.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6837023",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "x = torch.randn(4096, 4096).cuda()\n",
    "quantizer.weight_shape = x.shape\n",
    "training_lut = quantizer.codebook.get_training_lut().to(x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# @torch.compile\n",
    "def update(quantizer, training_lut, cost, orig_seq_part, state_candidates):\n",
    "    B = orig_seq_part.shape[0]  # batch size\n",
    "    R = 2 ** (quantizer.L - quantizer.K * quantizer.V)  # reduced state size\n",
    "    D = 2 ** (quantizer.K * quantizer.V)  # delta size\n",
    "    S = 2 ** quantizer.L  # total states\n",
    "\n",
    "    # Gather candidate costs (B, R, D)\n",
    "    cand_cost = torch.gather(\n",
    "        input=cost.view(B, 1, S).expand(-1, R, -1), \n",
    "        dim=-1, \n",
    "        index=state_candidates.expand(B, R, D)\n",
    "    )\n",
    "\n",
    "    # Find best candidate for each reduced state (B, R)\n",
    "    best = torch.min(cand_cost, dim=-1)\n",
    "\n",
    "    # Calculate state reconstruction error (B, S)\n",
    "    state_err = (training_lut - orig_seq_part.unsqueeze(1)).square().sum(dim=-1)\n",
    "\n",
    "    # Update cost (B, S)\n",
    "    cost = state_err + best.values.view(B, R, 1).expand(-1, -1, D).reshape(B, S)\n",
    "\n",
    "    # Get previous states (B, R)\n",
    "    prev_state = torch.gather(\n",
    "        input=state_candidates.expand(B, R, D), \n",
    "        dim=-1, \n",
    "        index=best.indices.unsqueeze(-1)\n",
    "    )[..., 0]\n",
    "\n",
    "    return prev_state, cost\n",
    "\n",
    "\n",
    "def viterbi(quantizer, training_lut, X):\n",
    "    \"\"\"Optimized Viterbi decoding with time-major storage\"\"\"\n",
    "\n",
    "    # State transition buffers\n",
    "    sumdelta = (torch.arange(2 ** (quantizer.K * quantizer.V), device=X.device) << (quantizer.L - quantizer.K * quantizer.V)).view(1, 1, -1)\n",
    "\n",
    "    # State candidates: maps (reduced_state, delta) -> full_state\n",
    "    # Shape: (1, 2^(L-K*V), 2^(K*V))\n",
    "    state_candidates = (torch.arange(2**quantizer.L, device=X.device).unsqueeze(0) >> (quantizer.K * quantizer.V))[\n",
    "        0, :: 2 ** (quantizer.K * quantizer.V)\n",
    "    ].unsqueeze(-1) + sumdelta\n",
    "\n",
    "    # print(\"state_candidates\")\n",
    "    # print(state_candidates[0, 0], state_candidates[0, 0].shape)\n",
    "    \n",
    "\n",
    "    B = X.shape[0]\n",
    "    T_v = quantizer.T // quantizer.V\n",
    "\n",
    "    # Forward pass\n",
    "    cost = (training_lut - X[:, : quantizer.V].unsqueeze(1)).square().sum(dim=-1)\n",
    "\n",
    "    # print(cost)\n",
    "    # print(cost.shape)\n",
    "    top_k = 1 #32 #64\n",
    "    values, indices = torch.topk(cost, k=top_k, dim=1, largest=False)\n",
    "    # print(\"topk cost:\", values, indices)\n",
    "    first_bytes = indices & 0xFF\n",
    "    # print(\"first_bytes\", first_bytes, first_bytes.shape)\n",
    "    # print(\"unique\", first_bytes.sort(dim=-1))\n",
    "    mode, _ = torch.mode(first_bytes, dim=1, keepdim=True)\n",
    "    # mode = mode.unsqueeze(-1)\n",
    "    cost_mask = (torch.arange(1 << 16, device=cost.device) & 0xFF).expand_as(cost)\n",
    "    cost_mask = (cost_mask != mode.expand_as(cost)).float()\n",
    "    cost_mask[cost_mask != 0] = torch.tensor(torch.inf)\n",
    "    cost = cost + cost_mask\n",
    "    # print(cost)\n",
    "\n",
    "    # Time-major storage for efficient backtrace\n",
    "    from_state = torch.zeros(T_v, B, 2 ** (quantizer.L - quantizer.K * quantizer.V), dtype=torch.long, device=X.device)\n",
    "\n",
    "    for i in range(1, T_v):\n",
    "        obs = X[:, i * quantizer.V : (i + 1) * quantizer.V]\n",
    "        prev_state, cost = quantizer.update(\n",
    "            training_lut.to(torch.float32),\n",
    "            cost.to(torch.float32),\n",
    "            obs.to(torch.float32),\n",
    "            state_candidates,\n",
    "        )\n",
    "        from_state[i] = prev_state\n",
    "\n",
    "    # Backtrace\n",
    "    backtrace_cost_mask = ((torch.arange(1 << 16, device=cost.device) >> 8) & 0xFF).expand_as(cost)\n",
    "    backtrace_cost_mask = (backtrace_cost_mask != mode.expand_as(cost)).float()\n",
    "    backtrace_cost_mask[backtrace_cost_mask != 0] = torch.tensor(torch.inf)\n",
    "    cost = cost + backtrace_cost_mask\n",
    "\n",
    "    final_state = torch.zeros(T_v, B, dtype=quantizer.idx_dtype, device=X.device)\n",
    "    final_state[T_v - 1] = torch.argmin(cost, dim=-1)\n",
    "\n",
    "    for i in range(T_v - 1, 0, -1):\n",
    "        reduced_idx = (final_state[i] >> (quantizer.K * quantizer.V)).long().unsqueeze(1)\n",
    "        final_state[i - 1] = torch.gather(from_state[i], 1, reduced_idx).squeeze(1)\n",
    "\n",
    "    return final_state.transpose(0, 1)  # Return as (B, T_v)\n",
    "\n",
    "\n",
    "def quantize_seq(quantizer, training_lut, X, **kwargs):\n",
    "    \"\"\"Quantize sequence with batch processing\"\"\"\n",
    "    n_seq, T = X.shape\n",
    "    batch_padding_len = math.ceil(n_seq / quantizer.viterbi_bs) * quantizer.viterbi_bs - n_seq\n",
    "    X = torch.nn.functional.pad(X.T, (0, batch_padding_len)).T\n",
    "\n",
    "    n_seq_padded = X.shape[0]\n",
    "    X = X.reshape(n_seq_padded // quantizer.viterbi_bs, quantizer.viterbi_bs, T).contiguous()\n",
    "\n",
    "    Qidxs = torch.zeros(\n",
    "        n_seq_padded // quantizer.viterbi_bs, quantizer.viterbi_bs, T // quantizer.V, dtype=quantizer.idx_dtype, device=X.device\n",
    "    )\n",
    "    for i in range(len(X)):\n",
    "        Qidxs[i] = viterbi(quantizer, training_lut, X[i])\n",
    "    Qidxs = Qidxs.reshape(n_seq_padded, T // quantizer.V)[:n_seq]\n",
    "    return Qidxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a320c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0795, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = quantize_seq(quantizer, training_lut, x.reshape(-1, quantizer.T))\n",
    "x_q = training_lut[state.int().to(training_lut.device)].to(state.device).reshape_as(x)\n",
    "((x_q - x)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4bfd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.tensor(15 << 8).to(torch.uint16).unsqueeze(0)\n",
    "# x.view(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e419cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in 4*[4096,] + 3*[11008,]:\n",
    "#     x = torch.randn(4096, s).cuda()\n",
    "#     quantizer.weight_shape = x.shape\n",
    "#     print(s)\n",
    "#     x_q = quantizer.quantize(x, return_reco=False)#.reshape_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8dd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((x_q - x)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a417195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
