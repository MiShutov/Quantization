{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f40639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msst/Utils/miniconda3/envs/qenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/home/msst/repo/Quantization\")\n",
    "from qlib.quantizers.trellis_quantizer import TrellisQuantizer\n",
    "DEVICE = 'cuda:0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827f8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = TrellisQuantizer(\n",
    "    values_type=\"LUTFREE_FP8\",\n",
    "    T=256,\n",
    "    V=4,\n",
    "    K=2,\n",
    "    viterbi_batch_size=1024,\n",
    "    use_kernel=False\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d18b14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0746, device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2048, 2048).cuda()\n",
    "quantizer.weight_shape = x.shape\n",
    "x_q = quantizer.quantize(x, return_reco=True).reshape_as(x)\n",
    "((x_q - x)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef1b679",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f52d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1717, -1.8615, -1.5512, -1.2410, -1.0858, -0.9307, -0.7756, -0.6205,\n",
       "        -0.5429, -0.4654, -0.3878, -0.3102, -0.2327, -0.1551, -0.0776,  0.0000,\n",
       "         0.0776,  0.1551,  0.2327,  0.3102,  0.3878,  0.4654,  0.5429,  0.6205,\n",
       "         0.7756,  0.9307,  1.0858,  1.2410,  1.5512,  1.8615,  2.1717],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_lut = quantizer.codebook.get_training_lut().to(x.device)\n",
    "training_lut.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffda0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6837023",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4096, 4096).cuda()\n",
    "quantizer.weight_shape = x.shape\n",
    "training_lut = quantizer.codebook.get_training_lut().to(x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "@torch.compile\n",
    "def update(quantizer, training_lut, cost, orig_seq_part, state_candidates):\n",
    "    B = orig_seq_part.shape[0]  # batch size\n",
    "    R = 2 ** (quantizer.L - quantizer.K * quantizer.V)  # reduced state size\n",
    "    D = 2 ** (quantizer.K * quantizer.V)  # delta size\n",
    "    S = 2 ** quantizer.L  # total states\n",
    "\n",
    "    # Gather candidate costs (B, R, D)\n",
    "    cand_cost = torch.gather(\n",
    "        input=cost.view(B, 1, S).expand(-1, R, -1), \n",
    "        dim=-1, \n",
    "        index=state_candidates.expand(B, R, D)\n",
    "    )\n",
    "\n",
    "    # Find best candidate for each reduced state (B, R)\n",
    "    best = torch.min(cand_cost, dim=-1)\n",
    "\n",
    "    # Calculate state reconstruction error (B, S)\n",
    "    state_err = (training_lut - orig_seq_part.unsqueeze(1)).square().sum(dim=-1)\n",
    "\n",
    "    # Update cost (B, S)\n",
    "    cost = state_err + best.values.view(B, R, 1).expand(-1, -1, D).reshape(B, S)\n",
    "\n",
    "    # Get previous states (B, R)\n",
    "    prev_state = torch.gather(\n",
    "        input=state_candidates.expand(B, R, D), \n",
    "        dim=-1, \n",
    "        index=best.indices.unsqueeze(-1)\n",
    "    )[..., 0]\n",
    "\n",
    "    return prev_state, cost\n",
    "\n",
    "def viterbi(quantizer, training_lut, X):\n",
    "    \"\"\"Optimized Viterbi decoding with time-major storage\"\"\"\n",
    "\n",
    "    # State transition buffers\n",
    "    sumdelta = (torch.arange(2 ** (quantizer.K * quantizer.V), device=X.device) << (quantizer.L - quantizer.K * quantizer.V)).view(1, 1, -1)\n",
    "\n",
    "    # State candidates: maps (reduced_state, delta) -> full_state\n",
    "    # Shape: (1, 2^(L-K*V), 2^(K*V))\n",
    "    state_candidates = (torch.arange(2**quantizer.L, device=X.device).unsqueeze(0) >> (quantizer.K * quantizer.V))[\n",
    "        0, :: 2 ** (quantizer.K * quantizer.V)\n",
    "    ].unsqueeze(-1) + sumdelta\n",
    "\n",
    "    B = X.shape[0]\n",
    "    T_v = quantizer.T // quantizer.V\n",
    "\n",
    "    # Forward pass\n",
    "    cost = (training_lut - X[:, : quantizer.V].unsqueeze(1)).square().sum(dim=-1)\n",
    "\n",
    "    # Time-major storage for efficient backtrace\n",
    "    from_state = torch.zeros(T_v, B, 2 ** (quantizer.L - quantizer.K * quantizer.V), dtype=torch.long, device=X.device)\n",
    "\n",
    "    for i in range(1, T_v):\n",
    "        obs = X[:, i * quantizer.V : (i + 1) * quantizer.V]\n",
    "        prev_state, cost = quantizer.update(\n",
    "            training_lut.to(torch.float32),\n",
    "            cost.to(torch.float32),\n",
    "            obs.to(torch.float32),\n",
    "            state_candidates,\n",
    "        )\n",
    "        from_state[i] = prev_state\n",
    "\n",
    "    # Backtrace\n",
    "    final_state = torch.zeros(T_v, B, dtype=quantizer.idx_dtype, device=X.device)\n",
    "    final_state[T_v - 1] = torch.argmin(cost, dim=-1)\n",
    "\n",
    "    for i in range(T_v - 1, 0, -1):\n",
    "        reduced_idx = (final_state[i] >> (quantizer.K * quantizer.V)).long().unsqueeze(1)\n",
    "        final_state[i - 1] = torch.gather(from_state[i], 1, reduced_idx).squeeze(1)\n",
    "\n",
    "    return final_state.transpose(0, 1)  # Return as (B, T_v)\n",
    "\n",
    "def quantize_seq(quantizer, training_lut, X, **kwargs):\n",
    "    \"\"\"Quantize sequence with batch processing\"\"\"\n",
    "    n_seq, T = X.shape\n",
    "    batch_padding_len = math.ceil(n_seq / quantizer.viterbi_bs) * quantizer.viterbi_bs - n_seq\n",
    "    X = torch.nn.functional.pad(X.T, (0, batch_padding_len)).T\n",
    "\n",
    "    n_seq_padded = X.shape[0]\n",
    "    X = X.reshape(n_seq_padded // quantizer.viterbi_bs, quantizer.viterbi_bs, T).contiguous()\n",
    "\n",
    "    Qidxs = torch.zeros(\n",
    "        n_seq_padded // quantizer.viterbi_bs, quantizer.viterbi_bs, T // quantizer.V, dtype=quantizer.idx_dtype, device=X.device\n",
    "    )\n",
    "    for i in range(len(X)):\n",
    "        Qidxs[i] = quantizer.viterbi(training_lut, X[i])\n",
    "    Qidxs = Qidxs.reshape(n_seq_padded, T // quantizer.V)[:n_seq]\n",
    "    return Qidxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a320c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0734, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = quantize_seq(quantizer, training_lut, x.reshape(-1, quantizer.T))\n",
    "x_q = training_lut[state.int().to(training_lut.device)].to(state.device).reshape_as(x)\n",
    "((x_q - x)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e419cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in 4*[4096,] + 3*[11008,]:\n",
    "#     x = torch.randn(4096, s).cuda()\n",
    "#     quantizer.weight_shape = x.shape\n",
    "#     print(s)\n",
    "#     x_q = quantizer.quantize(x, return_reco=False)#.reshape_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8dd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((x_q - x)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a417195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
