{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/msst/repo/Quantization\")\n",
    "import qlib\n",
    "\n",
    "model_name='Llama2-7b-hf'\n",
    "#model_name='Llama-3.2-1B'\n",
    "\n",
    "DTYPE = torch.float16\n",
    "model = qlib.load_custom_llama(\n",
    "\tmodel_name=model_name, \n",
    "\tdevice_map='cpu', \n",
    "\ttorch_dtype=DTYPE, \n",
    "\t#use_flash_attn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [00:05<00:00, 117.00it/s]\n",
      "100%|██████████| 688/688 [00:06<00:00, 113.79it/s]\n",
      "100%|██████████| 688/688 [00:05<00:00, 119.23it/s]\n",
      "100%|██████████| 688/688 [00:05<00:00, 115.38it/s]\n",
      "100%|██████████| 256/256 [00:02<00:00, 119.52it/s]\n",
      "100%|██████████| 256/256 [00:02<00:00, 117.00it/s]\n",
      "100%|██████████| 256/256 [00:02<00:00, 119.27it/s]\n",
      "100%|██████████| 256/256 [00:02<00:00, 112.31it/s]\n",
      "100%|██████████| 256/256 [00:02<00:00, 117.19it/s]\n",
      "100%|██████████| 256/256 [00:02<00:00, 112.89it/s]\n",
      " 56%|█████▋    | 144/256 [00:01<00:00, 115.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m\n\u001b[1;32m      8\u001b[0m viterby_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3072\u001b[39m\u001b[38;5;66;03m#1024\u001b[39;00m\n\u001b[1;32m     11\u001b[0m wrapper \u001b[38;5;241m=\u001b[39m qlib\u001b[38;5;241m.\u001b[39mHomeQuantWrapper(\n\u001b[1;32m     12\u001b[0m     wrap_rule\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     13\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear : qlib\u001b[38;5;241m.\u001b[39mTrellisLinear(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     }\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 28\u001b[0m \u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m model_checkpoints_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/msst/repo/Quantization/logs/checkpoints_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/trellis\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     31\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(model_checkpoints_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/wrappers/homequant_wrapper.py:25\u001b[0m, in \u001b[0;36mHomeQuantWrapper.wrap_model\u001b[0;34m(self, current_module, prefix)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28msetattr\u001b[39m(current_module, module_name, new_module)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/wrappers/homequant_wrapper.py:25\u001b[0m, in \u001b[0;36mHomeQuantWrapper.wrap_model\u001b[0;34m(self, current_module, prefix)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28msetattr\u001b[39m(current_module, module_name, new_module)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: HomeQuantWrapper.wrap_model at line 25 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/wrappers/homequant_wrapper.py:25\u001b[0m, in \u001b[0;36mHomeQuantWrapper.wrap_model\u001b[0;34m(self, current_module, prefix)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28msetattr\u001b[39m(current_module, module_name, new_module)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/wrappers/homequant_wrapper.py:22\u001b[0m, in \u001b[0;36mHomeQuantWrapper.wrap_model\u001b[0;34m(self, current_module, prefix)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_rule[module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m             new_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_rule\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28msetattr\u001b[39m(current_module, module_name, new_module)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/qlayers/VQ2SQ.py:489\u001b[0m, in \u001b[0;36mTrellisLinear.wrap_module\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# Quantize\u001b[39;00m\n\u001b[1;32m    488\u001b[0m w \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_device)\n\u001b[0;32m--> 489\u001b[0m _, states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodebook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompressed_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebook\u001b[38;5;241m.\u001b[39mpack_trellis(states)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m deepcopy(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mto(orig_device)\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/qlayers/VQ2SQ.py:366\u001b[0m, in \u001b[0;36mbitshift_codebook.quantize\u001b[0;34m(self, X, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m T \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    365\u001b[0m roll_X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mroll(X, T \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 366\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroll_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m overlap \u001b[38;5;241m=\u001b[39m state[T \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV)] \u001b[38;5;241m>>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV\n\u001b[1;32m    368\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantize_seq(X, overlap\u001b[38;5;241m=\u001b[39moverlap, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/qlayers/VQ2SQ.py:358\u001b[0m, in \u001b[0;36mbitshift_codebook.quantize_seq\u001b[0;34m(self, X, overlap, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))):\n\u001b[1;32m    357\u001b[0m     b_overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m overlap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m overlap[i]\n\u001b[0;32m--> 358\u001b[0m     Qidxs[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviterbi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_overlap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m Qidxs \u001b[38;5;241m=\u001b[39m Qidxs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(T \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV, N)[:, :NO]\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Qidxs\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/qlayers/VQ2SQ.py:316\u001b[0m, in \u001b[0;36mbitshift_codebook.viterbi\u001b[0;34m(self, X, overlap)\u001b[0m\n\u001b[1;32m    309\u001b[0m from_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(T \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV,\n\u001b[1;32m    310\u001b[0m                          B,\n\u001b[1;32m    311\u001b[0m                          \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV),\n\u001b[1;32m    312\u001b[0m                          dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    313\u001b[0m                          device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, T \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV):\n\u001b[0;32m--> 316\u001b[0m     from_state[i], cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overlap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(B, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL, device\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfakeinf\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:465\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m saved_dynamic_layer_stack_depth \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    461\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mget_dynamic_layer_stack_depth()\n\u001b[1;32m    462\u001b[0m )\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[1;32m    469\u001b[0m         saved_dynamic_layer_stack_depth\n\u001b[1;32m    470\u001b[0m     )\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/qlayers/VQ2SQ.py:279\u001b[0m, in \u001b[0;36mbitshift_codebook.update\u001b[0;34m(self, cost, thing)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrecons\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoded, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlut[:,\n\u001b[1;32m    277\u001b[0m                     encoded\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlut\u001b[38;5;241m.\u001b[39mdevice)]\u001b[38;5;241m.\u001b[39mto(encoded\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mcompile\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, cost, thing):\n\u001b[1;32m    281\u001b[0m     state_err \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecons_state \u001b[38;5;241m-\u001b[39m\n\u001b[1;32m    282\u001b[0m                  thing\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msquare()\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    283\u001b[0m     cand_cost \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    284\u001b[0m         cost\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_cand\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_cand\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;28mlen\u001b[39m(cost), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV)))\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:634\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m     \u001b[43m_maybe_set_eval_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprior\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "T=256 \n",
    "L=11\n",
    "V=2\n",
    "K=2\n",
    "tlut_bits=10\n",
    "decode_mode='quantlut_sym_2d'\n",
    "incoh_proc_mode='qtip'\n",
    "viterby_batch_size=3072#1024\n",
    "\n",
    "\n",
    "wrapper = qlib.HomeQuantWrapper(\n",
    "    wrap_rule={\n",
    "        torch.nn.Linear : qlib.TrellisLinear(\n",
    "\t\t\tT=T, \n",
    "            L=L, \n",
    "            V=V, \n",
    "            K=K,\n",
    "\t\t\ttlut_bits=tlut_bits,\n",
    "            decode_mode=decode_mode, \n",
    "            incoh_proc_mode=incoh_proc_mode, \n",
    "            viterby_batch_size=viterby_batch_size\n",
    "\t\t),\n",
    "    },\n",
    "    exceptions = {\n",
    "        'lm_head' : None,\n",
    "    }\n",
    ")\n",
    "wrapper.wrap_model(model)\n",
    "\n",
    "model_checkpoints_path = f'/home/msst/repo/Quantization/logs/checkpoints_{model_name}/trellis'\n",
    "os.makedirs(model_checkpoints_path, exist_ok=True)\n",
    "torch.save(model, os.path.join(model_checkpoints_path, f'T{T}_L{L}_V{V}_K{K}_{decode_mode}_{incoh_proc_mode}.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
