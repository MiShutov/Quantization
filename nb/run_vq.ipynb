{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nip\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/msst/repo/Quantization\")\n",
    "import qlib\n",
    "\n",
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_201750/3003855609.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  qmodel = torch.load('/home/msst/repo/Quantization/logs/checkpoints_Llama2-7b-hf/SymQuant/cb4096_vecdim8_weightPERCOORD_scaleOUTL2_distMSE_blocksizeNone_iters10_abscoords.pth')\n"
     ]
    }
   ],
   "source": [
    "#qmodel = torch.load('/home/msst/repo/Quantization/logs/checkpoints_Llama2-7b-hf/kmeans_noscale_percoord.pth')\n",
    "#qmodel = torch.load('/home/msst/repo/Quantization/logs/checkpoints_Llama2-7b-hf/kmeans_scaleL2_percoord.pth')\n",
    "\n",
    "qmodel = torch.load('/home/msst/repo/Quantization/logs/checkpoints_Llama2-7b-hf/SymQuant/cb4096_vecdim8_weightPERCOORD_scaleOUTL2_distMSE_blocksizeNone_iters10_abscoords.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4/83 [00:15<05:11,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.247810134281186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 5/83 [00:22<05:51,  4.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m qlib\u001b[38;5;241m.\u001b[39mQATDataset(\n\u001b[1;32m      2\u001b[0m     config\u001b[38;5;241m=\u001b[39mnip\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/msst/repo/Quantization/configs/data/wikitext_test_seqlen4096.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      3\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mqlib\u001b[38;5;241m.\u001b[39mload_tokenizer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLlama2-7b-hf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m )\u001b[38;5;241m.\u001b[39mget_dataloader()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16):\n\u001b[0;32m----> 8\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mqlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/utils/evaluation.py:69\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, print_times)\u001b[0m\n\u001b[1;32m     67\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     68\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 69\u001b[0m neg_log_likelihood \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     71\u001b[0m loss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m n_processed_samples \u001b[38;5;241m/\u001b[39m (n_processed_samples \u001b[38;5;241m+\u001b[39m n_samples)\n\u001b[1;32m     72\u001b[0m n_processed_samples \u001b[38;5;241m=\u001b[39m n_processed_samples \u001b[38;5;241m+\u001b[39m n_samples\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:834\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    833\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 834\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:592\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    581\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    582\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m         position_embeddings,\n\u001b[1;32m    590\u001b[0m     )\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:332\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:300\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m attention_interface(\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    290\u001b[0m     query_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    297\u001b[0m )\n\u001b[1;32m    299\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m--> 300\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/qlayers/symquant_layers.py:151\u001b[0m, in \u001b[0;36mSymHQLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# (self.trainable == True)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m         training_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_mode\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/qlayers/symquant_layers.py:138\u001b[0m, in \u001b[0;36mSymHQLinear._inference_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_inference_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigns\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 138\u001b[0m         w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43munpack_bool_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_shape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatent_weight\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    140\u001b[0m         w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msign(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/Quantization/qlib/utils/pack_effective.py:42\u001b[0m, in \u001b[0;36munpack_bool_tensor\u001b[0;34m(packed, original_shape)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03mUnpacks a uint8 tensor into a boolean tensor of the original shape.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    x (torch.Tensor): Unpacked boolean tensor.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Unpack bytes to booleans\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m bit_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpacked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m x_padded \u001b[38;5;241m=\u001b[39m (packed\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mbitwise_and(bit_weights)\u001b[38;5;241m.\u001b[39mne(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Remove padding and reshape to original shape\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloader = qlib.QATDataset(\n",
    "    config=nip.load('/home/msst/repo/Quantization/configs/data/wikitext_test_seqlen4096.yaml'),\n",
    "    tokenizer=qlib.load_tokenizer('Llama2-7b-hf')\n",
    ").get_dataloader()\n",
    "\n",
    "\n",
    "with torch.amp.autocast('cuda', dtype=torch.float16):\n",
    "    res = qlib.evaluate(qmodel.to(DEVICE), dataloader, print_times=25)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_new_blocks = '/home/msst/repo/Quantization/logs/llama2-7b/symquant/llama2_symquant_cb256_vecdim8_C5e-5_L5e-5_lossL1_reassfrac1.0_3layershighbit/per_block_q_trained'\n",
    "#path_to_new_blocks = '/home/msst/repo/Quantization/logs/llama2-7b/symquant/llama2_symquant_cb256_vecdim8_C1e4_lossL2/per_block_q_trained'\n",
    "block_names = sorted(os.listdir(path_to_new_blocks), key=lambda x: int(x.split('.')[-1]) if x.startswith(\"model.layers\") else -1)\n",
    "\n",
    "\n",
    "for block_name in block_names:\n",
    "    new_block = torch.load(os.path.join(path_to_new_blocks, block_name), weights_only=False)\n",
    "    curr_block = qmodel.get_submodule(block_name)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        curr_block.load_state_dict(new_block.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4/83 [00:15<05:10,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.779945339620922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7/83 [00:27<04:58,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9054375411395315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 10/83 [00:39<04:47,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.507165278640814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 13/83 [00:50<04:35,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.4600634749214665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 16/83 [01:02<04:23,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.739269670732486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 19/83 [01:14<04:11,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.632139277562521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 22/83 [01:26<03:59,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.333718325184093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 25/83 [01:37<03:47,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.265101692126863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 28/83 [01:49<03:35,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.431769656583945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 31/83 [02:01<03:23,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.32203109233849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 34/83 [02:12<03:11,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.122616858236108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 37/83 [02:24<02:59,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.232283657377245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 40/83 [02:36<02:48,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.108339437238607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 43/83 [02:47<02:36,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.115868156642258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 46/83 [02:59<02:24,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.117651459550004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 49/83 [03:11<02:13,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.086423604783443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 52/83 [03:23<02:01,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.10060706562432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 55/83 [03:34<01:49,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2974640224620195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 58/83 [03:46<01:37,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.313714900216302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 61/83 [03:58<01:26,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.347388542292815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 64/83 [04:09<01:14,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.297329185254992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 67/83 [04:21<01:02,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.315830345145776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 70/83 [04:33<00:50,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.286164617914699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 73/83 [04:44<00:39,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.257146888951413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 76/83 [04:56<00:27,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.223401156490881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 79/83 [05:08<00:15,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.176955465175023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 82/83 [05:19<00:03,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.21580253478738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [05:23<00:00,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.234027145707025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = qlib.QATDataset(\n",
    "    config=nip.load('/home/msst/repo/Quantization/configs/data/wikitext_test_seqlen4096.yaml'),\n",
    "    tokenizer=qlib.load_tokenizer('Llama2-7b-hf')\n",
    ").get_dataloader()\n",
    "\n",
    "with torch.amp.autocast('cuda', dtype=torch.float16):\n",
    "    res = qlib.evaluate(qmodel.to(DEVICE), dataloader, print_times=25)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(qmodel.cpu(), '/home/msst/repo/Quantization/logs/checkpoints_Llama2-7b-hf/SymQuant/cb256_vecdim8_weightPERCOORD_scaleOUTL2_distMSE_blocksizeNone_iters25_abscoords_ptq.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7862694300518134\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "self_attn_matrix_params = 4096 * 4096\n",
    "mlp_matrix_params = 11008 * 4096\n",
    "total_params = 4 * self_attn_matrix_params + 3 * mlp_matrix_params\n",
    "\n",
    "vecdim = 16\n",
    "cb_size = 2**12\n",
    "\n",
    "cb_bits = 16 * vecdim * cb_size\n",
    "\n",
    "q_self_attn_matrix_bits = self_attn_matrix_params // vecdim * (vecdim + math.log2(cb_size)) + cb_bits\n",
    "q_mlp_matrix_bit = mlp_matrix_params // vecdim * (vecdim + math.log2(cb_size)) + cb_bits\n",
    "\n",
    "total_bits = 4 * q_self_attn_matrix_bits + 3 * q_mlp_matrix_bit\n",
    "\n",
    "print(total_bits / total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lm_head.weight': tensor([[-0.0039,  0.0032, -0.0071,  ...,  0.0053, -0.0082,  0.0070],\n",
       "         [-0.0315,  0.0466, -0.0023,  ..., -0.0211,  0.0173,  0.0334],\n",
       "         [-0.0125,  0.0036,  0.0195,  ..., -0.0271,  0.0143, -0.0082],\n",
       "         ...,\n",
       "         [-0.0281, -0.0195, -0.0024,  ...,  0.0123, -0.0117, -0.0237],\n",
       "         [ 0.0229,  0.0255,  0.0315,  ...,  0.0067, -0.0092, -0.0058],\n",
       "         [ 0.0080, -0.0088,  0.0063,  ..., -0.0293, -0.0200,  0.0337]],\n",
       "        dtype=torch.float16),\n",
       " 'model.embed_tokens.weight': tensor([[ 1.2517e-06, -1.7881e-06, -4.3511e-06,  ...,  8.9407e-07,\n",
       "          -6.5565e-06,  8.9407e-07],\n",
       "         [ 1.8616e-03, -3.3722e-03,  3.9864e-04,  ..., -8.3008e-03,\n",
       "           2.5787e-03, -3.9368e-03],\n",
       "         [ 1.0986e-02,  9.8877e-03, -5.0964e-03,  ...,  2.5177e-03,\n",
       "           7.7057e-04, -5.0049e-03],\n",
       "         ...,\n",
       "         [-1.3977e-02, -2.7313e-03, -1.9897e-02,  ..., -1.0437e-02,\n",
       "           9.5825e-03, -1.8005e-03],\n",
       "         [-1.0742e-02,  9.3384e-03,  1.2939e-02,  ..., -3.3203e-02,\n",
       "          -1.6357e-02,  3.3875e-03],\n",
       "         [-8.3008e-03, -4.0588e-03, -1.1063e-03,  ...,  3.4790e-03,\n",
       "          -1.2939e-02,  3.1948e-05]], dtype=torch.float16),\n",
       " 'model.layers.0.input_layernorm.weight': tensor([0.0305, 0.0142, 0.0017,  ..., 0.0116, 0.0116, 0.0058],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.mlp.down_proj.centroids.weight': tensor([[-0.0174,  0.0036, -0.0073,  ...,  0.0029,  0.0208,  0.0055]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.mlp.down_proj.indices': tensor([[[  351616313,  1609234071,  -164566181,  ...,  -981285049,\n",
       "            -147417236,  1942455111],\n",
       "          [ 1975197697,   890612634,   657366362,  ...,   135503917,\n",
       "            -295398040, -2023530853],\n",
       "          [-1485206355, -1835929578,   350147107,  ...,  1411961190,\n",
       "             159684097,  1185741087],\n",
       "          ...,\n",
       "          [-1396984964,   589084839,  1214845687,  ...,  -997635105,\n",
       "           -1445930767,   580862325],\n",
       "          [ 1801095313, -1988887481,   177856814,  ...,  -878003280,\n",
       "             464637812, -1488957534],\n",
       "          [  721541815,  1886655928, -1858069150,  ..., -1003716098,\n",
       "            -600445415,  -227532813]]], dtype=torch.int32),\n",
       " 'model.layers.0.mlp.down_proj.perm': tensor([9243, 7377, 5389,  ..., 7208, 6670, 8812], dtype=torch.int16),\n",
       " 'model.layers.0.mlp.down_proj.weight_bias': tensor([ 3.1257e-04, -3.2163e-04,  2.1088e-04,  ..., -2.7323e-04,\n",
       "         -9.4652e-05,  6.5684e-05], dtype=torch.float16),\n",
       " 'model.layers.0.mlp.down_proj.weight_scale': tensor([1.0820, 1.0771, 1.0850,  ..., 1.0762, 1.0713, 1.0908],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.mlp.gate_proj.centroids.weight': tensor([[ 0.0041, -0.0296,  0.0154,  ...,  0.0115,  0.0149,  0.0045]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.mlp.gate_proj.indices': tensor([[[ -518045470,   544449273, -1884030179,  ..., -1410157921,\n",
       "            1532833490,  1512998336],\n",
       "          [-1970110040,   394237953,  1526083712,  ...,  -828240668,\n",
       "             721482948,    81464515],\n",
       "          [-1377362511,   197282548,   710539805,  ...,  -897994059,\n",
       "            -978204575,   676389900],\n",
       "          ...,\n",
       "          [  348304779,  -428536150,  -168248192,  ..., -1608523337,\n",
       "             239856539,  -943482577],\n",
       "          [  717890354,  1239921542, -1700676493,  ...,   457284770,\n",
       "           -1722120576,   -85228810],\n",
       "          [  312202008, -1141677786,   673856015,  ...,  -717196855,\n",
       "            1565470040,  1719089453]]], dtype=torch.int32),\n",
       " 'model.layers.0.mlp.gate_proj.perm': tensor([1512, 2944, 1415,  ..., 2522, 3946, 1793], dtype=torch.int16),\n",
       " 'model.layers.0.mlp.gate_proj.weight_bias': tensor([-0.0002,  0.0005, -0.0011,  ..., -0.0005, -0.0004, -0.0013],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.mlp.gate_proj.weight_scale': tensor([1.6787, 1.7383, 1.7090,  ..., 1.7266, 1.7061, 1.7061],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.mlp.up_proj.centroids.weight': tensor([[ 0.0162, -0.0077,  0.0059,  ..., -0.0063, -0.0012,  0.0025]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.mlp.up_proj.indices': tensor([[[-1549077209, -1831117399, -2043515259,  ...,  1297589322,\n",
       "            1991132712, -1039544846],\n",
       "          [  427623096,  1602863088,  -153156168,  ..., -1043180451,\n",
       "              30743171,  1259676606],\n",
       "          [-1623807320, -1964849011,   227202680,  ..., -1566055831,\n",
       "           -1318578066,  -473006707],\n",
       "          ...,\n",
       "          [ -333240399,  1313835857,  1814170559,  ...,  1315318967,\n",
       "            2052703055,   912623031],\n",
       "          [  753100419,  1299629700,  1671636884,  ...,  2105826831,\n",
       "             225755470,  1922389409],\n",
       "          [-1427004017,  1799708981,  -140349331,  ...,   -92672613,\n",
       "            1240365720,   287994859]]], dtype=torch.int32),\n",
       " 'model.layers.0.mlp.up_proj.perm': tensor([1512, 2944, 1415,  ..., 2522, 3946, 1793], dtype=torch.int16),\n",
       " 'model.layers.0.mlp.up_proj.weight_bias': tensor([ 3.6597e-04, -3.6049e-04,  3.0935e-05,  ..., -2.4796e-04,\n",
       "         -3.9577e-04, -2.0194e-04], dtype=torch.float16),\n",
       " 'model.layers.0.mlp.up_proj.weight_scale': tensor([1.6846, 1.6572, 1.7002,  ..., 1.7129, 1.7080, 1.6826],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.post_attention_layernorm.weight': tensor([0.0513, 0.0550, 0.0504,  ..., 0.0560, 0.0553, 0.0514],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.k_proj.centroids.weight': tensor([[-0.0185,  0.0398, -0.0080,  ...,  0.0054,  0.0260, -0.0112]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.k_proj.indices': tensor([[[ -363246045,   109558980,   637223389,  ...,  -833705108,\n",
       "           -1242388368, -1604595979],\n",
       "          [  -71342613, -1434001210,    58592402,  ...,  -561607222,\n",
       "            1542130540,  1680827347],\n",
       "          [   10323361,  1093163639,  1151629039,  ...,  1434417375,\n",
       "            1439490829,  -103857827],\n",
       "          ...,\n",
       "          [  512015718,  -897151592,  2041281913,  ..., -2011252666,\n",
       "            -982265127,  1919144889],\n",
       "          [ -933888604, -1332683752, -1802437733,  ..., -1026566246,\n",
       "              92627215,  -549803365],\n",
       "          [ -223395047,   -35475639, -1602802171,  ...,   270273258,\n",
       "            1902643187, -1595858410]]], dtype=torch.int32),\n",
       " 'model.layers.0.self_attn.k_proj.perm': tensor([3964, 1411,   22,  ...,  572, 2080,  705], dtype=torch.int16),\n",
       " 'model.layers.0.self_attn.k_proj.weight_bias': tensor([-3.0398e-04, -1.0672e-03,  8.7798e-05,  ...,  1.1331e-04,\n",
       "          7.0620e-04,  2.5213e-05], dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.k_proj.weight_scale': tensor([1.1758, 0.8262, 0.3096,  ..., 0.5889, 0.6553, 0.5815],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.o_proj.centroids.weight': tensor([[ 0.0171, -0.0023, -0.0015,  ...,  0.0043,  0.0098, -0.0138]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.o_proj.indices': tensor([[[ 1283947161,  -974431915,   -35463813,  ...,  1745162111,\n",
       "             622336920,   618960741],\n",
       "          [-1445604341,  1366027881,   716265970,  ...,  1089118166,\n",
       "            1478533795,    91531815],\n",
       "          [-1276457137,  2083494349,  1323775234,  ...,   214572855,\n",
       "           -1348148918, -1382581916],\n",
       "          ...,\n",
       "          [-1387650451,  2043922304,  -397765811,  ...,   166679504,\n",
       "            1217426255,   700153956],\n",
       "          [-1772713988, -1192835720,  -870000888,  ..., -1915056413,\n",
       "             940333303,  -139680291],\n",
       "          [ -297623849,  1607804893, -1701412714,  ...,   247154124,\n",
       "           -1283752924,  1126769838]]], dtype=torch.int32),\n",
       " 'model.layers.0.self_attn.o_proj.perm': tensor([2739,  214, 3250,  ..., 4075, 1182, 3562], dtype=torch.int16),\n",
       " 'model.layers.0.self_attn.o_proj.weight_bias': tensor([ 1.5497e-06, -5.9843e-05,  2.2602e-04,  ...,  2.1935e-05,\n",
       "         -4.9472e-06, -1.8144e-04], dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.o_proj.weight_scale': tensor([0.2805, 0.2827, 0.2654,  ..., 0.2625, 0.2678, 0.2649],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.q_proj.centroids.weight': tensor([[ 0.0008,  0.0231, -0.0067,  ...,  0.0143,  0.0101,  0.0073]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.q_proj.indices': tensor([[[-1745875011,   800951779, -1181808184,  ...,  1305813219,\n",
       "            1202086589,  -822410021],\n",
       "          [  954038552,   807132543,  -209669135,  ...,  1329101643,\n",
       "           -1189033440, -1229010497],\n",
       "          [ -995908845,  1193866704,   741379793,  ...,  1668487342,\n",
       "            1046405965, -1573776348],\n",
       "          ...,\n",
       "          [ 1334469596, -1968368171,  -295882453,  ..., -1627300278,\n",
       "             586598229,  1352548451],\n",
       "          [ -636317695,  1456998390,  1572789937,  ...,  1510029799,\n",
       "            -705796873,  -171984449],\n",
       "          [  252337396,   396779319,  1982761677,  ..., -1859990278,\n",
       "           -1525678357, -1579874096]]], dtype=torch.int32),\n",
       " 'model.layers.0.self_attn.q_proj.perm': tensor([3964, 1411,   22,  ...,  572, 2080,  705], dtype=torch.int16),\n",
       " 'model.layers.0.self_attn.q_proj.weight_bias': tensor([ 1.1501e-03,  3.4690e-04,  2.6584e-04,  ...,  4.6349e-04,\n",
       "         -6.3419e-04,  4.8339e-05], dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.q_proj.weight_scale': tensor([0.8848, 0.6528, 0.2561,  ..., 0.5371, 0.5562, 0.4512],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.v_proj.centroids.weight': tensor([[ 0.0003,  0.0026, -0.0036,  ...,  0.0164, -0.0011, -0.0056]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.v_proj.indices': tensor([[[ 1523945622,   776410539,  1761232969,  ...,  1603698569,\n",
       "           -1226641226, -1458479948],\n",
       "          [ -908944879,  1397454784,  1061990800,  ...,   664052509,\n",
       "           -1198055001, -1229067978],\n",
       "          [ 1109971957,  -890980494,  -743735580,  ...,  -589235867,\n",
       "            1144749389,  -788860904],\n",
       "          ...,\n",
       "          [ 1658933959,  1120366614,  2064603241,  ..., -2052356452,\n",
       "           -1673301093,  -764693906],\n",
       "          [  -36207906,   768940408,  -142053788,  ...,  1547964964,\n",
       "             -17082250,  1060228281],\n",
       "          [ 2098268492,  -808939880, -1119339884,  ..., -1769999483,\n",
       "            -742169448,  -284824795]]], dtype=torch.int32),\n",
       " 'model.layers.0.self_attn.v_proj.perm': tensor([3964, 1411,   22,  ...,  572, 2080,  705], dtype=torch.int16),\n",
       " 'model.layers.0.self_attn.v_proj.weight_bias': tensor([-4.9543e-04, -6.0844e-04,  3.2485e-05,  ...,  4.8876e-04,\n",
       "         -8.1968e-04,  1.0004e-03], dtype=torch.float16),\n",
       " 'model.layers.0.self_attn.v_proj.weight_scale': tensor([0.7241, 0.7617, 0.5034,  ..., 0.7656, 0.7676, 0.6851],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.input_layernorm.weight': tensor([0.1132, 0.1096, 0.1001,  ..., 0.0622, 0.0937, 0.0753],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.mlp.down_proj.centroids.weight': tensor([[ 0.0183,  0.0093, -0.0171,  ...,  0.0014,  0.0012,  0.0041]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.mlp.down_proj.indices': tensor([[[ 1319359856, -1346628655,   223995775,  ..., -1788369468,\n",
       "            -682345832, -1836039836],\n",
       "          [ -544424552,  -654337614,   659447257,  ..., -1493881513,\n",
       "             487932514,   630877820],\n",
       "          [  562870475, -2021376811,  1266114157,  ..., -1250501643,\n",
       "            -756337818,  2007571395],\n",
       "          ...,\n",
       "          [  935687536,  -375413470,  -266224987,  ...,  -796177277,\n",
       "             265998629,  1586624463],\n",
       "          [  104711132,   574574148,   333134694,  ..., -1476804940,\n",
       "            1499861401,  -263303355],\n",
       "          [-2098479429,   229127253,   255068870,  ...,   353486334,\n",
       "            1446286275,   797438161]]], dtype=torch.int32),\n",
       " 'model.layers.1.mlp.down_proj.perm': tensor([ 7890, 10411,  1192,  ...,  2831,   299,  2078], dtype=torch.int16),\n",
       " 'model.layers.1.mlp.down_proj.weight_bias': tensor([-1.2159e-04, -3.1829e-05,  1.2106e-04,  ...,  2.9445e-04,\n",
       "         -2.3246e-06,  2.9325e-04], dtype=torch.float16),\n",
       " 'model.layers.1.mlp.down_proj.weight_scale': tensor([1.1074, 1.1074, 1.1250,  ..., 1.1201, 1.1270, 1.1250],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.mlp.gate_proj.centroids.weight': tensor([[-0.0036, -0.0201,  0.0043,  ...,  0.0158,  0.0177, -0.0040]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.mlp.gate_proj.indices': tensor([[[  815686829,   -52325283, -1170274927,  ...,   414628501,\n",
       "            1899337904,  -192652591],\n",
       "          [  534440457,  -592706823,  1202103900,  ...,  1492715429,\n",
       "           -1139171724,  1863189672],\n",
       "          [ -817389543,  -947092633,    49329639,  ...,   590354007,\n",
       "           -1864022504,   467071368],\n",
       "          ...,\n",
       "          [ -491979978,  -737818631, -2077999557,  ...,  -753425272,\n",
       "           -1987902000, -1671992960],\n",
       "          [ 1758486491,  1533457902,  1760928576,  ...,   837119546,\n",
       "            -279941000,  1125897137],\n",
       "          [ -934289816,    65166552,  1339394003,  ...,  -150881750,\n",
       "             887116799,  1259829124]]], dtype=torch.int32),\n",
       " 'model.layers.1.mlp.gate_proj.perm': tensor([2298, 3209, 2158,  ...,  575, 1512, 1793], dtype=torch.int16),\n",
       " 'model.layers.1.mlp.gate_proj.weight_bias': tensor([-1.8902e-03,  3.0327e-03,  1.3180e-03,  ..., -4.2510e-04,\n",
       "         -6.5184e-04,  3.5107e-05], dtype=torch.float16),\n",
       " 'model.layers.1.mlp.gate_proj.weight_scale': tensor([1.9482, 1.9365, 1.8828,  ..., 1.9453, 1.8994, 1.8916],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.mlp.up_proj.centroids.weight': tensor([[ 0.0081, -0.0160,  0.0112,  ..., -0.0084, -0.0118,  0.0154]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.mlp.up_proj.indices': tensor([[[  -93205908,  1207171062,  -710116727,  ...,  1267331531,\n",
       "           -1921254825,  -637040152],\n",
       "          [  205816123,  1246634077, -1537084057,  ...,  1829238592,\n",
       "            -694916137, -2035637479],\n",
       "          [ 1530513913,   969755546,   578209216,  ..., -1625134339,\n",
       "             740800437,   284827650],\n",
       "          ...,\n",
       "          [ 1426071013, -1806390833,  -405182344,  ...,   438351717,\n",
       "           -2034459003,  2022970941],\n",
       "          [-2074621158, -1974590407, -1522662479,  ..., -1137206017,\n",
       "             557225000,  1106400098],\n",
       "          [-1060531191,  -998695399, -1399947924,  ..., -1128312340,\n",
       "            1736677901,   291232382]]], dtype=torch.int32),\n",
       " 'model.layers.1.mlp.up_proj.perm': tensor([2298, 3209, 2158,  ...,  575, 1512, 1793], dtype=torch.int16),\n",
       " 'model.layers.1.mlp.up_proj.weight_bias': tensor([-2.5153e-04, -4.8923e-04, -9.0241e-05,  ..., -5.2738e-04,\n",
       "          4.3488e-04, -9.8419e-04], dtype=torch.float16),\n",
       " 'model.layers.1.mlp.up_proj.weight_scale': tensor([1.7607, 1.8057, 1.8271,  ..., 1.8018, 1.8066, 1.8203],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.post_attention_layernorm.weight': tensor([0.0984, 0.1013, 0.0977,  ..., 0.1087, 0.0997, 0.1021],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.k_proj.centroids.weight': tensor([[ 0.0070,  0.0523, -0.0783,  ..., -0.0165, -0.0160, -0.0004]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.k_proj.indices': tensor([[[ 1135436487, -2087768976, -2099713665,  ...,   790615606,\n",
       "            -357582617,  1417430453],\n",
       "          [   39761034,  1507937420, -1149479970,  ...,    46745390,\n",
       "             944039441,  -933820449],\n",
       "          [ -619662016,  1332564996,   542748034,  ...,  1476441307,\n",
       "             968640852,  -264432973],\n",
       "          ...,\n",
       "          [-1354358855,   277293613,  1262793798,  ..., -1148074319,\n",
       "            1906811126, -2120077784],\n",
       "          [ 1186085284,   928289246,  -462534990,  ...,  2137086755,\n",
       "            -515432425, -1561128734],\n",
       "          [  781563832, -1320004942,  1899434901,  ...,   729515686,\n",
       "            -514671003,  1378516009]]], dtype=torch.int32),\n",
       " 'model.layers.1.self_attn.k_proj.perm': tensor([1512, 2944, 2393,  ..., 2670, 3191, 3064], dtype=torch.int16),\n",
       " 'model.layers.1.self_attn.k_proj.weight_bias': tensor([-0.0006,  0.0019,  0.0010,  ..., -0.0008, -0.0009, -0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.k_proj.weight_scale': tensor([2.0254, 1.9668, 2.0371,  ..., 1.6641, 1.8975, 1.8096],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.o_proj.centroids.weight': tensor([[-0.0030,  0.0070,  0.0145,  ..., -0.0429, -0.0065,  0.0202]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.o_proj.indices': tensor([[[-1992562490,  -813975950, -2007810534,  ...,  1305244205,\n",
       "           -1857330738,   631446206],\n",
       "          [  682272220, -1401028779,  1559305202,  ..., -1146357511,\n",
       "             578849854,  1971957396],\n",
       "          [-1134995100,   682918494,  -472258348,  ...,  -577391470,\n",
       "           -1637862552,   458922683],\n",
       "          ...,\n",
       "          [-2092656011, -1888692603, -1751462365,  ..., -2036457590,\n",
       "             991831513, -1308883848],\n",
       "          [-1351859935,   943010150,  1475246650,  ...,   221724959,\n",
       "            -108575764,   948237141],\n",
       "          [ -388715956,  -722590407,   355440048,  ..., -1149730090,\n",
       "             833960907,  -830728359]]], dtype=torch.int32),\n",
       " 'model.layers.1.self_attn.o_proj.perm': tensor([1072, 3750,  260,  ...,  251, 1710,  506], dtype=torch.int16),\n",
       " 'model.layers.1.self_attn.o_proj.weight_bias': tensor([ 5.5456e-04, -2.3568e-04,  7.6294e-04,  ...,  7.6234e-05,\n",
       "          1.2195e-04,  2.5249e-04], dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.o_proj.weight_scale': tensor([0.8589, 0.8018, 0.6904,  ..., 0.2126, 0.2181, 0.2175],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.q_proj.centroids.weight': tensor([[-0.0293, -0.0114, -0.0094,  ..., -0.0155, -0.0150, -0.0127]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.q_proj.indices': tensor([[[ -817136489,  1360906619, -1833132946,  ...,  1388727609,\n",
       "              67359269,  -561319374],\n",
       "          [ -854662896,    41881860,  1023787016,  ...,  1659360882,\n",
       "           -1104134922,   723052202],\n",
       "          [ 1166046936,  -796365437,   714309884,  ...,  1096741471,\n",
       "             317633944, -1056348618],\n",
       "          ...,\n",
       "          [ -425314188,   933282807,  -159609832,  ...,    18464728,\n",
       "           -1647381664,     2044312],\n",
       "          [  318993672,  1373435510,    88041408,  ...,  1208940051,\n",
       "              26867099,  1016952655],\n",
       "          [-1817424273,  -928979210,  1765184398,  ..., -1936800109,\n",
       "            -573371884,  1221540083]]], dtype=torch.int32),\n",
       " 'model.layers.1.self_attn.q_proj.perm': tensor([1512, 2944, 2393,  ..., 2670, 3191, 3064], dtype=torch.int16),\n",
       " 'model.layers.1.self_attn.q_proj.weight_bias': tensor([-0.0020,  0.0013,  0.0022,  ..., -0.0003, -0.0016, -0.0001],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.q_proj.weight_scale': tensor([1.9258, 1.9062, 1.8604,  ..., 1.6797, 1.9355, 1.6709],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.v_proj.centroids.weight': tensor([[ 0.0103,  0.0112,  0.0067,  ...,  0.0028, -0.0369, -0.0002]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.v_proj.indices': tensor([[[ 1721324762,   680618040, -1330404643,  ...,  1235065485,\n",
       "            -301282191,   914297826],\n",
       "          [  416148133,  -312128974,  1481242211,  ..., -1097468063,\n",
       "           -1353407134,   573707877],\n",
       "          [-1556338725,  -191375781,  -185631946,  ...,   260987954,\n",
       "             474979875,  2135885341],\n",
       "          ...,\n",
       "          [ 1658505446, -1602917795,   505517500,  ...,  2089893282,\n",
       "           -1741340612,  1732417364],\n",
       "          [  586701380,   457784279, -1768380028,  ...,   563070552,\n",
       "           -2046562677,   798459886],\n",
       "          [-1419589114, -1623158125, -1058998186,  ...,  -110533460,\n",
       "           -2013299017,  1438889322]]], dtype=torch.int32),\n",
       " 'model.layers.1.self_attn.v_proj.perm': tensor([1512, 2944, 2393,  ..., 2670, 3191, 3064], dtype=torch.int16),\n",
       " 'model.layers.1.self_attn.v_proj.weight_bias': tensor([-1.8013e-04,  1.2457e-05,  4.8089e-04,  ...,  1.9956e-04,\n",
       "         -2.2805e-04,  4.1580e-04], dtype=torch.float16),\n",
       " 'model.layers.1.self_attn.v_proj.weight_scale': tensor([0.5425, 0.5356, 0.5498,  ..., 0.6499, 0.5742, 0.6455],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.input_layernorm.weight': tensor([0.3772, 0.3755, 0.3125,  ..., 0.3428, 0.3582, 0.3398],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.mlp.down_proj.centroids.weight': tensor([[-0.0101,  0.0193,  0.0115,  ...,  0.0064, -0.0038, -0.0159]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.mlp.down_proj.indices': tensor([[[ -711938008, -1156406511,   143080732,  ...,  -270054585,\n",
       "            -930278503,  -365138687],\n",
       "          [   60633334,   445148549, -2120785239,  ...,  -418830049,\n",
       "             582181966, -1351885837],\n",
       "          [ -809088345,   100986693,  1213445452,  ..., -1155528513,\n",
       "             -79802577, -2117100398],\n",
       "          ...,\n",
       "          [ -108210698,   -42817962, -1964835518,  ...,  -954340387,\n",
       "            -835556540,   440832900],\n",
       "          [ -676001185,   993958238,  -946233563,  ...,  -299771029,\n",
       "            1267218133,  1307856683],\n",
       "          [ -947797057,  1998471590, -1795311722,  ...,   347525826,\n",
       "           -2068456256, -1907800173]]], dtype=torch.int32),\n",
       " 'model.layers.10.mlp.down_proj.perm': tensor([ 1963, 10375,  6800,  ...,  6232,  8613,  2256], dtype=torch.int16),\n",
       " 'model.layers.10.mlp.down_proj.weight_bias': tensor([ 2.1029e-04,  5.1451e-04,  2.1279e-05,  ..., -3.7360e-04,\n",
       "          1.7703e-04,  1.6558e-04], dtype=torch.float16),\n",
       " 'model.layers.10.mlp.down_proj.weight_scale': tensor([1.2314, 1.2227, 1.0762,  ..., 1.1064, 1.0771, 1.0977],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.mlp.gate_proj.centroids.weight': tensor([[ 0.0073,  0.0024,  0.0204,  ..., -0.0044,  0.0037,  0.0019]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.mlp.gate_proj.indices': tensor([[[-1193358157, -1601732098, -1953957256,  ...,  -960082225,\n",
       "            1665826777,  -308278655],\n",
       "          [-2102048273, -2083489138,  1398019466,  ..., -1674155125,\n",
       "           -1547422567,  1719224473],\n",
       "          [ -196737383,  1523639073, -1403540080,  ...,   843892290,\n",
       "           -1248466229,  1405411883],\n",
       "          ...,\n",
       "          [ 1872263559,   378969804,   373369445,  ...,    78410117,\n",
       "           -1730366086,   270522874],\n",
       "          [-1614320522, -1607707156,    10244205,  ..., -1624110002,\n",
       "             432395479,  2000273831],\n",
       "          [ -268705038, -1819761865,  -432669524,  ...,  1295552099,\n",
       "           -1135464258,  -829650037]]], dtype=torch.int32),\n",
       " 'model.layers.10.mlp.gate_proj.perm': tensor([2298, 2789, 2393,  ..., 3282, 2931,  234], dtype=torch.int16),\n",
       " 'model.layers.10.mlp.gate_proj.weight_bias': tensor([-3.3808e-04, -4.3750e-04,  1.7917e-04,  ...,  8.8274e-05,\n",
       "          2.2042e-04, -8.2135e-05], dtype=torch.float16),\n",
       " 'model.layers.10.mlp.gate_proj.weight_scale': tensor([2.0527, 2.0078, 2.0117,  ..., 2.0410, 2.0000, 2.0273],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.mlp.up_proj.centroids.weight': tensor([[-0.0059, -0.0018, -0.0213,  ..., -0.0054,  0.0017, -0.0055]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.mlp.up_proj.indices': tensor([[[ -392576373,  -811515181,   528240330,  ...,  1456462940,\n",
       "             584171187,   351866753],\n",
       "          [ 1139855786,  1546542674,  -387615623,  ...,  2071109314,\n",
       "             902433365,  1556343074],\n",
       "          [ 1943987827,  1856284020,  1046410861,  ..., -1710989593,\n",
       "             281401321, -1708333090],\n",
       "          ...,\n",
       "          [ 1074533578,  1422222589, -1060897679,  ...,  -820972027,\n",
       "           -1697673914,  1959526213],\n",
       "          [-1448278111,  -387493535, -1197634634,  ...,  -460512945,\n",
       "            1357420208,  1529235710],\n",
       "          [  658962055,  1546573068,    87277966,  ...,  -896977506,\n",
       "            1059389492, -1032751900]]], dtype=torch.int32),\n",
       " 'model.layers.10.mlp.up_proj.perm': tensor([2298, 2789, 2393,  ..., 3282, 2931,  234], dtype=torch.int16),\n",
       " 'model.layers.10.mlp.up_proj.weight_bias': tensor([ 5.5742e-04,  4.9257e-04, -9.6560e-06,  ..., -1.0049e-04,\n",
       "          1.7941e-04,  4.2200e-04], dtype=torch.float16),\n",
       " 'model.layers.10.mlp.up_proj.weight_scale': tensor([1.8945, 1.8750, 1.8809,  ..., 1.8906, 1.9219, 1.8965],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.post_attention_layernorm.weight': tensor([0.2549, 0.2351, 0.2285,  ..., 0.2448, 0.2424, 0.2424],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.k_proj.centroids.weight': tensor([[ 0.0226,  0.0003, -0.0008,  ..., -0.0198,  0.0019,  0.0018]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.k_proj.indices': tensor([[[ 1428426850,   766751956,  1752017816,  ...,    98983539,\n",
       "           -1187986828, -1340106665],\n",
       "          [ -123796448,  1342416477,   355671489,  ...,    25879283,\n",
       "             113503729,  1414404375],\n",
       "          [  423979927,  -770148424, -1889777101,  ..., -2067686941,\n",
       "           -1216753965,   585608820],\n",
       "          ...,\n",
       "          [ -421616373, -1656959525, -1777887129,  ...,    76190714,\n",
       "           -1376556466,  1447454548],\n",
       "          [  675856652,  1428796216, -1765781686,  ...,   553039061,\n",
       "            1487660607,  1747817287],\n",
       "          [-1356424891,    74634219,   642717715,  ...,  -523021446,\n",
       "            1914430253,  -508275448]]], dtype=torch.int32),\n",
       " 'model.layers.10.self_attn.k_proj.perm': tensor([1076, 2789, 2393,  ...,  888,  216, 1415], dtype=torch.int16),\n",
       " 'model.layers.10.self_attn.k_proj.weight_bias': tensor([-4.8184e-04,  1.3666e-03, -1.4286e-03,  ..., -4.8027e-03,\n",
       "         -3.1834e-03,  1.9252e-05], dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.k_proj.weight_scale': tensor([1.6680, 1.6768, 1.6816,  ..., 1.5830, 1.6074, 1.6777],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.o_proj.centroids.weight': tensor([[-0.0006,  0.0096, -0.0137,  ..., -0.0214, -0.0118, -0.0085]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.o_proj.indices': tensor([[[  -95280738, -1475133160,  1552268187,  ...,  -153440975,\n",
       "           -1229505902,  1215215480],\n",
       "          [  243821256,   413855438,   715883323,  ...,  -531472203,\n",
       "              48550776, -2134052270],\n",
       "          [  456513480,  2053819511,   851467185,  ..., -1581392060,\n",
       "            -971949027,   184265902],\n",
       "          ...,\n",
       "          [ -275353906,  -956299522,  -926366436,  ...,  -821413807,\n",
       "           -1680632798,  2068008568],\n",
       "          [  243559599,  -819886774, -1850513223,  ...,  2124161819,\n",
       "             547162412,   281833384],\n",
       "          [ 1034703108,  2121643931,  1709225604,  ..., -1436128758,\n",
       "           -2113482438, -1278140904]]], dtype=torch.int32),\n",
       " 'model.layers.10.self_attn.o_proj.perm': tensor([3729, 3926,  325,  ...,  935,  946,  988], dtype=torch.int16),\n",
       " 'model.layers.10.self_attn.o_proj.weight_bias': tensor([ 2.6321e-04,  8.9347e-05,  2.5344e-04,  ..., -8.4996e-05,\n",
       "          4.0889e-05, -1.8859e-04], dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.o_proj.weight_scale': tensor([1.0859, 1.0693, 1.0898,  ..., 0.8853, 0.8818, 0.8994],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.q_proj.centroids.weight': tensor([[-0.0211, -0.0367,  0.0279,  ..., -0.0339,  0.0163, -0.0422]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.q_proj.indices': tensor([[[ 1357311911, -1589092215,  1049349969,  ...,   768219495,\n",
       "           -1722418519,   237505877],\n",
       "          [  902805309,  -619002974,  1822617992,  ..., -1936436856,\n",
       "             259945770,   790604454],\n",
       "          [-1547213298,    93114920, -1754678344,  ..., -1018860700,\n",
       "           -1624589294, -1674796962],\n",
       "          ...,\n",
       "          [  773198656,   869560250,  1388565517,  ..., -1541384652,\n",
       "           -1847985414,  1287682257],\n",
       "          [ 1055947735, -2014646150,   577701827,  ...,  1274821327,\n",
       "            1896992297,  -254871103],\n",
       "          [ 1195711058, -1048562369,    20544600,  ...,   997948645,\n",
       "             437468186,  1202530876]]], dtype=torch.int32),\n",
       " 'model.layers.10.self_attn.q_proj.perm': tensor([1076, 2789, 2393,  ...,  888,  216, 1415], dtype=torch.int16),\n",
       " 'model.layers.10.self_attn.q_proj.weight_bias': tensor([ 0.0005,  0.0013,  0.0006,  ..., -0.0008, -0.0006, -0.0005],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.q_proj.weight_scale': tensor([1.5781, 1.6025, 1.5508,  ..., 1.6240, 1.6279, 1.6221],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.v_proj.centroids.weight': tensor([[-0.0014,  0.0090,  0.0130,  ...,  0.0237, -0.0097, -0.0130]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.v_proj.indices': tensor([[[ -746413503,   852374321,   759234732,  ...,   833376583,\n",
       "            1316873581,   825974121],\n",
       "          [-1048371233,  1492961426,  1990966885,  ...,  1407964688,\n",
       "            1961444641,  1629676339],\n",
       "          [ 1634423159, -2091417451,  1749426763,  ..., -1349132023,\n",
       "           -1451975408,    -8585244],\n",
       "          ...,\n",
       "          [  -59415600, -1063824249,    77020530,  ...,  -768669833,\n",
       "             645454251,  1681281470],\n",
       "          [-1922994244, -1739956628,  -797985330,  ..., -1025308104,\n",
       "            -426450208, -1464845156],\n",
       "          [  278835819,   570415044,  2013398623,  ..., -1740427828,\n",
       "            -316838948,   104918046]]], dtype=torch.int32),\n",
       " 'model.layers.10.self_attn.v_proj.perm': tensor([1076, 2789, 2393,  ...,  888,  216, 1415], dtype=torch.int16),\n",
       " 'model.layers.10.self_attn.v_proj.weight_bias': tensor([-9.0599e-06, -4.7565e-04,  5.8651e-05,  ...,  2.0456e-04,\n",
       "         -3.5834e-04, -3.5596e-04], dtype=torch.float16),\n",
       " 'model.layers.10.self_attn.v_proj.weight_scale': tensor([0.9819, 0.9131, 0.8906,  ..., 0.9546, 0.9385, 0.9248],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.input_layernorm.weight': tensor([0.4075, 0.3979, 0.3635,  ..., 0.3826, 0.3745, 0.3728],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.mlp.down_proj.centroids.weight': tensor([[-0.0138,  0.0194, -0.0161,  ..., -0.0126,  0.0045,  0.0044]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.mlp.down_proj.indices': tensor([[[ -854408794, -1503898981,   848157354,  ..., -1769095922,\n",
       "           -1638627638, -1828713744],\n",
       "          [-1346423622,   130828486, -1266953711,  ...,  1279169847,\n",
       "             849841181,  1485697257],\n",
       "          [-1709499278,  -793883777, -1670521352,  ...,   -39336946,\n",
       "            1458125983,  -510601632],\n",
       "          ...,\n",
       "          [ -347461776,    16106559, -1346619939,  ..., -1220307659,\n",
       "            1077899033,  -777514614],\n",
       "          [  -47031603,    62721618, -1424634512,  ...,  -471137094,\n",
       "           -1192606729,  -290608461],\n",
       "          [  903273345, -1542800154,  1666346686,  ...,  -855416833,\n",
       "           -1217222779,  1221400502]]], dtype=torch.int32),\n",
       " 'model.layers.11.mlp.down_proj.perm': tensor([ 6757,  1578,  4657,  ..., 10606,  8348,  2838], dtype=torch.int16),\n",
       " 'model.layers.11.mlp.down_proj.weight_bias': tensor([ 5.5456e-04, -3.4285e-04,  1.2827e-04,  ..., -2.7239e-05,\n",
       "          2.4366e-04, -3.9434e-04], dtype=torch.float16),\n",
       " 'model.layers.11.mlp.down_proj.weight_scale': tensor([1.1797, 1.2168, 1.1885,  ..., 1.0693, 1.0928, 1.1025],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.mlp.gate_proj.centroids.weight': tensor([[ 0.0132,  0.0063, -0.0061,  ..., -0.0112, -0.0065,  0.0041]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.mlp.gate_proj.indices': tensor([[[ 1758959797,   685830593, -1286500475,  ...,   139098873,\n",
       "           -1274440308,   588911703],\n",
       "          [  994883477, -1771261613,   786282880,  ...,  -775902627,\n",
       "           -2032111366,  1506619478],\n",
       "          [-1940647311,   491368578,  -362878382,  ...,  -441596435,\n",
       "             -79898235,   110199552],\n",
       "          ...,\n",
       "          [-1558813110,  -934082791,  -776082809,  ...,  -824313437,\n",
       "           -1496593092,  1101225632],\n",
       "          [ 1544321948,  1758542702,  1944498714,  ...,    14378267,\n",
       "            1092508821, -1370342266],\n",
       "          [ 1669530344,  -509952435,   -38315706,  ...,  -563830887,\n",
       "              26888492,    69983012]]], dtype=torch.int32),\n",
       " 'model.layers.11.mlp.gate_proj.perm': tensor([2298, 2789, 2350,  ..., 3962,   10, 3380], dtype=torch.int16),\n",
       " 'model.layers.11.mlp.gate_proj.weight_bias': tensor([-3.1185e-04, -3.4070e-04, -1.7905e-04,  ...,  7.1168e-05,\n",
       "         -1.1864e-03, -8.4639e-05], dtype=torch.float16),\n",
       " 'model.layers.11.mlp.gate_proj.weight_scale': tensor([2.0332, 2.0254, 2.0273,  ..., 2.0234, 2.0078, 2.0000],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.mlp.up_proj.centroids.weight': tensor([[-0.0095, -0.0007, -0.0061,  ..., -0.0143,  0.0058,  0.0142]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.mlp.up_proj.indices': tensor([[[ -756890524,  2083408486, -1171880005,  ..., -1672714723,\n",
       "            1378361380,  1982953949],\n",
       "          [ 2076008446,  1660558613,   207522828,  ...,  1044718199,\n",
       "           -1040292454,  -567924674],\n",
       "          [ 1242450326,  1766590480,  2036998032,  ...,  -211705899,\n",
       "           -2133791611,  -965135817],\n",
       "          ...,\n",
       "          [  398554945,  -783824381,  -892265290,  ..., -1701193691,\n",
       "           -1251567481, -2102168895],\n",
       "          [ -389659135,  1806121474, -2053529987,  ...,  1054592465,\n",
       "           -1880043216,  -481193835],\n",
       "          [ 2050593263, -1214110307,  1254132439,  ..., -1398938480,\n",
       "           -1119712169,  1600399171]]], dtype=torch.int32),\n",
       " 'model.layers.11.mlp.up_proj.perm': tensor([2298, 2789, 2350,  ..., 3962,   10, 3380], dtype=torch.int16),\n",
       " 'model.layers.11.mlp.up_proj.weight_bias': tensor([ 2.2781e-04, -1.6761e-04,  3.0804e-04,  ..., -3.2806e-04,\n",
       "         -7.8201e-05,  2.8491e-04], dtype=torch.float16),\n",
       " 'model.layers.11.mlp.up_proj.weight_scale': tensor([1.9170, 1.8916, 1.8848,  ..., 1.9150, 1.9326, 1.9180],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.post_attention_layernorm.weight': tensor([0.2622, 0.2399, 0.2375,  ..., 0.2566, 0.2559, 0.2515],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.k_proj.centroids.weight': tensor([[-4.0436e-02,  4.0955e-02,  3.1114e-05,  ..., -3.2013e-02,\n",
       "           1.0071e-02,  3.5553e-03]], dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.k_proj.indices': tensor([[[ -397776877, -1018763784,  1907539675,  ...,   660828560,\n",
       "            -807350008, -2040244785],\n",
       "          [-1701025377,   449900272,  1844569050,  ...,   827727135,\n",
       "             992427252, -2022063218],\n",
       "          [ 1905406604,   726488126,  -324657794,  ...,  1523230425,\n",
       "            2125148247,  1744201599],\n",
       "          ...,\n",
       "          [ 2055009375,  -675520930,   778319742,  ...,  2140531692,\n",
       "            1188611566, -1125021602],\n",
       "          [  431511200,   670957114,  1159294902,  ..., -1561381568,\n",
       "            -507056823, -2054538201],\n",
       "          [ 1074054396,   803046215,  1988378237,  ..., -1222189987,\n",
       "             389300345,  -848365913]]], dtype=torch.int32),\n",
       " 'model.layers.11.self_attn.k_proj.perm': tensor([1076, 2789, 2393,  ...,  216,  596, 1415], dtype=torch.int16),\n",
       " 'model.layers.11.self_attn.k_proj.weight_bias': tensor([-0.0026,  0.0021, -0.0001,  ..., -0.0020,  0.0007,  0.0004],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.k_proj.weight_scale': tensor([1.5117, 1.5244, 1.5762,  ..., 1.5020, 1.4570, 1.5537],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.o_proj.centroids.weight': tensor([[ 0.0162,  0.0358, -0.0147,  ...,  0.0161,  0.0182,  0.0102]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.o_proj.indices': tensor([[[ -148105986,   991150498,   452638534,  ..., -1036440668,\n",
       "             645605990,  -900683941],\n",
       "          [   -6507028,  1893971793, -2061584159,  ..., -2132836398,\n",
       "             125472949,  1151670950],\n",
       "          [ -221641330,  -209173516,    98198080,  ...,  -251785027,\n",
       "             636876599,  1143283496],\n",
       "          ...,\n",
       "          [-1575905310,  1429649302,   456723438,  ...,  -265334526,\n",
       "           -1181074759, -1099636717],\n",
       "          [  555912125, -2073618396,  -754757314,  ..., -2140757949,\n",
       "            1806933102,  1933099823],\n",
       "          [  492072307, -1997758895,  -183092820,  ..., -1533770353,\n",
       "             266252202,  -169479458]]], dtype=torch.int32),\n",
       " 'model.layers.11.self_attn.o_proj.perm': tensor([3034,  811, 3844,  ..., 1777, 1706, 1667], dtype=torch.int16),\n",
       " 'model.layers.11.self_attn.o_proj.weight_bias': tensor([-2.7776e-05,  6.2287e-05,  6.6757e-06,  ...,  1.2130e-04,\n",
       "          1.1897e-04,  3.2330e-04], dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.o_proj.weight_scale': tensor([0.8950, 0.9268, 0.8940,  ..., 0.9604, 0.9941, 0.9785],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.q_proj.centroids.weight': tensor([[ 0.0034,  0.0038, -0.0018,  ..., -0.0157, -0.0206,  0.0053]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.q_proj.indices': tensor([[[ -819062258,  1980901610,    52373616,  ..., -1809015131,\n",
       "             705048303,   677986458],\n",
       "          [ -498829501, -1662755988,  -497215083,  ...,  -115334950,\n",
       "            -345381951,  -609741019],\n",
       "          [ 1417160236,   611116462,  1442316738,  ..., -1257766663,\n",
       "            1195427644,  -155401562],\n",
       "          ...,\n",
       "          [ 1195060917,   317292709, -1108848605,  ...,  1753705084,\n",
       "            1092674476, -1479452236],\n",
       "          [ 1862578259,   386898579,    79319461,  ...,  -867516582,\n",
       "           -1110559146,  1895373867],\n",
       "          [-1054215009,  1120266383, -1268518292,  ...,  1952902898,\n",
       "            1816640729,   741764655]]], dtype=torch.int32),\n",
       " 'model.layers.11.self_attn.q_proj.perm': tensor([1076, 2789, 2393,  ...,  216,  596, 1415], dtype=torch.int16),\n",
       " 'model.layers.11.self_attn.q_proj.weight_bias': tensor([ 0.0003, -0.0019, -0.0002,  ..., -0.0001,  0.0024,  0.0001],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.q_proj.weight_scale': tensor([1.5332, 1.5762, 1.5068,  ..., 1.5107, 1.5615, 1.5371],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.v_proj.centroids.weight': tensor([[-0.0066,  0.0192, -0.0132,  ...,  0.0012, -0.0075,  0.0136]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.v_proj.indices': tensor([[[ 1324097696,  -304899734,   976289484,  ..., -1012455611,\n",
       "             353322559,   180057153],\n",
       "          [-1705016664,   707340606, -1136254631,  ...,   281521305,\n",
       "            1455663359,  1168722539],\n",
       "          [ -126964899, -2117662438,   104103091,  ..., -1796831200,\n",
       "            1444316455,  -106276309],\n",
       "          ...,\n",
       "          [  477347024, -1709161265, -2104758086,  ...,  -361717438,\n",
       "             205533489, -2067609729],\n",
       "          [  738083013, -1246632550, -2073138400,  ...,   266177927,\n",
       "            1514389682, -1380282947],\n",
       "          [-1504469669, -1036719207, -1753211510,  ..., -1990906947,\n",
       "           -1617959615,  2011480317]]], dtype=torch.int32),\n",
       " 'model.layers.11.self_attn.v_proj.perm': tensor([1076, 2789, 2393,  ...,  216,  596, 1415], dtype=torch.int16),\n",
       " 'model.layers.11.self_attn.v_proj.weight_bias': tensor([-7.3576e-04,  4.2605e-04,  1.4186e-04,  ..., -4.9782e-04,\n",
       "         -1.7023e-04, -9.2983e-06], dtype=torch.float16),\n",
       " 'model.layers.11.self_attn.v_proj.weight_scale': tensor([0.9912, 0.9326, 0.8999,  ..., 1.0049, 0.9824, 0.9580],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.input_layernorm.weight': tensor([0.4021, 0.3987, 0.3730,  ..., 0.3831, 0.3860, 0.3875],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.mlp.down_proj.centroids.weight': tensor([[-0.0229, -0.0098, -0.0031,  ...,  0.0001, -0.0043, -0.0055]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.mlp.down_proj.indices': tensor([[[ 2130378404,   311386464,   939607216,  ...,   -73872369,\n",
       "            -243060946,  1201608103],\n",
       "          [-1987326769,  -209877985, -1150158751,  ...,   689085484,\n",
       "            -755242059, -1151488826],\n",
       "          [ -529045561,   206630972,   923725504,  ...,   268737865,\n",
       "             379441911,  1603102729],\n",
       "          ...,\n",
       "          [-1397415681,  1568026306,   595833722,  ...,  1757968506,\n",
       "           -1234098029, -2100537707],\n",
       "          [  341775953, -2122497529, -2135954964,  ...,    46343122,\n",
       "             118584044,  -692118352],\n",
       "          [ -559950419,   974322604, -1343424197,  ..., -2092314862,\n",
       "            -733333343, -1892446351]]], dtype=torch.int32),\n",
       " 'model.layers.12.mlp.down_proj.perm': tensor([ 1085,  2591, 10038,  ...,  2774,  3978,  2881], dtype=torch.int16),\n",
       " 'model.layers.12.mlp.down_proj.weight_bias': tensor([ 2.1279e-04,  1.5771e-04,  9.8825e-05,  ..., -4.3750e-04,\n",
       "         -8.3506e-05,  6.6102e-05], dtype=torch.float16),\n",
       " 'model.layers.12.mlp.down_proj.weight_scale': tensor([1.2246, 1.2070, 1.1084,  ..., 1.1348, 1.0977, 1.0742],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.mlp.gate_proj.centroids.weight': tensor([[-0.0018,  0.0252,  0.0073,  ..., -0.0057,  0.0021,  0.0114]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.mlp.gate_proj.indices': tensor([[[ -682182197,  1167919482, -2114656298,  ...,    50422698,\n",
       "           -1782804204,  1710168159],\n",
       "          [ -986369493,   983745201,   949641134,  ...,  -754062149,\n",
       "           -1093361395,  -249563643],\n",
       "          [-1391616560, -2127475082, -1093320455,  ..., -1993666283,\n",
       "            -784932538,  1204608076],\n",
       "          ...,\n",
       "          [  433674877,  1612101017,  1427228901,  ...,  -945687508,\n",
       "            1463868491, -2072565708],\n",
       "          [-1348264180,  1807982751,  -350136553,  ...,  -246954073,\n",
       "            2007088767, -1396823197],\n",
       "          [-1947503819,   259947651,  2088370911,  ...,  -963332991,\n",
       "            2133580180,   405139797]]], dtype=torch.int32),\n",
       " 'model.layers.12.mlp.gate_proj.perm': tensor([2298, 2789, 2350,  ..., 2329, 3817, 2950], dtype=torch.int16),\n",
       " 'model.layers.12.mlp.gate_proj.weight_bias': tensor([-5.4216e-04, -1.9064e-03, -1.2636e-05,  ..., -2.7776e-04,\n",
       "          3.1209e-04,  5.4419e-05], dtype=torch.float16),\n",
       " 'model.layers.12.mlp.gate_proj.weight_scale': tensor([2.0000, 1.9980, 1.9971,  ..., 1.9980, 1.9824, 2.0137],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.mlp.up_proj.centroids.weight': tensor([[-0.0019,  0.0091,  0.0168,  ..., -0.0070, -0.0115, -0.0003]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.mlp.up_proj.indices': tensor([[[ 1453645791,   384157150,  1337383422,  ...,  -392346350,\n",
       "             965972475,  -394746170],\n",
       "          [ -739023893, -1694012803,  1185013365,  ...,  -468125904,\n",
       "            1440222891,   593496481],\n",
       "          [ 2014100720,  1627864000,  1915554731,  ..., -1303973042,\n",
       "              62937107,  -706821023],\n",
       "          ...,\n",
       "          [  781876185,    32626311,  1430359180,  ..., -1750668585,\n",
       "             245676117,  1944685359],\n",
       "          [ 1944008080,  1078421269, -1499976251,  ...,  1724067617,\n",
       "           -1650693369, -1099445306],\n",
       "          [  334276221,  1771321760,  1635726863,  ...,  1839305640,\n",
       "           -1541669746,  1465336149]]], dtype=torch.int32),\n",
       " 'model.layers.12.mlp.up_proj.perm': tensor([2298, 2789, 2350,  ..., 2329, 3817, 2950], dtype=torch.int16),\n",
       " 'model.layers.12.mlp.up_proj.weight_bias': tensor([ 8.2731e-05, -1.6201e-04, -1.6916e-04,  ...,  7.2956e-05,\n",
       "          2.5105e-04,  8.8573e-05], dtype=torch.float16),\n",
       " 'model.layers.12.mlp.up_proj.weight_scale': tensor([1.9482, 1.9199, 1.9316,  ..., 1.9463, 1.9443, 1.9258],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.post_attention_layernorm.weight': tensor([0.2676, 0.2505, 0.2468,  ..., 0.2644, 0.2627, 0.2610],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.k_proj.centroids.weight': tensor([[ 0.0020,  0.0024,  0.0021,  ..., -0.0262,  0.0127,  0.0001]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.k_proj.indices': tensor([[[ -349928144, -1584614003, -1253467890,  ..., -1740401905,\n",
       "            -970287819,   296426957],\n",
       "          [ 1334228275,  1186679712,   379974350,  ..., -1790011300,\n",
       "            1585282815,  1997458476],\n",
       "          [ -469918590,  -184086913,  1880598121,  ..., -1290363645,\n",
       "            1897919704,  -363858134],\n",
       "          ...,\n",
       "          [  759328998,  1496520128, -1839144863,  ..., -2103806430,\n",
       "            -339833873,  -331595540],\n",
       "          [ 1460062684,  -517818137, -1188317304,  ...,  -352020684,\n",
       "             743496805,   778966307],\n",
       "          [ -459143445, -1989286802,  -413251509,  ...,   491390068,\n",
       "            2052973334, -1860535306]]], dtype=torch.int32),\n",
       " 'model.layers.12.self_attn.k_proj.perm': tensor([2789, 1076, 2158,  ..., 1342,  216, 1415], dtype=torch.int16),\n",
       " 'model.layers.12.self_attn.k_proj.weight_bias': tensor([ 0.0002,  0.0037,  0.0014,  ...,  0.0019, -0.0020,  0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.k_proj.weight_scale': tensor([1.6475, 1.6338, 1.6260,  ..., 1.5898, 1.5605, 1.6133],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.o_proj.centroids.weight': tensor([[ 0.0288,  0.0065, -0.0163,  ..., -0.0022, -0.0093, -0.0013]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.o_proj.indices': tensor([[[-1580973076, -1572686375,    93284660,  ...,  1083292292,\n",
       "            -117503076,   122429555],\n",
       "          [-1782248589, -1278748068,  1221986856,  ...,   118152964,\n",
       "            2133342106,  1528685767],\n",
       "          [  128728338, -1887419396,  1746563417,  ...,   516280338,\n",
       "             225760399,  -158250136],\n",
       "          ...,\n",
       "          [-1349782075,  -467802968,  -137361618,  ...,  1859402586,\n",
       "            2033606625,  -273329491],\n",
       "          [-2039683012,  1116759511,  2039889520,  ...,  -108584925,\n",
       "            1340132720,  1442738690],\n",
       "          [  693457943, -1868413639,  1343207258,  ...,  1058036641,\n",
       "             770051581,  1388718033]]], dtype=torch.int32),\n",
       " 'model.layers.12.self_attn.o_proj.perm': tensor([ 540, 1776, 1667,  ..., 2925, 2907, 2881], dtype=torch.int16),\n",
       " 'model.layers.12.self_attn.o_proj.weight_bias': tensor([ 3.6812e-04, -1.4830e-04, -9.7036e-05,  ...,  1.2696e-04,\n",
       "         -1.4591e-04, -3.8385e-04], dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.o_proj.weight_scale': tensor([0.8984, 0.9072, 0.9351,  ..., 0.8052, 0.8203, 0.8208],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.q_proj.centroids.weight': tensor([[ 0.0346,  0.0481,  0.0203,  ...,  0.0043, -0.0102,  0.0048]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.q_proj.indices': tensor([[[ 1567896984,  1450943441,  1009756760,  ...,  1055101774,\n",
       "             954351733, -1847715064],\n",
       "          [ 1868069123,  -927491787,   997659436,  ...,  1402291282,\n",
       "           -1207059374,  1799288137],\n",
       "          [  425908296, -2023500571,  1280274140,  ..., -1763353502,\n",
       "           -1811671293,   219260887],\n",
       "          ...,\n",
       "          [  916851361,   217503329, -1440942559,  ...,  1621938979,\n",
       "            1560796780,  -796506970],\n",
       "          [-1910854228,  1826009306,  1440456924,  ...,   399668302,\n",
       "            1168325484,   933791255],\n",
       "          [ -627264196,  1235393070,  1467939454,  ...,   621201500,\n",
       "            -978524259,   655225073]]], dtype=torch.int32),\n",
       " 'model.layers.12.self_attn.q_proj.perm': tensor([2789, 1076, 2158,  ..., 1342,  216, 1415], dtype=torch.int16),\n",
       " 'model.layers.12.self_attn.q_proj.weight_bias': tensor([-1.6394e-03,  1.2159e-03, -8.8692e-05,  ...,  2.5520e-03,\n",
       "         -1.6956e-03, -1.8559e-03], dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.q_proj.weight_scale': tensor([1.5098, 1.5742, 1.5391,  ..., 1.5195, 1.5781, 1.5752],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.v_proj.centroids.weight': tensor([[-0.0064,  0.0087, -0.0122,  ...,  0.0167,  0.0119,  0.0306]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.v_proj.indices': tensor([[[ -643869815,   -97901474,  -420923345,  ...,   605933446,\n",
       "             821117075,  -521404559],\n",
       "          [ -485726435,  1335080555, -1731529474,  ..., -1305888291,\n",
       "             816965946,  1311056792],\n",
       "          [  654848251, -2145505320,  -761509593,  ...,  2008390637,\n",
       "            1066833603,  1039701598],\n",
       "          ...,\n",
       "          [ -541847162, -1392452191,  -107773990,  ..., -2127167939,\n",
       "           -1250248580,  -958261264],\n",
       "          [ 2062216254, -1053709100,  1977057256,  ...,  -389717135,\n",
       "            1105356252,  -381596853],\n",
       "          [-2046670601,    69404957,  1861222651,  ..., -1005208890,\n",
       "            1398936722, -1632311699]]], dtype=torch.int32),\n",
       " 'model.layers.12.self_attn.v_proj.perm': tensor([2789, 1076, 2158,  ..., 1342,  216, 1415], dtype=torch.int16),\n",
       " 'model.layers.12.self_attn.v_proj.weight_bias': tensor([-0.0003,  0.0002, -0.0001,  ..., -0.0002,  0.0002,  0.0001],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.12.self_attn.v_proj.weight_scale': tensor([0.9824, 0.8833, 0.9224,  ..., 1.0000, 0.9800, 0.9448],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.input_layernorm.weight': tensor([0.4265, 0.4155, 0.3774,  ..., 0.3875, 0.3823, 0.3994],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.mlp.down_proj.centroids.weight': tensor([[-0.0098, -0.0145, -0.0314,  ..., -0.0129, -0.0125, -0.0286]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.mlp.down_proj.indices': tensor([[[ 1559682745, -1395634013, -1307011409,  ..., -2067618648,\n",
       "           -1762851696, -1802100166],\n",
       "          [  232564912,  1111532801,  -357378509,  ...,   763789682,\n",
       "             204205621, -1845828039],\n",
       "          [ -915417727,  2089297682,   639978461,  ...,  1849680649,\n",
       "           -1254443855,  1580527844],\n",
       "          ...,\n",
       "          [ -963114134,  2055823109,  1011494093,  ...,  1417685645,\n",
       "            -826054773,  -937266844],\n",
       "          [-1890388256,  1092792841, -1086012324,  ...,  -860893303,\n",
       "            -307111607,   157865488],\n",
       "          [-2139063764, -1944567804,  1740179603,  ...,   380059316,\n",
       "             474065783, -1730335294]]], dtype=torch.int32),\n",
       " 'model.layers.13.mlp.down_proj.perm': tensor([2208,  330, 7276,  ..., 3794, 3611, 7218], dtype=torch.int16),\n",
       " 'model.layers.13.mlp.down_proj.weight_bias': tensor([ 5.3740e-04, -2.7514e-04, -7.3385e-04,  ..., -2.2054e-06,\n",
       "         -3.1734e-04, -1.9979e-04], dtype=torch.float16),\n",
       " 'model.layers.13.mlp.down_proj.weight_scale': tensor([1.0566, 1.1348, 1.1553,  ..., 1.1260, 1.1074, 1.1719],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.mlp.gate_proj.centroids.weight': tensor([[0.0031, 0.0103, 0.0028,  ..., 0.0049, 0.0022, 0.0076]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.mlp.gate_proj.indices': tensor([[[-1953561082,  1194196324,   159398591,  ..., -1468513011,\n",
       "            -142459268, -1051049536],\n",
       "          [-1819313476,  -369683437,  -388269868,  ...,  1176330835,\n",
       "            -787201069,  -242006514],\n",
       "          [  -47088945,  1434253094, -2053011102,  ...,  -705482117,\n",
       "            1956648867,   767091653],\n",
       "          ...,\n",
       "          [ 1108325743, -1319942428, -1057866995,  ..., -1552371652,\n",
       "            1450092952,  -417602189],\n",
       "          [-1285881261,   569557117,  1412852152,  ..., -1724006128,\n",
       "             670047557,  -209075489],\n",
       "          [-1544169592, -1651586385, -1396608270,  ..., -2058182765,\n",
       "            1058628980,  1212702496]]], dtype=torch.int32),\n",
       " 'model.layers.13.mlp.gate_proj.perm': tensor([2789, 2298, 4071,  ..., 2861, 3380, 2167], dtype=torch.int16),\n",
       " 'model.layers.13.mlp.gate_proj.weight_bias': tensor([-0.0010,  0.0003, -0.0004,  ..., -0.0002, -0.0007, -0.0013],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.mlp.gate_proj.weight_scale': tensor([2.0000, 1.9824, 2.0059,  ..., 2.0078, 2.0137, 1.9902],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.mlp.up_proj.centroids.weight': tensor([[ 0.0064, -0.0054,  0.0023,  ...,  0.0049,  0.0122, -0.0017]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.mlp.up_proj.indices': tensor([[[ -121705082,   996743021,   597310194,  ...,  -984510123,\n",
       "           -1609081593,  1211858451],\n",
       "          [ 1467690453,   739388524,  1479135278,  ...,  -773284937,\n",
       "            -174360819, -1175756125],\n",
       "          [-1640665409,  1030786035,  -646391045,  ...,  -895162907,\n",
       "            -677795761, -1243628213],\n",
       "          ...,\n",
       "          [-1196850230,   620804076,  -290853170,  ...,  1283253654,\n",
       "           -1521550508,   313829333],\n",
       "          [ 1512715919,   717162393,   -15817268,  ...,  1317130105,\n",
       "           -1914758334,  1393801694],\n",
       "          [-2100497757,  1326522001,   652740497,  ..., -1276584361,\n",
       "            2072472538,    67300262]]], dtype=torch.int32),\n",
       " 'model.layers.13.mlp.up_proj.perm': tensor([2789, 2298, 4071,  ..., 2861, 3380, 2167], dtype=torch.int16),\n",
       " 'model.layers.13.mlp.up_proj.weight_bias': tensor([ 3.3879e-04, -1.5950e-04, -1.0598e-04,  ..., -1.8668e-04,\n",
       "          2.4676e-05,  2.7347e-04], dtype=torch.float16),\n",
       " 'model.layers.13.mlp.up_proj.weight_scale': tensor([1.9570, 1.9492, 1.9199,  ..., 1.9473, 1.9375, 1.9590],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.post_attention_layernorm.weight': tensor([0.2725, 0.2578, 0.2489,  ..., 0.2720, 0.2700, 0.2607],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.k_proj.centroids.weight': tensor([[ 0.0378, -0.0319,  0.0180,  ...,  0.0164, -0.0326, -0.0047]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.k_proj.indices': tensor([[[ -208266877,  1751353157,  1778381236,  ..., -1890354967,\n",
       "             190371742,  1499405938],\n",
       "          [ 2140162677,   942291782,  -773232149,  ...,  1952046109,\n",
       "           -1031214603, -1004423592],\n",
       "          [  294153956,   427608573,   234271578,  ...,  1343706136,\n",
       "           -1940034246,   225201185],\n",
       "          ...,\n",
       "          [ -494485405,  2110432303, -1997093532,  ...,  1633547261,\n",
       "            1406819837, -1475248920],\n",
       "          [ -922835855,  1366470825,  -574318833,  ..., -1715979596,\n",
       "           -1603650139,  2037135553],\n",
       "          [  247173701, -1799984467,  1886125753,  ...,   341493426,\n",
       "             945154882,  2004706511]]], dtype=torch.int32),\n",
       " 'model.layers.13.self_attn.k_proj.perm': tensor([1076, 2789, 2158,  ..., 1946, 1342, 1415], dtype=torch.int16),\n",
       " 'model.layers.13.self_attn.k_proj.weight_bias': tensor([ 0.0011,  0.0005, -0.0029,  ..., -0.0006, -0.0022, -0.0003],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.k_proj.weight_scale': tensor([1.6172, 1.5859, 1.5869,  ..., 1.5586, 1.5420, 1.5762],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.o_proj.centroids.weight': tensor([[ 0.0005,  0.0233, -0.0188,  ...,  0.0277, -0.0005,  0.0124]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.o_proj.indices': tensor([[[  585615264,  -720121393,  -512123160,  ...,  -739811195,\n",
       "             354611452,  1990202182],\n",
       "          [-2094036185,   770511683, -1681222416,  ...,   441456840,\n",
       "           -1945235438, -1984098790],\n",
       "          [  -64072936,  1290944271,   167488372,  ...,  1824494423,\n",
       "            -803175518,   344441980],\n",
       "          ...,\n",
       "          [ 1149282396,  1001536730, -1498816022,  ...,  -261322315,\n",
       "            1883431620,   868310325],\n",
       "          [-1688070059,  1578736981,  1621563218,  ...,  1734310796,\n",
       "           -1449195056,  -749241952],\n",
       "          [-1304041481,   645165920,  1442635019,  ...,   141457565,\n",
       "            -897847731,  1403044227]]], dtype=torch.int32),\n",
       " 'model.layers.13.self_attn.o_proj.perm': tensor([ 525, 3982, 2212,  ..., 1973, 1944, 2003], dtype=torch.int16),\n",
       " 'model.layers.13.self_attn.o_proj.weight_bias': tensor([ 1.7405e-04,  5.0128e-05, -2.8539e-04,  ..., -5.9247e-05,\n",
       "          2.0862e-06,  3.6120e-04], dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.o_proj.weight_scale': tensor([0.8965, 0.9219, 0.9331,  ..., 0.9429, 0.9028, 0.9355],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.q_proj.centroids.weight': tensor([[ 0.0021,  0.0103,  0.0095,  ...,  0.0383, -0.0017, -0.0070]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.q_proj.indices': tensor([[[-1641017837, -1731958716,  -282264891,  ...,   361791317,\n",
       "           -1893709357, -1846900645],\n",
       "          [ -322238304,  -855991325,  1512862615,  ..., -1969053943,\n",
       "           -1641637678, -1078835300],\n",
       "          [  691135257,   561146957,   655908251,  ..., -1097944396,\n",
       "           -1199773043,  1614698071],\n",
       "          ...,\n",
       "          [ 1368313158,   598084830,  1823608511,  ...,  1907024590,\n",
       "           -1041024783,  1447612292],\n",
       "          [ -780751207,  2014383701,  1244463011,  ...,  1895940461,\n",
       "           -1367470432, -1477667676],\n",
       "          [ -887198664,  -928112783,  -701134927,  ...,  1069313455,\n",
       "           -1160193392, -1518527535]]], dtype=torch.int32),\n",
       " 'model.layers.13.self_attn.q_proj.perm': tensor([1076, 2789, 2158,  ..., 1946, 1342, 1415], dtype=torch.int16),\n",
       " 'model.layers.13.self_attn.q_proj.weight_bias': tensor([-0.0010,  0.0014,  0.0023,  ..., -0.0009,  0.0014,  0.0017],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.q_proj.weight_scale': tensor([1.5059, 1.5762, 1.5205,  ..., 1.5391, 1.5400, 1.5596],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.v_proj.centroids.weight': tensor([[-0.0295,  0.0206, -0.0042,  ..., -0.0117, -0.0038, -0.0320]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.v_proj.indices': tensor([[[ -232122435,  -259322497,  1282698878,  ...,  2039681274,\n",
       "            1624792878,  1910765803],\n",
       "          [ -425301680,  1891385860, -1507558890,  ..., -1235289347,\n",
       "           -1061931484,   166919602],\n",
       "          [-1621793730, -1440168053,  -331388351,  ...,  1999707931,\n",
       "           -1957919788,  1131400746],\n",
       "          ...,\n",
       "          [ -177121640, -1280241621,   987411872,  ...,  -785115415,\n",
       "           -1908742640,    70638676],\n",
       "          [  973102763,  1113404773,  1951636131,  ...,   714804839,\n",
       "           -2060145325, -1474984417],\n",
       "          [ 1328204259,  -620132304, -1987782544,  ...,  -584179658,\n",
       "              16704004,  1933963807]]], dtype=torch.int32),\n",
       " 'model.layers.13.self_attn.v_proj.perm': tensor([1076, 2789, 2158,  ..., 1946, 1342, 1415], dtype=torch.int16),\n",
       " 'model.layers.13.self_attn.v_proj.weight_bias': tensor([ 2.0659e-04, -1.4496e-04, -1.7583e-04,  ..., -7.6818e-04,\n",
       "          1.1802e-05,  4.3333e-05], dtype=torch.float16),\n",
       " 'model.layers.13.self_attn.v_proj.weight_scale': tensor([1.0244, 0.9604, 0.9751,  ..., 1.0137, 1.0068, 0.9585],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.input_layernorm.weight': tensor([0.4199, 0.4263, 0.3806,  ..., 0.4204, 0.4106, 0.3997],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.mlp.down_proj.centroids.weight': tensor([[ 0.0210,  0.0066, -0.0145,  ...,  0.0143, -0.0032, -0.0131]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.mlp.down_proj.indices': tensor([[[ 1898310880,  -179020156, -1721925492,  ..., -1816601354,\n",
       "            2015992795,  -499278439],\n",
       "          [ -431134565,   762108049,  1796063301,  ...,  1226171972,\n",
       "             500417804,  1269263350],\n",
       "          [  -43990579,  1957532433, -1037973805,  ..., -1156406257,\n",
       "            -248131529,   667017060],\n",
       "          ...,\n",
       "          [-1557165542,  1558163672,  -476308522,  ...,  1889315917,\n",
       "           -1427467108,  -492865908],\n",
       "          [ 1058703863,  1554788995,  1956407625,  ...,  1266561251,\n",
       "            1778447453,  2136117914],\n",
       "          [-2035077788,   784080142,  1016551680,  ...,  1213201077,\n",
       "             892554387, -1969769484]]], dtype=torch.int32),\n",
       " 'model.layers.14.mlp.down_proj.perm': tensor([4900, 9875, 7794,  ..., 2607, 8438, 3574], dtype=torch.int16),\n",
       " 'model.layers.14.mlp.down_proj.weight_bias': tensor([-1.5914e-05, -1.7619e-04, -1.9383e-04,  ..., -2.0480e-04,\n",
       "          2.9993e-04,  3.6526e-04], dtype=torch.float16),\n",
       " 'model.layers.14.mlp.down_proj.weight_scale': tensor([1.1504, 1.1885, 1.1533,  ..., 1.2041, 1.1240, 1.0850],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.mlp.gate_proj.centroids.weight': tensor([[ 0.0031,  0.0069,  0.0096,  ...,  0.0018, -0.0088, -0.0040]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.mlp.gate_proj.indices': tensor([[[ -739405869,  1713770657, -1357718209,  ..., -1487877782,\n",
       "              89778771,  -362554387],\n",
       "          [ 1201685849, -1985128086,  1161546401,  ...,  1425647373,\n",
       "            1555789672,   552947096],\n",
       "          [  876841698,  -625450306, -1603524867,  ...,   827686593,\n",
       "           -1473040208,  -187576777],\n",
       "          ...,\n",
       "          [-1843650718, -1421696038,  -164736485,  ..., -1788278174,\n",
       "             631594732,   -67145136],\n",
       "          [  216374688,   530411037,  -157319947,  ...,   540354996,\n",
       "            -917086229,   612982038],\n",
       "          [ 1650015960,  1815073482,  1757007444,  ...,   877917072,\n",
       "           -1884945600,  -964768009]]], dtype=torch.int32),\n",
       " 'model.layers.14.mlp.gate_proj.perm': tensor([2789, 2298, 4071,  ..., 3116, 2918, 1697], dtype=torch.int16),\n",
       " 'model.layers.14.mlp.gate_proj.weight_bias': tensor([-3.2401e-04, -6.3705e-04, -8.4519e-05,  ..., -9.0837e-05,\n",
       "         -1.4448e-03, -7.6485e-04], dtype=torch.float16),\n",
       " 'model.layers.14.mlp.gate_proj.weight_scale': tensor([1.9932, 1.9775, 1.9980,  ..., 2.0098, 1.9775, 1.9746],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.mlp.up_proj.centroids.weight': tensor([[ 0.0024,  0.0206,  0.0013,  ..., -0.0013,  0.0018,  0.0002]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.mlp.up_proj.indices': tensor([[[ -513049804, -1063352459,   121095766,  ..., -1174130206,\n",
       "             335407307,  1232851748],\n",
       "          [  746922120,   493881356,  1263307786,  ...,  -292132147,\n",
       "            1754490269,  1037132702],\n",
       "          [ 1233070363,  1447820194,  1083943597,  ..., -2100087652,\n",
       "            1196179496, -1088063613],\n",
       "          ...,\n",
       "          [ 1118647125,   362100208,  -841260459,  ...,  1465854653,\n",
       "            -110024232, -1522850178],\n",
       "          [-1917615663,  2035145309,  -302690253,  ..., -1092680071,\n",
       "            1533027564,   -65417591],\n",
       "          [ 1874922759,   264091681,  1803432461,  ...,  1887690726,\n",
       "             545515133,  -269232572]]], dtype=torch.int32),\n",
       " 'model.layers.14.mlp.up_proj.perm': tensor([2789, 2298, 4071,  ..., 3116, 2918, 1697], dtype=torch.int16),\n",
       " 'model.layers.14.mlp.up_proj.weight_bias': tensor([-3.5882e-05,  1.6999e-04, -4.5538e-05,  ..., -4.1842e-05,\n",
       "         -5.1677e-05, -3.4809e-04], dtype=torch.float16),\n",
       " 'model.layers.14.mlp.up_proj.weight_scale': tensor([1.9658, 1.9502, 1.9385,  ..., 1.9365, 1.9756, 1.9629],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.post_attention_layernorm.weight': tensor([0.2812, 0.2651, 0.2654,  ..., 0.2832, 0.2793, 0.2742],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.k_proj.centroids.weight': tensor([[ 0.0108, -0.0078,  0.0169,  ...,  0.0284,  0.0151,  0.0158]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.k_proj.indices': tensor([[[-1390424891, -1582203025,  -631825545,  ..., -1438236028,\n",
       "            1998205683,  -557704663],\n",
       "          [  720294389,   312483399, -1291838268,  ...,  1479845673,\n",
       "           -2106951715,  1028879018],\n",
       "          [ 1427303074,   554554031,  1165664983,  ...,    62732830,\n",
       "            -891908688,  1501253333],\n",
       "          ...,\n",
       "          [  308358780,   993850966, -1920052905,  ...,   968481985,\n",
       "             -92045912, -1413921008],\n",
       "          [ 1288537462, -1729529151,   400928098,  ...,   712163143,\n",
       "            1930675579,  1314173851],\n",
       "          [-1795749821,   740532073,   127958348,  ...,  -312134576,\n",
       "           -1080672485,   954831088]]], dtype=torch.int32),\n",
       " 'model.layers.14.self_attn.k_proj.perm': tensor([2789, 1076, 2158,  ..., 1946, 4062, 1415], dtype=torch.int16),\n",
       " 'model.layers.14.self_attn.k_proj.weight_bias': tensor([-0.0028, -0.0012,  0.0002,  ...,  0.0019, -0.0033,  0.0018],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.k_proj.weight_scale': tensor([1.6133, 1.5811, 1.5957,  ..., 1.5459, 1.5342, 1.5566],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.o_proj.centroids.weight': tensor([[-0.0151, -0.0029,  0.0068,  ..., -0.0166, -0.0065,  0.0096]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.o_proj.indices': tensor([[[ -761621174,  1943687999,  -203996693,  ..., -1875476941,\n",
       "            1429956668,  -921093500],\n",
       "          [  182392783,  1315023274,   211348387,  ...,  1047661196,\n",
       "            1911817224,  -435125996],\n",
       "          [ 1375502287,  -978776243,  1315173885,  ...,  2056376750,\n",
       "           -1899871033,  -641181134],\n",
       "          ...,\n",
       "          [-1297540148, -1937376500, -1070500237,  ...,   668345027,\n",
       "            -641929527,   120178548],\n",
       "          [ -500196984, -1262134073,  1368590972,  ..., -1910296547,\n",
       "            1286965830,  1455235556],\n",
       "          [  686165600,  1311899724,  -290697633,  ...,   890669702,\n",
       "            -402992601,   302746207]]], dtype=torch.int32),\n",
       " 'model.layers.14.self_attn.o_proj.perm': tensor([ 510, 1275, 2034,  ..., 1373, 1360, 1370], dtype=torch.int16),\n",
       " 'model.layers.14.self_attn.o_proj.weight_bias': tensor([-2.9016e-04,  6.2048e-05,  2.4700e-04,  ...,  5.6148e-05,\n",
       "          9.7096e-05, -1.5891e-04], dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.o_proj.weight_scale': tensor([0.8818, 0.8735, 0.8691,  ..., 1.0410, 1.0176, 1.0391],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.q_proj.centroids.weight': tensor([[ 0.0217,  0.0036, -0.0149,  ..., -0.0088,  0.0006, -0.0026]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.q_proj.indices': tensor([[[-1497360333,  -301359146,  1582559035,  ..., -1255756015,\n",
       "            -881162323,   -74002784],\n",
       "          [ -163751075,    76438436,  -203732722,  ..., -1046034846,\n",
       "             287960188,  -957547268],\n",
       "          [ 1051767468,   637211836,  -466567260,  ...,  -438001772,\n",
       "           -1474637453,     5538667],\n",
       "          ...,\n",
       "          [  801845805,  1561031972,  -116276155,  ..., -1289646513,\n",
       "           -1825545919,   381821586],\n",
       "          [ 1446354680,   228341209, -2026559496,  ...,  -972822211,\n",
       "            -150006634,  1121875940],\n",
       "          [ 1032996789,   527398564, -1853816058,  ...,  -916789792,\n",
       "            1512860871,  -475460485]]], dtype=torch.int32),\n",
       " 'model.layers.14.self_attn.q_proj.perm': tensor([2789, 1076, 2158,  ..., 1946, 4062, 1415], dtype=torch.int16),\n",
       " 'model.layers.14.self_attn.q_proj.weight_bias': tensor([ 6.2847e-04, -2.8706e-04,  6.3705e-04,  ...,  2.5511e-05,\n",
       "          1.8024e-04, -4.8459e-05], dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.q_proj.weight_scale': tensor([1.5225, 1.5469, 1.5283,  ..., 1.5820, 1.5410, 1.5576],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.v_proj.centroids.weight': tensor([[-0.0019,  0.0021, -0.0102,  ...,  0.0021,  0.0361,  0.0050]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.v_proj.indices': tensor([[[ -658415268,   614478399,   628345956,  ...,   748775715,\n",
       "             444671801, -2031552151],\n",
       "          [ 1702317164, -1868911674,  -635058410,  ...,   700964115,\n",
       "            1204829253,  -268560144],\n",
       "          [ -742851375,  1765656927, -1428507445,  ..., -1750065786,\n",
       "            1153498362, -1125116792],\n",
       "          ...,\n",
       "          [-1760086551,  -421110163,   267292043,  ...,  1464007523,\n",
       "            1342762309,  -577419198],\n",
       "          [  697379593,  1949493198, -1501777909,  ...,  1485638543,\n",
       "             427009346,  -448867628],\n",
       "          [ 1923372074, -1107129293,   320567965,  ...,   885268928,\n",
       "            1099268141,   146921636]]], dtype=torch.int32),\n",
       " 'model.layers.14.self_attn.v_proj.perm': tensor([2789, 1076, 2158,  ..., 1946, 4062, 1415], dtype=torch.int16),\n",
       " 'model.layers.14.self_attn.v_proj.weight_bias': tensor([-0.0003, -0.0003,  0.0004,  ..., -0.0002,  0.0003,  0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.14.self_attn.v_proj.weight_scale': tensor([0.9678, 0.9136, 0.9575,  ..., 0.9863, 1.0068, 0.9868],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.input_layernorm.weight': tensor([0.4055, 0.4060, 0.3779,  ..., 0.3870, 0.3835, 0.3928],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.mlp.down_proj.centroids.weight': tensor([[ 0.0083, -0.0114, -0.0068,  ..., -0.0070,  0.0316,  0.0167]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.mlp.down_proj.indices': tensor([[[-1617680000,   837312627, -1024197457,  ..., -1378370992,\n",
       "            1509469923,   319417427],\n",
       "          [ -959641816,  -701480097,  -617778675,  ...,  -283687294,\n",
       "            2114227310,  -628815608],\n",
       "          [-1730231333, -1169622367, -1860811426,  ...,  1543118191,\n",
       "           -1259491704,  -976900165],\n",
       "          ...,\n",
       "          [-1535257886,   643493621,   772487577,  ..., -1551385166,\n",
       "             876206786,   146718733],\n",
       "          [-1420914663, -1331933167,  -629206767,  ...,  -653459265,\n",
       "           -1019731167,  2072174472],\n",
       "          [ 1810579761, -1505070692,  1706316278,  ...,  -640282037,\n",
       "             727737951,  1551854155]]], dtype=torch.int32),\n",
       " 'model.layers.15.mlp.down_proj.perm': tensor([3603, 6320, 4260,  ..., 4610, 9312, 6325], dtype=torch.int16),\n",
       " 'model.layers.15.mlp.down_proj.weight_bias': tensor([-2.3770e-04, -1.0914e-04, -2.7609e-04,  ..., -2.8551e-05,\n",
       "          3.7527e-04,  1.7655e-04], dtype=torch.float16),\n",
       " 'model.layers.15.mlp.down_proj.weight_scale': tensor([1.1855, 1.1748, 1.3145,  ..., 1.0596, 1.1104, 1.0850],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.mlp.gate_proj.centroids.weight': tensor([[ 0.0447,  0.0065, -0.0034,  ...,  0.0052,  0.0047, -0.0180]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.mlp.gate_proj.indices': tensor([[[ 1212113908,  1015358240,   179014848,  ...,  1883540817,\n",
       "           -1595563565, -1599885238],\n",
       "          [  554544679,    38811581,  1175468787,  ...,  -618332392,\n",
       "           -1673372526,  -472595128],\n",
       "          [-1851656020,   574194699, -1506128759,  ..., -1707270004,\n",
       "              79028145,   466843998],\n",
       "          ...,\n",
       "          [ 1223637373, -1519617680, -2041016452,  ...,  1219747812,\n",
       "             226154667,  1958683991],\n",
       "          [ -592744061,  1893014972, -1178245611,  ...,  1349133227,\n",
       "           -1689647243,  1879329997],\n",
       "          [ 1467376051,  1528374734, -1369120554,  ...,  -517262377,\n",
       "           -1524741479,  2118206589]]], dtype=torch.int32),\n",
       " 'model.layers.15.mlp.gate_proj.perm': tensor([2789, 4071, 2298,  ..., 3248, 2033, 3252], dtype=torch.int16),\n",
       " 'model.layers.15.mlp.gate_proj.weight_bias': tensor([-0.0009, -0.0007, -0.0012,  ...,  0.0004, -0.0014, -0.0006],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.mlp.gate_proj.weight_scale': tensor([2.0059, 2.0020, 2.0156,  ..., 2.0137, 2.0059, 2.0098],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.mlp.up_proj.centroids.weight': tensor([[-0.0202,  0.0072, -0.0017,  ..., -0.0089,  0.0079,  0.0050]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.mlp.up_proj.indices': tensor([[[-1811387738,  1188632358,    25783318,  ..., -1800795204,\n",
       "            -706121202,  -378593113],\n",
       "          [ 1152338459,  1131254535,  -282688417,  ...,  1685469882,\n",
       "           -1814178205, -1806048355],\n",
       "          [ 1346409808,  1238459781,  1674428795,  ...,   762236556,\n",
       "           -1180789849,  2002392286],\n",
       "          ...,\n",
       "          [  -12016370,   613652105,  1572183456,  ...,   603948146,\n",
       "            1257652806,  -263426057],\n",
       "          [ -342855777,  -849525237, -2028552913,  ...,   550918081,\n",
       "            -157967594,  2104318982],\n",
       "          [ -460329556,  -592737381,   687663666,  ..., -1533086494,\n",
       "           -2056259320,   674532605]]], dtype=torch.int32),\n",
       " 'model.layers.15.mlp.up_proj.perm': tensor([2789, 4071, 2298,  ..., 3248, 2033, 3252], dtype=torch.int16),\n",
       " 'model.layers.15.mlp.up_proj.weight_bias': tensor([ 1.2171e-04, -1.0359e-04, -3.2008e-05,  ...,  2.1160e-04,\n",
       "          1.0592e-04, -2.1768e-04], dtype=torch.float16),\n",
       " 'model.layers.15.mlp.up_proj.weight_scale': tensor([1.9619, 1.9521, 1.9424,  ..., 1.9580, 1.9688, 1.9512],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.post_attention_layernorm.weight': tensor([0.2886, 0.2776, 0.2781,  ..., 0.2883, 0.2871, 0.2881],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.k_proj.centroids.weight': tensor([[-0.0090, -0.0014, -0.0036,  ...,  0.0359,  0.0273,  0.0117]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.k_proj.indices': tensor([[[ 1081451915,  -241939929,  -273715110,  ..., -1578803733,\n",
       "           -1161265868,  -876399394],\n",
       "          [ -332778260, -2103232649,  1232726174,  ..., -1083271963,\n",
       "             852876226, -1484909715],\n",
       "          [   91488516,  1674313865,   708975360,  ...,   -72050841,\n",
       "             772217560, -1759850174],\n",
       "          ...,\n",
       "          [ -578826399,   423198119,  1530395894,  ..., -1043256649,\n",
       "              24946063, -1804951198],\n",
       "          [ -936313126, -1966107059,   457157462,  ..., -1458888858,\n",
       "            2063133993,  2097337920],\n",
       "          [ -801874791, -1092325093, -1974417162,  ...,   292459143,\n",
       "           -1616533074,    -4004870]]], dtype=torch.int32),\n",
       " 'model.layers.15.self_attn.k_proj.perm': tensor([2789, 1076, 3431,  ..., 4002, 1946, 1415], dtype=torch.int16),\n",
       " 'model.layers.15.self_attn.k_proj.weight_bias': tensor([-7.1907e-04,  8.9765e-05,  1.5917e-03,  ...,  4.9114e-05,\n",
       "          2.5482e-03, -6.7520e-04], dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.k_proj.weight_scale': tensor([1.6240, 1.5859, 1.5732,  ..., 1.5156, 1.5693, 1.5566],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.o_proj.centroids.weight': tensor([[-0.0094, -0.0054, -0.0092,  ..., -0.0191, -0.0052, -0.0329]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.o_proj.indices': tensor([[[ 1918837224, -1990912147, -1974145206,  ...,  1526829703,\n",
       "            -835645710,  1559300932],\n",
       "          [ -355556517, -1541120782,  1741646734,  ...,  1671101861,\n",
       "           -1775880837,   666972643],\n",
       "          [-2035972083,   107361292, -2110069612,  ..., -1844770473,\n",
       "             -64318334, -2109193018],\n",
       "          ...,\n",
       "          [ 1959152113,   448482846,   319511772,  ...,  1140520241,\n",
       "           -1863869398,   366037918],\n",
       "          [ -641360258,  1547814693,   138819509,  ...,   118415988,\n",
       "             660562722, -1749536488],\n",
       "          [-1129648608,  1238893528,  1629056279,  ...,  -875384290,\n",
       "            1479651792, -1258684154]]], dtype=torch.int32),\n",
       " 'model.layers.15.self_attn.o_proj.perm': tensor([1513, 1204, 1433,  ...,  102,  119,   16], dtype=torch.int16),\n",
       " 'model.layers.15.self_attn.o_proj.weight_bias': tensor([-5.0354e-04,  6.7890e-05, -1.4913e-04,  ...,  6.5804e-04,\n",
       "         -4.0698e-04, -9.5248e-05], dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.o_proj.weight_scale': tensor([1.0156, 1.0352, 0.9897,  ..., 0.9609, 0.9780, 0.9375],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.q_proj.centroids.weight': tensor([[ 0.0085,  0.0286,  0.0308,  ...,  0.0501, -0.0141,  0.1321]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.q_proj.indices': tensor([[[ 1908714951,  -230667944,  1816478644,  ...,    62034980,\n",
       "             452143899,  -403313289],\n",
       "          [ -273391123,  -719370768, -1898323426,  ...,    79517734,\n",
       "           -1705543265,  1661889303],\n",
       "          [ 2068599311, -1933622775, -1675329762,  ..., -1699901138,\n",
       "             938072858,  -637594170],\n",
       "          ...,\n",
       "          [  251085624,  1553907780,  -517381328,  ...,  1854998144,\n",
       "            1503877736,  1276038311],\n",
       "          [-1345479820,    34984345,   412636793,  ...,  -576246501,\n",
       "            -709743023,  -820376329],\n",
       "          [ -453838245,  -126463882,   596944504,  ...,  -407270986,\n",
       "           -1442832672,  -150573336]]], dtype=torch.int32),\n",
       " 'model.layers.15.self_attn.q_proj.perm': tensor([2789, 1076, 3431,  ..., 4002, 1946, 1415], dtype=torch.int16),\n",
       " 'model.layers.15.self_attn.q_proj.weight_bias': tensor([ 1.1959e-03,  2.5311e-03,  4.2963e-04,  ...,  8.2254e-06,\n",
       "         -7.3242e-04, -9.7132e-04], dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.q_proj.weight_scale': tensor([1.4922, 1.5400, 1.4844,  ..., 1.5244, 1.5264, 1.5410],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.v_proj.centroids.weight': tensor([[-0.0248,  0.0144,  0.0204,  ...,  0.0024, -0.0085,  0.0164]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.v_proj.indices': tensor([[[  603506515,   803255210,  1688730937,  ...,  -283065492,\n",
       "            1602346867, -1309163647],\n",
       "          [  141899426,   449839293,  1057611331,  ...,  -935552709,\n",
       "           -1905978941,  1303779811],\n",
       "          [  287194936, -1456358420, -1095236405,  ...,  1744244414,\n",
       "             -12001101,   330242296],\n",
       "          ...,\n",
       "          [  762133770,  1045593144,  -489122877,  ...,  1543810620,\n",
       "             989101848,   519975781],\n",
       "          [-1273051636,  1762624197,   304848819,  ...,  -644396419,\n",
       "           -2098640537,   696888263],\n",
       "          [-1455163883,  -123212660,  1928126787,  ..., -1223558453,\n",
       "            -726474803,  1233170403]]], dtype=torch.int32),\n",
       " 'model.layers.15.self_attn.v_proj.perm': tensor([2789, 1076, 3431,  ..., 4002, 1946, 1415], dtype=torch.int16),\n",
       " 'model.layers.15.self_attn.v_proj.weight_bias': tensor([-1.8704e-04, -1.5426e-04, -2.3258e-04,  ..., -1.1337e-04,\n",
       "          5.6267e-05, -2.7001e-05], dtype=torch.float16),\n",
       " 'model.layers.15.self_attn.v_proj.weight_scale': tensor([1.0156, 0.9731, 0.9819,  ..., 1.0391, 1.0244, 0.9839],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.input_layernorm.weight': tensor([0.4197, 0.4189, 0.3926,  ..., 0.3745, 0.4104, 0.4080],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.mlp.down_proj.centroids.weight': tensor([[-0.0459, -0.0077, -0.0005,  ...,  0.0009, -0.0198,  0.0021]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.mlp.down_proj.indices': tensor([[[ 1688652596,   486993525,   349196919,  ...,  1505808088,\n",
       "             905296225,  1253073505],\n",
       "          [ 1987774768,  2121125563, -1798967237,  ..., -2137818197,\n",
       "            1415506447,  1086290075],\n",
       "          [ 1670302900,  -517080131,   897282975,  ...,  -608454903,\n",
       "            2110687861,   775716428],\n",
       "          ...,\n",
       "          [  673397165,   957614899,   832621319,  ...,  1635262413,\n",
       "            1548433810,  -853015923],\n",
       "          [ 1679199177,   721603237, -1914580202,  ...,   914079006,\n",
       "             181812288,  1409805045],\n",
       "          [ 1062986848,  -949080009,   808763771,  ...,  1059241249,\n",
       "           -1885457753,   906232264]]], dtype=torch.int32),\n",
       " 'model.layers.16.mlp.down_proj.perm': tensor([ 7117,  3415, 10884,  ...,  6328,  2136,  4467], dtype=torch.int16),\n",
       " 'model.layers.16.mlp.down_proj.weight_bias': tensor([ 4.9889e-05, -3.2902e-04,  2.5201e-04,  ..., -2.8396e-04,\n",
       "         -5.7817e-06,  4.4131e-04], dtype=torch.float16),\n",
       " 'model.layers.16.mlp.down_proj.weight_scale': tensor([1.1914, 1.0645, 1.1523,  ..., 1.1367, 0.9214, 1.3193],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.mlp.gate_proj.centroids.weight': tensor([[-0.0140,  0.0011, -0.0013,  ..., -0.0064, -0.0216, -0.0067]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.mlp.gate_proj.indices': tensor([[[ -208537712,  -511834644,  -745961335,  ..., -1609408357,\n",
       "           -1184750718,  -649308992],\n",
       "          [ -753219603, -1236681200, -1508592813,  ..., -1106888735,\n",
       "             436861424,   184183381],\n",
       "          [-1479932790,   337885096,  -985118588,  ..., -1235590253,\n",
       "             902104998,  1511125600],\n",
       "          ...,\n",
       "          [-1852787929,   559556480, -1181340325,  ..., -1713757239,\n",
       "            1675283260, -1886801357],\n",
       "          [ -172123162,  1164487035,   172381902,  ...,  1852038001,\n",
       "            -736702783,  -841251737],\n",
       "          [   13861422,   420122671, -1876358382,  ..., -1269438793,\n",
       "            1071290931,  1374812211]]], dtype=torch.int32),\n",
       " 'model.layers.16.mlp.gate_proj.perm': tensor([2789, 2927, 4071,  ..., 3380,  301, 3955], dtype=torch.int16),\n",
       " 'model.layers.16.mlp.gate_proj.weight_bias': tensor([-4.6635e-04, -5.4312e-04, -7.7784e-05,  ...,  1.1902e-03,\n",
       "         -2.4261e-03, -1.2312e-03], dtype=torch.float16),\n",
       " 'model.layers.16.mlp.gate_proj.weight_scale': tensor([2.0059, 2.0098, 2.0391,  ..., 2.0234, 2.0410, 2.0059],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.mlp.up_proj.centroids.weight': tensor([[ 0.0004, -0.0123,  0.0054,  ...,  0.0056, -0.0088, -0.0070]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.mlp.up_proj.indices': tensor([[[  578177924,  -156720051,   535506352,  ...,  -713835286,\n",
       "           -2004213831,  1819183022],\n",
       "          [ -223756748,  1363550817, -1447195621,  ...,  -379738214,\n",
       "           -1303020015,  1959715151],\n",
       "          [-1609136061, -1041515913, -2131623379,  ...,  -663187589,\n",
       "           -2100231269,  2098729269],\n",
       "          ...,\n",
       "          [ 1386461082,   633756996,  1194212167,  ...,  -223218553,\n",
       "           -1491685777,  1309268168],\n",
       "          [-1832014044,  -536716102,  -134368562,  ...,  -596926106,\n",
       "           -1931296206, -1208542136],\n",
       "          [ -170012794,   896466869,   370993980,  ...,  1206775780,\n",
       "           -1163563607,  -640388353]]], dtype=torch.int32),\n",
       " 'model.layers.16.mlp.up_proj.perm': tensor([2789, 2927, 4071,  ..., 3380,  301, 3955], dtype=torch.int16),\n",
       " 'model.layers.16.mlp.up_proj.weight_bias': tensor([-4.6492e-06, -3.7766e-04,  2.2340e-04,  ...,  4.1032e-04,\n",
       "         -8.2612e-05, -3.3355e-04], dtype=torch.float16),\n",
       " 'model.layers.16.mlp.up_proj.weight_scale': tensor([1.9756, 1.9492, 1.9297,  ..., 1.9600, 1.9492, 1.9561],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.post_attention_layernorm.weight': tensor([0.3069, 0.2878, 0.2966,  ..., 0.3074, 0.3135, 0.2971],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.k_proj.centroids.weight': tensor([[-0.0260,  0.0035, -0.0030,  ..., -0.0016, -0.0119, -0.0087]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.k_proj.indices': tensor([[[ 1543725586,   663996399, -1361838500,  ...,  -887658651,\n",
       "             405864466,  1810846891],\n",
       "          [  351876054,  1406561737,  -752809257,  ...,  2040863181,\n",
       "           -1310583630, -1775685667],\n",
       "          [ 1277364333,  -660541512,  1817074934,  ..., -1301128521,\n",
       "             206773068,  1095014239],\n",
       "          ...,\n",
       "          [ 1858606856,  1584404976, -1741010151,  ...,   686931375,\n",
       "            1861025351, -1167954515],\n",
       "          [ 1192784735,  1102861797,  -251290643,  ...,  -765180301,\n",
       "            -886540329,  1892639037],\n",
       "          [-1343338116,   391256742,    68748499,  ..., -1068740005,\n",
       "            -255297488, -1933466497]]], dtype=torch.int32),\n",
       " 'model.layers.16.self_attn.k_proj.perm': tensor([2789, 1076, 3209,  ..., 3130, 1946, 1415], dtype=torch.int16),\n",
       " 'model.layers.16.self_attn.k_proj.weight_bias': tensor([-0.0001,  0.0017,  0.0012,  ...,  0.0022,  0.0031, -0.0012],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.k_proj.weight_scale': tensor([1.5967, 1.5889, 1.5498,  ..., 1.5068, 1.5244, 1.5586],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.o_proj.centroids.weight': tensor([[ 0.0430,  0.0137, -0.0072,  ..., -0.0111,  0.0311,  0.0013]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.o_proj.indices': tensor([[[-1131407279,  2027837927,  -887609208,  ..., -1997472406,\n",
       "           -1215536791, -1764295196],\n",
       "          [ 1030978610,   730658577,   642008312,  ...,  -360074618,\n",
       "             322575647, -1414895906],\n",
       "          [ 1868159484, -1378776406,   861265752,  ...,   -64968957,\n",
       "            -796949531,   608473465],\n",
       "          ...,\n",
       "          [  -99889852, -1597880885,  1309014587,  ...,   -27185094,\n",
       "           -1300109410,  -445372633],\n",
       "          [ 1987626961,   717644667,   920646011,  ...,  1076641367,\n",
       "            -125671276, -1350307704],\n",
       "          [-1788605564,  -383554518,  1295947934,  ...,  -800029072,\n",
       "            1025283510, -1790322710]]], dtype=torch.int32),\n",
       " 'model.layers.16.self_attn.o_proj.perm': tensor([ 840, 1829,  375,  ..., 3353, 3367, 3415], dtype=torch.int16),\n",
       " 'model.layers.16.self_attn.o_proj.weight_bias': tensor([-9.7871e-05,  3.8099e-04, -1.4198e-04,  ...,  2.6131e-04,\n",
       "         -1.2326e-04,  2.7013e-04], dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.o_proj.weight_scale': tensor([1.2617, 1.1992, 1.2510,  ..., 1.0479, 1.0518, 1.0586],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.q_proj.centroids.weight': tensor([[-0.0044, -0.0162,  0.0098,  ..., -0.0338, -0.0180,  0.0013]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.q_proj.indices': tensor([[[  -52474281, -1136432345, -1386648753,  ...,  1454082025,\n",
       "           -1912808766,  1386205376],\n",
       "          [-1047935343, -1533543922, -1518582858,  ..., -1566717268,\n",
       "           -1109115204,  1246049617],\n",
       "          [ -766938644, -1974321730, -1730264248,  ...,  -300692479,\n",
       "            -609009173,  2061935825],\n",
       "          ...,\n",
       "          [-1593003513,  -997925532, -1613740896,  ...,    56074538,\n",
       "            1890173535,  2015840606],\n",
       "          [ -522105720,   172983951,  1354262632,  ..., -1218157015,\n",
       "           -1247650221,   292780252],\n",
       "          [ 2108898101,  1127603474, -1530732394,  ...,   -85252667,\n",
       "            1121203018,  -473966954]]], dtype=torch.int32),\n",
       " 'model.layers.16.self_attn.q_proj.perm': tensor([2789, 1076, 3209,  ..., 3130, 1946, 1415], dtype=torch.int16),\n",
       " 'model.layers.16.self_attn.q_proj.weight_bias': tensor([-9.7370e-04, -6.5660e-04,  4.5419e-05,  ..., -3.4451e-04,\n",
       "          1.6832e-04, -2.0278e-04], dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.q_proj.weight_scale': tensor([1.4893, 1.4785, 1.4648,  ..., 1.4854, 1.5225, 1.4902],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.v_proj.centroids.weight': tensor([[ 0.0340, -0.0029, -0.0140,  ..., -0.0047,  0.0091, -0.0236]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.v_proj.indices': tensor([[[ 1124515920,  -820306306, -1893763336,  ...,  1412965196,\n",
       "             403653248, -1409004083],\n",
       "          [    4943239,   386673575,  -532034271,  ..., -1982766821,\n",
       "            2007436124,   -96840729],\n",
       "          [-1974926078,   995939158,  1798926443,  ...,   892393039,\n",
       "            1255863979,   -41338752],\n",
       "          ...,\n",
       "          [ -475213196,   711661170,  -380508676,  ..., -1711370046,\n",
       "             435961424,  1938893091],\n",
       "          [  -17396590,  -291285244,  1338293574,  ...,  -617073240,\n",
       "            1256983854,   783322259],\n",
       "          [ -337206983,  2092866219,  1854011760,  ...,  2051162895,\n",
       "            1881070745,  -479996004]]], dtype=torch.int32),\n",
       " 'model.layers.16.self_attn.v_proj.perm': tensor([2789, 1076, 3209,  ..., 3130, 1946, 1415], dtype=torch.int16),\n",
       " 'model.layers.16.self_attn.v_proj.weight_bias': tensor([ 2.2113e-04, -4.3440e-04,  2.3365e-04,  ..., -3.6895e-05,\n",
       "          5.3108e-05,  2.2233e-04], dtype=torch.float16),\n",
       " 'model.layers.16.self_attn.v_proj.weight_scale': tensor([1.0752, 1.0195, 1.0693,  ..., 1.0840, 1.0518, 1.0459],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.input_layernorm.weight': tensor([0.4226, 0.4294, 0.4016,  ..., 0.4285, 0.4319, 0.3984],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.mlp.down_proj.centroids.weight': tensor([[ 0.0284, -0.0054, -0.0202,  ...,  0.0119, -0.0327,  0.0134]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.mlp.down_proj.indices': tensor([[[ 1201210060,  1257110443,  1557615609,  ...,  -743349696,\n",
       "            1873923024,   218437747],\n",
       "          [ 1156472117,   978718217,  1201649626,  ...,    -6696305,\n",
       "           -2112778564,     5424445],\n",
       "          [ 1825543975,  1868615498, -1044217655,  ...,   330066914,\n",
       "             791355441,  1189519308],\n",
       "          ...,\n",
       "          [-1043311672,  -500832699, -1840950765,  ...,  -789518433,\n",
       "           -1854710618, -1186778418],\n",
       "          [  337024564,  -977122142,   659803995,  ...,  -139950645,\n",
       "            1316276042, -1185200005],\n",
       "          [  328797203, -1687556258,  -247839851,  ...,  1509250330,\n",
       "            -362525287,  -809630237]]], dtype=torch.int32),\n",
       " 'model.layers.17.mlp.down_proj.perm': tensor([  331,  6057, 10512,  ...,  5542,  1096,  6203], dtype=torch.int16),\n",
       " 'model.layers.17.mlp.down_proj.weight_bias': tensor([ 0.0002, -0.0001,  0.0003,  ...,  0.0001, -0.0002, -0.0006],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.mlp.down_proj.weight_scale': tensor([1.1475, 1.1436, 1.1123,  ..., 1.1611, 1.1973, 1.1016],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.mlp.gate_proj.centroids.weight': tensor([[ 0.0163,  0.0157, -0.0060,  ...,  0.0193, -0.0068,  0.0044]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.mlp.gate_proj.indices': tensor([[[ -261784456,  1213670114,   677569605,  ..., -1975305111,\n",
       "           -1094396626,  -307495311],\n",
       "          [ 1009664179,  1091308804,  -117226996,  ..., -1478595809,\n",
       "            1049089689,   352591587],\n",
       "          [  803419278, -1643751548,   593472374,  ..., -2130536159,\n",
       "             -54509023,  2027709760],\n",
       "          ...,\n",
       "          [-1482395670,  -406586542, -2030312692,  ...,  1445489511,\n",
       "            2055630784, -1661748575],\n",
       "          [ 1715249483,   574502613,  -716104449,  ...,  1293078269,\n",
       "           -1084805508,  1525099304],\n",
       "          [  567365921, -2111742846,   620880222,  ...,   227012941,\n",
       "              39942347,   250325372]]], dtype=torch.int32),\n",
       " 'model.layers.17.mlp.gate_proj.perm': tensor([4071, 2927, 2469,  ..., 3130, 3497,  623], dtype=torch.int16),\n",
       " 'model.layers.17.mlp.gate_proj.weight_bias': tensor([-1.5173e-03,  2.4199e-05, -7.9274e-05,  ...,  1.3885e-03,\n",
       "         -1.0843e-03, -1.9779e-03], dtype=torch.float16),\n",
       " 'model.layers.17.mlp.gate_proj.weight_scale': tensor([2.0195, 2.0352, 2.0508,  ..., 2.0566, 2.0352, 2.0176],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.mlp.up_proj.centroids.weight': tensor([[-0.0038, -0.0068, -0.0042,  ..., -0.0041,  0.0070,  0.0003]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.mlp.up_proj.indices': tensor([[[ 1660103845,  2038673511,  1304930183,  ..., -2015358912,\n",
       "            -852913844,  -957895975],\n",
       "          [  908377332,   933706386, -1752573858,  ..., -2136668385,\n",
       "           -1084933243,   152156950],\n",
       "          [-1778264848, -1580745829,  1012350474,  ...,  -982159520,\n",
       "             468566709,  2139057796],\n",
       "          ...,\n",
       "          [ 1700041573, -1541302013,  1785512710,  ...,  -688091071,\n",
       "           -1227641085,  1810946834],\n",
       "          [ -198675881, -1315827419,  -405444710,  ...,  -702309946,\n",
       "            2014394468, -1622270837],\n",
       "          [ 1617340433, -1007404077,    69335157,  ...,  1309473470,\n",
       "           -1533858005,  1660847521]]], dtype=torch.int32),\n",
       " 'model.layers.17.mlp.up_proj.perm': tensor([4071, 2927, 2469,  ..., 3130, 3497,  623], dtype=torch.int16),\n",
       " 'model.layers.17.mlp.up_proj.weight_bias': tensor([-2.3496e-04, -2.4581e-04, -1.3590e-04,  ...,  9.6381e-05,\n",
       "          1.5903e-04,  3.4356e-04], dtype=torch.float16),\n",
       " 'model.layers.17.mlp.up_proj.weight_scale': tensor([1.9668, 1.9521, 1.9395,  ..., 1.9375, 1.9639, 1.9590],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.post_attention_layernorm.weight': tensor([0.3223, 0.3154, 0.3186,  ..., 0.3289, 0.3298, 0.3137],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.k_proj.centroids.weight': tensor([[-0.0017,  0.0079, -0.0013,  ...,  0.0139,  0.0323, -0.0041]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.k_proj.indices': tensor([[[ -172221503,  -416822131,   235928701,  ...,   690041174,\n",
       "            -205153373,  -862987296],\n",
       "          [  343045319,  1981105882,   370073970,  ...,  1392757234,\n",
       "            -225518637,  -729819548],\n",
       "          [ 1132557657,    56654433,  1085601524,  ...,   571870964,\n",
       "            -566201651,  -864411178],\n",
       "          ...,\n",
       "          [  965619235,  -128532687,   707536527,  ..., -1228772989,\n",
       "            1711987267, -1618743908],\n",
       "          [ 1670399842,  -461954882,   262495853,  ...,   193854552,\n",
       "           -1075300320,  -645910297],\n",
       "          [ 1656982213,  2110306338,  1903868852,  ..., -1604803903,\n",
       "            1405833046,  1266610597]]], dtype=torch.int32),\n",
       " 'model.layers.17.self_attn.k_proj.perm': tensor([1076, 2789, 3209,  ...,  951, 1946, 1415], dtype=torch.int16),\n",
       " 'model.layers.17.self_attn.k_proj.weight_bias': tensor([-0.0010, -0.0009,  0.0009,  ...,  0.0009,  0.0019, -0.0013],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.k_proj.weight_scale': tensor([1.5645, 1.5967, 1.5176,  ..., 1.4990, 1.5225, 1.5254],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.o_proj.centroids.weight': tensor([[-0.0097, -0.0168,  0.0296,  ..., -0.0375,  0.0120, -0.0126]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.o_proj.indices': tensor([[[ -946659471,  1721218165,  1407541441,  ..., -1219145933,\n",
       "              22978324,   633478499],\n",
       "          [  727702044, -1340567390,  2125766007,  ...,  -314051322,\n",
       "             632546639, -1899446100],\n",
       "          [ 2145635042,   980473192, -1809612757,  ..., -1988234360,\n",
       "           -1854898745,  -343657287],\n",
       "          ...,\n",
       "          [-1170648616,  1733385979,   593788054,  ...,  -824645852,\n",
       "           -1950414876,  1376899197],\n",
       "          [-2054102421,  1162369481, -1473351448,  ...,  2060273242,\n",
       "             796077872, -1552853199],\n",
       "          [ -369852616,  -914682967,  1894696114,  ...,  1554781642,\n",
       "            2093633576,   444038612]]], dtype=torch.int32),\n",
       " 'model.layers.17.self_attn.o_proj.perm': tensor([1832,  503, 1382,  ..., 2978, 3012, 3001], dtype=torch.int16),\n",
       " 'model.layers.17.self_attn.o_proj.weight_bias': tensor([ 4.5538e-05,  2.3532e-04, -2.7657e-04,  ..., -1.2970e-04,\n",
       "          2.5344e-04, -5.2309e-04], dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.o_proj.weight_scale': tensor([1.0059, 1.0322, 0.9561,  ..., 1.0049, 0.9751, 1.0107],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.q_proj.centroids.weight': tensor([[ 0.0112,  0.0212,  0.0069,  ..., -0.0087,  0.0050,  0.0004]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.q_proj.indices': tensor([[[-1586974528,  -106375299,  -985189443,  ...,  1003827275,\n",
       "           -1376254789,  1846384249],\n",
       "          [ -561244537,  1413150755,   704529189,  ...,  -369771591,\n",
       "             -11178784,  -644722379],\n",
       "          [ 1162799219,  1752102307,  1795469649,  ...,  -830180663,\n",
       "             789340477,  -644845049],\n",
       "          ...,\n",
       "          [  102856679, -1727078798,  1607865531,  ...,  1124412114,\n",
       "           -1316004991, -1314226412],\n",
       "          [ 1341230392,   758077515,   977326623,  ...,  -380002297,\n",
       "            -661798307,    94642247],\n",
       "          [ -508233185,  -182730479, -1979434144,  ...,  1478523669,\n",
       "             581702770,  -981368393]]], dtype=torch.int32),\n",
       " 'model.layers.17.self_attn.q_proj.perm': tensor([1076, 2789, 3209,  ...,  951, 1946, 1415], dtype=torch.int16),\n",
       " 'model.layers.17.self_attn.q_proj.weight_bias': tensor([ 0.0017, -0.0006, -0.0016,  ..., -0.0005, -0.0003,  0.0024],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.q_proj.weight_scale': tensor([1.4766, 1.4717, 1.4697,  ..., 1.5186, 1.5381, 1.4844],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.v_proj.centroids.weight': tensor([[ 0.0051,  0.0140, -0.0088,  ...,  0.0065,  0.0302,  0.0174]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.v_proj.indices': tensor([[[  872212504, -2129263409, -1471857279,  ..., -1458237282,\n",
       "            1154949083,   457182021],\n",
       "          [  823548806, -1965681696,  2107535885,  ...,   336075127,\n",
       "           -1372466052,    55876550],\n",
       "          [ -253337417,  1152778464,  1965730937,  ...,  1714640278,\n",
       "           -1298201475,  -620563395],\n",
       "          ...,\n",
       "          [ 1109132250, -1639790098,  1550718543,  ..., -1989222608,\n",
       "            -849088212,  -130067765],\n",
       "          [  -75955176,  1767513581,  1443875290,  ...,  -105331784,\n",
       "            -121278868,  -655329024],\n",
       "          [-1500638289,  -829199479,  -979128369,  ..., -1819107272,\n",
       "             765652266, -1921154657]]], dtype=torch.int32),\n",
       " 'model.layers.17.self_attn.v_proj.perm': tensor([1076, 2789, 3209,  ...,  951, 1946, 1415], dtype=torch.int16),\n",
       " 'model.layers.17.self_attn.v_proj.weight_bias': tensor([-0.0004,  0.0004,  0.0004,  ...,  0.0002, -0.0003,  0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.17.self_attn.v_proj.weight_scale': tensor([1.0322, 1.0000, 1.0791,  ..., 1.0430, 1.0684, 1.0518],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.input_layernorm.weight': tensor([0.4487, 0.4492, 0.4375,  ..., 0.4263, 0.4453, 0.4243],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.mlp.down_proj.centroids.weight': tensor([[0.0076, 0.0021, 0.0252,  ..., 0.0083, 0.0213, 0.0085]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.mlp.down_proj.indices': tensor([[[  640367352,  -759480358, -1075590881,  ...,  1474503242,\n",
       "             772056860,  1124334350],\n",
       "          [ 1762528156,   376443102,   822684578,  ...,   425148466,\n",
       "            1522132104,  -478289801],\n",
       "          [  442895646, -1256604029,  1880543339,  ...,    21829363,\n",
       "            1590387952,   789883969],\n",
       "          ...,\n",
       "          [-2098125929,  -804468291,  -631949296,  ...,   783759909,\n",
       "           -1151004915,   161541634],\n",
       "          [ -548184374, -1775983310,  1185713408,  ..., -1240118699,\n",
       "           -1243658052, -1958374709],\n",
       "          [-1063260699, -1185545986,  1944903473,  ..., -2027785494,\n",
       "            -830492465,  -479364051]]], dtype=torch.int32),\n",
       " 'model.layers.18.mlp.down_proj.perm': tensor([5324, 2676, 4818,  ..., 5027, 1822, 1476], dtype=torch.int16),\n",
       " 'model.layers.18.mlp.down_proj.weight_bias': tensor([ 9.6858e-05,  6.2227e-04,  2.4819e-04,  ..., -1.6332e-04,\n",
       "          2.5892e-04,  2.1791e-04], dtype=torch.float16),\n",
       " 'model.layers.18.mlp.down_proj.weight_scale': tensor([1.1660, 1.2344, 1.1797,  ..., 1.1865, 1.1855, 1.1885],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.mlp.gate_proj.centroids.weight': tensor([[-0.0083, -0.0025,  0.0045,  ...,  0.0030,  0.0038,  0.0129]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.mlp.gate_proj.indices': tensor([[[ -749423730,  1166238938,  1390842250,  ...,  1433227489,\n",
       "             861421439,   261562808],\n",
       "          [  991607566,  1326817564,  1552568452,  ..., -1610087948,\n",
       "             803560688, -1230966270],\n",
       "          [-1985840367,  1554516293, -1679431361,  ...,  -569711380,\n",
       "            1745811469,  -838927437],\n",
       "          ...,\n",
       "          [   55623052, -1820433390, -1337732417,  ..., -2134811386,\n",
       "            1809344456,  1413119704],\n",
       "          [ 1511363230,  2020789219, -2032077317,  ...,   -69719775,\n",
       "            -515133304,  -741625796],\n",
       "          [ -421276462,  1301029098,   859569319,  ...,  -501282612,\n",
       "             138708682,  1592593951]]], dtype=torch.int32),\n",
       " 'model.layers.18.mlp.gate_proj.perm': tensor([1512, 4071, 2927,  ..., 3497, 3130, 1794], dtype=torch.int16),\n",
       " 'model.layers.18.mlp.gate_proj.weight_bias': tensor([-2.5215e-03, -6.3956e-05,  3.2210e-04,  ...,  9.4128e-04,\n",
       "         -2.2812e-03, -4.4870e-04], dtype=torch.float16),\n",
       " 'model.layers.18.mlp.gate_proj.weight_scale': tensor([2.0332, 2.0469, 2.0547,  ..., 2.0723, 2.0488, 2.0566],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.mlp.up_proj.centroids.weight': tensor([[-0.0046, -0.0058, -0.0167,  ..., -0.0035,  0.0080, -0.0100]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.mlp.up_proj.indices': tensor([[[ 1086375348,  1606588493, -1268650440,  ...,  -981152468,\n",
       "           -1060408230, -1454938549],\n",
       "          [  629545923,   831693648,   188412490,  ...,   233502154,\n",
       "            1034089722,  -348678530],\n",
       "          [   57310168, -1692870042,  1707902208,  ..., -1442954566,\n",
       "             296144926, -1783263272],\n",
       "          ...,\n",
       "          [  529042148,  -662080185,   900315811,  ...,  -499239642,\n",
       "            1944419591,   637670039],\n",
       "          [ 1047136962, -2019181577, -2097863007,  ..., -1313978141,\n",
       "             208407982,  -819883177],\n",
       "          [  -88556821,  1688516030, -1685617510,  ...,   959318752,\n",
       "            -101942241, -1539964252]]], dtype=torch.int32),\n",
       " 'model.layers.18.mlp.up_proj.perm': tensor([1512, 4071, 2927,  ..., 3497, 3130, 1794], dtype=torch.int16),\n",
       " 'model.layers.18.mlp.up_proj.weight_bias': tensor([ 1.0121e-04,  1.0365e-04, -1.2803e-04,  ...,  4.3321e-04,\n",
       "         -7.3135e-05, -4.5300e-04], dtype=torch.float16),\n",
       " 'model.layers.18.mlp.up_proj.weight_scale': tensor([1.9521, 1.9609, 1.9434,  ..., 1.9424, 1.9531, 1.9404],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.post_attention_layernorm.weight': tensor([0.3408, 0.3372, 0.3347,  ..., 0.3438, 0.3442, 0.3379],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.k_proj.centroids.weight': tensor([[ 0.0336,  0.0175, -0.0288,  ...,  0.0047,  0.0145,  0.0222]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.k_proj.indices': tensor([[[  359356447,  1533044459, -1290406252,  ..., -1381443320,\n",
       "            -126272340,   383180398],\n",
       "          [-1135157466,  -196005201,  1608749775,  ...,  -680821862,\n",
       "            2083890036,   262948537],\n",
       "          [ -806382069,  -444586009,   511440951,  ...,   977343553,\n",
       "            1747410642, -1031928088],\n",
       "          ...,\n",
       "          [  -16218088,  -353540910, -1922552843,  ...,  -819414346,\n",
       "             956635021,  -497455987],\n",
       "          [-1816596125,  1359487117,  1011306031,  ...,  1234399495,\n",
       "           -1552120427,   969631055],\n",
       "          [   10186802, -1684173563, -1584702852,  ...,  -652410763,\n",
       "             660067567,  1009643911]]], dtype=torch.int32),\n",
       " 'model.layers.18.self_attn.k_proj.perm': tensor([1076, 2789, 3209,  ..., 3709, 3130, 1415], dtype=torch.int16),\n",
       " 'model.layers.18.self_attn.k_proj.weight_bias': tensor([ 0.0013,  0.0003, -0.0015,  ...,  0.0012, -0.0014,  0.0015],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.k_proj.weight_scale': tensor([1.5293, 1.5410, 1.4736,  ..., 1.4971, 1.4707, 1.4473],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.o_proj.centroids.weight': tensor([[-0.0171, -0.0298,  0.0284,  ...,  0.0091, -0.0056, -0.0134]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.o_proj.indices': tensor([[[-1341891830,  1629045346,  -217878609,  ...,   872567544,\n",
       "           -1531612326,  1927407524],\n",
       "          [ -496479194,  -915040787,  2008143809,  ...,  -315655428,\n",
       "           -1428644512,  -894263719],\n",
       "          [   46085255,  1398446167, -1375452460,  ...,  1634498831,\n",
       "             -61620868,  -215825261],\n",
       "          ...,\n",
       "          [ -152459280,   305217375, -2025378151,  ..., -1617696232,\n",
       "             706742600,  -240468029],\n",
       "          [-1178355298,   459435520, -1743354694,  ...,  2001703311,\n",
       "            1771654282,   -84384053],\n",
       "          [ -241681103,  1000381504, -1315959400,  ..., -1174154521,\n",
       "           -1333393147,  -867575269]]], dtype=torch.int32),\n",
       " 'model.layers.18.self_attn.o_proj.perm': tensor([ 654, 1358,  639,  ..., 3724, 3788, 3731], dtype=torch.int16),\n",
       " 'model.layers.18.self_attn.o_proj.weight_bias': tensor([ 4.1509e-04,  1.6665e-04, -3.4750e-05,  ...,  2.3854e-04,\n",
       "          5.1117e-04,  8.5890e-05], dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.o_proj.weight_scale': tensor([1.1787, 1.1875, 1.1768,  ..., 0.9736, 0.9873, 1.0059],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.q_proj.centroids.weight': tensor([[ 0.0599,  0.0106, -0.0071,  ..., -0.0020,  0.0128,  0.0305]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.q_proj.indices': tensor([[[-1810266580,  -129549373,   765583293,  ...,  -748615086,\n",
       "            1809145637,  1745378442],\n",
       "          [ 1623806813,  1963459804,    28652016,  ...,   242797506,\n",
       "            1988231425,  -912616580],\n",
       "          [-1385396141,  2110498107,  1648446004,  ..., -1215926110,\n",
       "             725642826, -1842730847],\n",
       "          ...,\n",
       "          [   17160097,   394513069,   385722888,  ..., -1931491220,\n",
       "            1752853492,   456137461],\n",
       "          [-1018304896,  1394150113,  -541798909,  ..., -1715091423,\n",
       "            1531991034,  -629053756],\n",
       "          [ -886579328,   192089256,  -579986154,  ...,  -155998626,\n",
       "            -985826682,   135272432]]], dtype=torch.int32),\n",
       " 'model.layers.18.self_attn.q_proj.perm': tensor([1076, 2789, 3209,  ..., 3709, 3130, 1415], dtype=torch.int16),\n",
       " 'model.layers.18.self_attn.q_proj.weight_bias': tensor([ 6.9571e-04,  3.7527e-04, -2.3537e-03,  ..., -1.5192e-03,\n",
       "          1.1148e-03,  4.7088e-05], dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.q_proj.weight_scale': tensor([1.4492, 1.4941, 1.4873,  ..., 1.4414, 1.4707, 1.4609],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.v_proj.centroids.weight': tensor([[ 0.0009, -0.0016,  0.0077,  ...,  0.0221, -0.0056, -0.0087]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.v_proj.indices': tensor([[[  995991111,  -458417264, -1475009546,  ...,  -516201288,\n",
       "           -1778411351,  1832685924],\n",
       "          [  445150801,  1856345913, -1375576573,  ...,   690333674,\n",
       "           -2019114937,  1311570698],\n",
       "          [  691292874, -2025531753,  1839456815,  ..., -2037918144,\n",
       "             176458646,  -303386349],\n",
       "          ...,\n",
       "          [-1047142529, -1958785491, -1641426693,  ...,  -944913951,\n",
       "           -1210608346, -1665488743],\n",
       "          [ -176572370,  -477618406,  1502422616,  ...,   779854935,\n",
       "            -512559510, -1451022636],\n",
       "          [  362629591, -1503964843,   529761883,  ...,   234443875,\n",
       "           -1079826964,   672551399]]], dtype=torch.int32),\n",
       " 'model.layers.18.self_attn.v_proj.perm': tensor([1076, 2789, 3209,  ..., 3709, 3130, 1415], dtype=torch.int16),\n",
       " 'model.layers.18.self_attn.v_proj.weight_bias': tensor([-3.6025e-04,  2.7966e-04,  5.9009e-05,  ...,  4.0817e-04,\n",
       "          4.9305e-04, -3.0231e-04], dtype=torch.float16),\n",
       " 'model.layers.18.self_attn.v_proj.weight_scale': tensor([1.0615, 1.0361, 1.0967,  ..., 1.1279, 1.1133, 1.1201],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.input_layernorm.weight': tensor([0.4548, 0.4626, 0.4419,  ..., 0.4304, 0.4312, 0.4360],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.mlp.down_proj.centroids.weight': tensor([[ 0.0073,  0.0003,  0.0058,  ..., -0.0118, -0.0041,  0.0187]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.mlp.down_proj.indices': tensor([[[  643258375,  1842953039, -1899753988,  ...,  -737950089,\n",
       "           -1761632764,   357678809],\n",
       "          [ -819891201,  2080160002,  -882854478,  ..., -1964875177,\n",
       "            1518567463,    95912913],\n",
       "          [ -822774399,  1854069184, -1091943421,  ...,  -863654705,\n",
       "           -1035741198, -2124359977],\n",
       "          ...,\n",
       "          [  -88229179,  -318833004,  1289113318,  ...,  1076337895,\n",
       "             809457609, -1496672338],\n",
       "          [ -153124574,  1553637689,  1351676199,  ..., -1006342006,\n",
       "            -894438689, -1285332057],\n",
       "          [ 1920596435, -2062754766, -2100179067,  ...,  1616486666,\n",
       "           -1359684554,  -600237630]]], dtype=torch.int32),\n",
       " 'model.layers.19.mlp.down_proj.perm': tensor([ 4203,  8467, 10131,  ...,  8814,  9228,  5097], dtype=torch.int16),\n",
       " 'model.layers.19.mlp.down_proj.weight_bias': tensor([ 6.3777e-06, -2.9993e-04,  4.7755e-04,  ..., -3.0041e-05,\n",
       "         -5.5194e-05,  2.3365e-05], dtype=torch.float16),\n",
       " 'model.layers.19.mlp.down_proj.weight_scale': tensor([0.9824, 1.1299, 1.1426,  ..., 1.1221, 1.1387, 1.0840],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.mlp.gate_proj.centroids.weight': tensor([[-0.0006,  0.0131,  0.0081,  ..., -0.0069, -0.0021, -0.0007]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.mlp.gate_proj.indices': tensor([[[  852016719,  -777137134,  -943041766,  ..., -1857743703,\n",
       "           -1430471328,  1171284430],\n",
       "          [ -570734095,   -81022487,    61072102,  ...,  1928264124,\n",
       "            1308277410,  -993748110],\n",
       "          [ 2091054291,   332900333, -1562190229,  ...,  1210333664,\n",
       "             317604064,  -153697924],\n",
       "          ...,\n",
       "          [-1323596589,  1661577281, -1273029073,  ...,   397242671,\n",
       "            -745155931,    22540786],\n",
       "          [  190784173, -1480935399,  -304158193,  ..., -1672402109,\n",
       "             742221656, -1736188093],\n",
       "          [ -780168288,  -301866555,   103809954,  ..., -1453348600,\n",
       "            -962495517, -1958115614]]], dtype=torch.int32),\n",
       " 'model.layers.19.mlp.gate_proj.perm': tensor([2927, 2789, 4071,  ...,  623, 3497, 1794], dtype=torch.int16),\n",
       " 'model.layers.19.mlp.gate_proj.weight_bias': tensor([-2.0485e-03, -7.8976e-05,  7.0858e-04,  ...,  1.2589e-03,\n",
       "         -5.4979e-04, -6.0654e-04], dtype=torch.float16),\n",
       " 'model.layers.19.mlp.gate_proj.weight_scale': tensor([2.0547, 2.0586, 2.0703,  ..., 2.0723, 2.0508, 2.0527],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.mlp.up_proj.centroids.weight': tensor([[-9.2163e-03, -1.2901e-02, -2.2948e-05,  ...,  1.4496e-02,\n",
       "          -9.3536e-03,  4.7073e-03]], dtype=torch.float16),\n",
       " 'model.layers.19.mlp.up_proj.indices': tensor([[[  -14972645, -2078323335,  -137694437,  ...,  1094576103,\n",
       "             -31669219,  -927526791],\n",
       "          [  650994411,    41153180,  -340162930,  ...,  -671155951,\n",
       "            1172747785,  1547584454],\n",
       "          [ 1266207403,   390064267,  -174226117,  ...,  -219709112,\n",
       "           -1606761887, -1428277840],\n",
       "          ...,\n",
       "          [-1035575263,  1391283224,    -5004822,  ...,  1754473655,\n",
       "           -1533052298,   271202435],\n",
       "          [ -660139836, -1707068386,  -178443250,  ...,   552824839,\n",
       "           -1747185835,  -145020713],\n",
       "          [  -50200726,   643597594,   307371496,  ..., -1070483443,\n",
       "           -1710148230,  -387886570]]], dtype=torch.int32),\n",
       " 'model.layers.19.mlp.up_proj.perm': tensor([2927, 2789, 4071,  ...,  623, 3497, 1794], dtype=torch.int16),\n",
       " 'model.layers.19.mlp.up_proj.weight_bias': tensor([ 0.0004, -0.0001, -0.0002,  ..., -0.0004,  0.0001, -0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.mlp.up_proj.weight_scale': tensor([1.9570, 1.9404, 1.9424,  ..., 1.9434, 1.9600, 1.9512],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.post_attention_layernorm.weight': tensor([0.3579, 0.3447, 0.3486,  ..., 0.3550, 0.3518, 0.3489],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.k_proj.centroids.weight': tensor([[-0.0228, -0.0410, -0.0288,  ..., -0.0184, -0.0266, -0.0095]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.k_proj.indices': tensor([[[-1139868613,  -539314622, -1849382797,  ...,  -532722067,\n",
       "            1120566268,   183762227],\n",
       "          [  159520714, -1536437940,  1651567993,  ...,   994361592,\n",
       "           -1730811652,  -350359413],\n",
       "          [-1475266800,  1144946363,  1875807741,  ...,  1905883412,\n",
       "            -451816727,  -642844840],\n",
       "          ...,\n",
       "          [  437307588,   340229910,  1002683314,  ...,  -721192719,\n",
       "             568066929,  2141219158],\n",
       "          [ 1387844137,  1508516505,  -203102157,  ..., -1633630122,\n",
       "           -2078573721,   891918915],\n",
       "          [-1526414430, -1271839742,   573066698,  ...,    -8632134,\n",
       "           -1679478890, -1101651161]]], dtype=torch.int32),\n",
       " 'model.layers.19.self_attn.k_proj.perm': tensor([1076, 2789, 3209,  ..., 3677, 2747, 1415], dtype=torch.int16),\n",
       " 'model.layers.19.self_attn.k_proj.weight_bias': tensor([ 0.0011, -0.0008, -0.0017,  ..., -0.0006,  0.0001, -0.0035],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.k_proj.weight_scale': tensor([1.4971, 1.5244, 1.4844,  ..., 1.4287, 1.4492, 1.4697],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.o_proj.centroids.weight': tensor([[ 0.0083,  0.0081, -0.0313,  ...,  0.0210,  0.0306,  0.0244]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.o_proj.indices': tensor([[[ -105369391,  2096901906,  1732442470,  ...,  -797323123,\n",
       "            1024008128,   394438615],\n",
       "          [ 2060030858,   -48908372,   -23915535,  ...,   784558427,\n",
       "            -137733400,  1908947190],\n",
       "          [-1582290808,  1588529786,  -940494015,  ..., -2134525504,\n",
       "           -1793598040,   226361540],\n",
       "          ...,\n",
       "          [-1867030863, -1182240284,  -290324551,  ..., -1236030097,\n",
       "           -1190482799,  -450175202],\n",
       "          [-1136549473,  1303974565,   339361637,  ...,  1687974062,\n",
       "            -769207708,   -27425166],\n",
       "          [ 1374171704, -1886382244,   713478435,  ...,  2029830916,\n",
       "            1774041600,  -552070633]]], dtype=torch.int32),\n",
       " 'model.layers.19.self_attn.o_proj.perm': tensor([2175,  302, 3819,  ..., 3894, 3847, 3616], dtype=torch.int16),\n",
       " 'model.layers.19.self_attn.o_proj.weight_bias': tensor([ 0.0001,  0.0004,  0.0001,  ..., -0.0002,  0.0001, -0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.o_proj.weight_scale': tensor([1.1465, 1.1348, 1.1445,  ..., 1.1025, 1.0723, 1.0664],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.q_proj.centroids.weight': tensor([[ 0.0155, -0.0126, -0.0049,  ..., -0.0032,  0.0231,  0.0003]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.q_proj.indices': tensor([[[-1309983206, -1939971972,  -439842376,  ...,  1650280283,\n",
       "             -54899543,  1654154822],\n",
       "          [ 1553357090,   -46437735, -2023934019,  ...,   922879243,\n",
       "            -682604721,   -39538170],\n",
       "          [ 1036403377,  1976469833,  1268334026,  ..., -1324393805,\n",
       "           -2021335314, -1979923210],\n",
       "          ...,\n",
       "          [ 1267383916,   -30412942, -1661243709,  ...,  2111476028,\n",
       "             636685440,   209662672],\n",
       "          [-1892023558,  1768406594, -2022448539,  ...,  1802364026,\n",
       "            2007608278, -1678666741],\n",
       "          [ 1084244354,  -872664101,  1562881080,  ...,  -325344495,\n",
       "            2109930657,  1734253493]]], dtype=torch.int32),\n",
       " 'model.layers.19.self_attn.q_proj.perm': tensor([1076, 2789, 3209,  ..., 3677, 2747, 1415], dtype=torch.int16),\n",
       " 'model.layers.19.self_attn.q_proj.weight_bias': tensor([ 0.0005,  0.0014,  0.0004,  ..., -0.0020, -0.0009, -0.0010],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.q_proj.weight_scale': tensor([1.4209, 1.4453, 1.4219,  ..., 1.4248, 1.4482, 1.4619],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.v_proj.centroids.weight': tensor([[ 0.0017,  0.0138, -0.0070,  ...,  0.0089,  0.0033, -0.0217]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.v_proj.indices': tensor([[[  582147682,  1265003353,  -605973906,  ...,   855074370,\n",
       "             638841389,  1082735925],\n",
       "          [ 1900913754,   524744629,   512572301,  ...,  -279835936,\n",
       "           -1424032922,  -962434145],\n",
       "          [ -800700246,  2128370722, -1420402677,  ..., -1097589000,\n",
       "            -787159601,  1716938494],\n",
       "          ...,\n",
       "          [-1877373393,  1111479552,  1987326068,  ...,  1881429580,\n",
       "            1815384845,  1525052592],\n",
       "          [ -879666309,  1401775025,  1098902439,  ..., -1575991755,\n",
       "           -1449384473,  -919082519],\n",
       "          [ 1294387370, -1867764204, -1361442327,  ...,  1727771475,\n",
       "             493663760,  1286736651]]], dtype=torch.int32),\n",
       " 'model.layers.19.self_attn.v_proj.perm': tensor([1076, 2789, 3209,  ..., 3677, 2747, 1415], dtype=torch.int16),\n",
       " 'model.layers.19.self_attn.v_proj.weight_bias': tensor([-1.7905e-04,  1.4913e-04, -3.1447e-04,  ...,  1.9848e-05,\n",
       "          1.6010e-04,  3.3307e-04], dtype=torch.float16),\n",
       " 'model.layers.19.self_attn.v_proj.weight_scale': tensor([1.0967, 1.0908, 1.1201,  ..., 1.1377, 1.1055, 1.0898],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.input_layernorm.weight': tensor([0.1797, 0.1815, 0.1821,  ..., 0.1807, 0.1744, 0.1830],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.mlp.down_proj.centroids.weight': tensor([[-0.0091,  0.0145,  0.0105,  ..., -0.0225,  0.0077,  0.0122]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.mlp.down_proj.indices': tensor([[[-1409829827,  -517744492,   -36343385,  ...,  -195367835,\n",
       "            1382399304,   912059062],\n",
       "          [ -162894689,  1611871138,  -650257678,  ...,   783031217,\n",
       "            2012808918, -1076587087],\n",
       "          [ 1303667648,  -772601308,  1691953622,  ...,  2097685538,\n",
       "            1737090988,  1960654935],\n",
       "          ...,\n",
       "          [  490994074,   908844853,   120621653,  ...,  1293973942,\n",
       "             711904125,  -855759432],\n",
       "          [-1429101297,  1447843080, -1185456194,  ...,  1286930265,\n",
       "            1269378210,   753896777],\n",
       "          [ 1073435047,   619391236,  1043686804,  ...,  1844045450,\n",
       "             604047269,  1359698005]]], dtype=torch.int32),\n",
       " 'model.layers.2.mlp.down_proj.perm': tensor([1661,  968,  328,  ..., 9196, 1997, 2736], dtype=torch.int16),\n",
       " 'model.layers.2.mlp.down_proj.weight_bias': tensor([ 2.9826e-04,  4.7183e-04,  9.3818e-05,  ..., -2.4617e-05,\n",
       "         -1.0014e-05,  3.6120e-04], dtype=torch.float16),\n",
       " 'model.layers.2.mlp.down_proj.weight_scale': tensor([1.1338, 1.1377, 1.1406,  ..., 1.1465, 1.1074, 1.0576],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.mlp.gate_proj.centroids.weight': tensor([[-0.0132,  0.0065, -0.0023,  ...,  0.0113, -0.0075,  0.0109]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.mlp.gate_proj.indices': tensor([[[  164376702, -1966767298,  1071504315,  ...,   -19997270,\n",
       "            -563356379,  1624885535],\n",
       "          [-1593413685,  1528752398,  2123739383,  ...,  -826780706,\n",
       "            1489724124,  -272657618],\n",
       "          [-1974267793,  -426304121,   985167717,  ...,  -165513853,\n",
       "            1388425552, -1719366651],\n",
       "          ...,\n",
       "          [ 2022476973,  -582803612,   344147794,  ...,  -586062929,\n",
       "            -290788400, -1957574033],\n",
       "          [  906237876, -1184201956, -1432673564,  ...,    64660231,\n",
       "             -79989142, -1395012910],\n",
       "          [  609420521, -1037914254,   573399120,  ...,   572937346,\n",
       "             808055570,   519169599]]], dtype=torch.int32),\n",
       " 'model.layers.2.mlp.gate_proj.perm': tensor([3209, 1404,  363,  ...,  339, 2393, 2235], dtype=torch.int16),\n",
       " 'model.layers.2.mlp.gate_proj.weight_bias': tensor([ 0.0003, -0.0001,  0.0010,  ...,  0.0009,  0.0010,  0.0009],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.mlp.gate_proj.weight_scale': tensor([1.9453, 1.9893, 1.9756,  ..., 1.9814, 1.9844, 1.9453],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.mlp.up_proj.centroids.weight': tensor([[ 0.0087, -0.0085,  0.0100,  ..., -0.0044,  0.0013,  0.0229]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.mlp.up_proj.indices': tensor([[[-2058290484,  -905742202, -1047652915,  ..., -1701472564,\n",
       "            1114502922,  -157947384],\n",
       "          [ -957976567,  2078491319, -1636040200,  ...,   229664385,\n",
       "             -82976194, -2124220910],\n",
       "          [  747511023,  1193703825, -1108856747,  ...,   805373979,\n",
       "            -993662640,  1885397150],\n",
       "          ...,\n",
       "          [ 1452148537,  -732978320,  1063051946,  ...,   962709245,\n",
       "             312492140,   626024996],\n",
       "          [ -937882087,  -824110757,  1556795009,  ..., -2091147874,\n",
       "           -1183108268,   676336411],\n",
       "          [-1985692524,    40596800,  1182030946,  ..., -1823104290,\n",
       "           -2080705090,  1318569282]]], dtype=torch.int32),\n",
       " 'model.layers.2.mlp.up_proj.perm': tensor([3209, 1404,  363,  ...,  339, 2393, 2235], dtype=torch.int16),\n",
       " 'model.layers.2.mlp.up_proj.weight_bias': tensor([ 0.0001,  0.0002,  0.0003,  ...,  0.0003,  0.0002, -0.0006],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.mlp.up_proj.weight_scale': tensor([1.8457, 1.8184, 1.8350,  ..., 1.8320, 1.8291, 1.8633],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.post_attention_layernorm.weight': tensor([0.1326, 0.1372, 0.1367,  ..., 0.1366, 0.1398, 0.1382],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.k_proj.centroids.weight': tensor([[-0.0027,  0.0501, -0.0049,  ...,  0.0132, -0.0247,  0.0095]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.k_proj.indices': tensor([[[  266251006, -2071396334, -1655806155,  ..., -2054888016,\n",
       "            -262241249,   468961186],\n",
       "          [ 2107268555,  1327053355,   514453316,  ..., -1180233035,\n",
       "             -33608481, -1118427282],\n",
       "          [ -726868512,  1295100384,   994292757,  ...,  1832996399,\n",
       "            1410549632,  1334864652],\n",
       "          ...,\n",
       "          [ -555580068,   547297260, -2073787617,  ...,  -501207939,\n",
       "            -774592564,  1915828440],\n",
       "          [ -819220634,  2048517808,  2012821625,  ...,   718985048,\n",
       "            -100053106, -2139245716],\n",
       "          [ -884817124,  -539720070, -1584999824,  ...,  1374673461,\n",
       "           -1721279141, -1585061120]]], dtype=torch.int32),\n",
       " 'model.layers.2.self_attn.k_proj.perm': tensor([2393, 2298, 1512,  ..., 2168, 1415,  310], dtype=torch.int16),\n",
       " 'model.layers.2.self_attn.k_proj.weight_bias': tensor([-0.0003, -0.0026,  0.0014,  ...,  0.0006, -0.0007, -0.0058],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.k_proj.weight_scale': tensor([1.7861, 1.7549, 1.8262,  ..., 1.7979, 1.7529, 1.7832],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.o_proj.centroids.weight': tensor([[-0.0140, -0.0084, -0.0249,  ..., -0.0251,  0.0157,  0.0071]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.o_proj.indices': tensor([[[  141920088,  2045595293,  -483884619,  ...,  1754736238,\n",
       "            1775521458,  1097682356],\n",
       "          [-1284554567,  1848463109,  1396305978,  ...,  -509060411,\n",
       "            1721191292, -2022733904],\n",
       "          [ 2037478615,  -830563229, -1355093714,  ..., -1494820072,\n",
       "             655800796, -1519363059],\n",
       "          ...,\n",
       "          [-2038342947,   167428817,  1777009440,  ...,  1665529486,\n",
       "             486009866,   456611607],\n",
       "          [-1141172094,   429164080,   460274081,  ..., -1600224005,\n",
       "            -642472519,  1786332203],\n",
       "          [  637782073,  1872449927,  -206530785,  ..., -1814953428,\n",
       "            -816165533, -1665867827]]], dtype=torch.int32),\n",
       " 'model.layers.2.self_attn.o_proj.perm': tensor([ 848,  880, 1544,  ...,  832,  890,  814], dtype=torch.int16),\n",
       " 'model.layers.2.self_attn.o_proj.weight_bias': tensor([ 2.2757e-04,  1.9050e-04,  3.6299e-05,  ..., -1.2082e-04,\n",
       "         -6.2943e-05, -2.5058e-04], dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.o_proj.weight_scale': tensor([0.9175, 0.9854, 0.9419,  ..., 0.9385, 0.9639, 0.9185],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.q_proj.centroids.weight': tensor([[-0.0284,  0.0249, -0.0045,  ...,  0.0450,  0.0077,  0.0033]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.q_proj.indices': tensor([[[-1478250482,  1469608951,  1447861773,  ...,   677080422,\n",
       "           -1659716753,   477556480],\n",
       "          [ -520286765,   668930398,  1214263800,  ...,  -148504544,\n",
       "           -1329232746, -1426208855],\n",
       "          [  870531028,  -458295234,   545392893,  ...,  -717839001,\n",
       "             985193054,   454870219],\n",
       "          ...,\n",
       "          [  785634632,  1696587722,  1661349904,  ...,  1963982556,\n",
       "             754587586,   351684773],\n",
       "          [ 2008512074,   651125195,  1311440462,  ...,  1502937039,\n",
       "           -1865154926,  2127692874],\n",
       "          [ -541307285,  1039646192,  -869132340,  ...,   287462986,\n",
       "              -6098607,  1588706712]]], dtype=torch.int32),\n",
       " 'model.layers.2.self_attn.q_proj.perm': tensor([2393, 2298, 1512,  ..., 2168, 1415,  310], dtype=torch.int16),\n",
       " 'model.layers.2.self_attn.q_proj.weight_bias': tensor([-0.0006,  0.0004,  0.0030,  ..., -0.0012,  0.0047, -0.0003],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.q_proj.weight_scale': tensor([1.6875, 1.7217, 1.6836,  ..., 1.7520, 1.6240, 1.6543],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.v_proj.centroids.weight': tensor([[-0.0227,  0.0001,  0.0066,  ..., -0.0022, -0.0113,  0.0143]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.v_proj.indices': tensor([[[ 1478610510,  1562338291, -1961171978,  ...,  1520140581,\n",
       "             929157292,  -118934396],\n",
       "          [ 1647231906,  2120803606,  1985914454,  ...,   365914437,\n",
       "             593733511, -1298356163],\n",
       "          [  637040603,   -53981205,   277174912,  ...,  -310981121,\n",
       "             932740956,  1268470283],\n",
       "          ...,\n",
       "          [  528542280, -1451185629,   777909151,  ...,   692681191,\n",
       "            -364344031,  -844482908],\n",
       "          [-1208795414, -1279950361,   -60002668,  ..., -1657319567,\n",
       "           -1488605843,   771172112],\n",
       "          [ 1764137803, -1230729006, -1248729454,  ..., -2147149900,\n",
       "            1596154596,   886632066]]], dtype=torch.int32),\n",
       " 'model.layers.2.self_attn.v_proj.perm': tensor([2393, 2298, 1512,  ..., 2168, 1415,  310], dtype=torch.int16),\n",
       " 'model.layers.2.self_attn.v_proj.weight_bias': tensor([ 2.7227e-04,  4.5896e-04,  2.5511e-05,  ..., -1.5080e-04,\n",
       "          3.8326e-05, -3.4904e-04], dtype=torch.float16),\n",
       " 'model.layers.2.self_attn.v_proj.weight_scale': tensor([0.9302, 0.9297, 0.9258,  ..., 0.9028, 0.9604, 0.9609],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.input_layernorm.weight': tensor([0.4504, 0.4773, 0.4453,  ..., 0.4353, 0.4414, 0.4551],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.mlp.down_proj.centroids.weight': tensor([[0.0146, 0.0306, 0.0175,  ..., 0.0378, 0.0144, 0.0068]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.mlp.down_proj.indices': tensor([[[-1711435333,  -164902074,    61669621,  ...,  -607286506,\n",
       "            1854817564,  -605703406],\n",
       "          [ -815410976, -1048822289, -2123348909,  ..., -1360133610,\n",
       "              41699345,  -219160829],\n",
       "          [-1037661074,  -586692214,  1634110697,  ..., -1367620860,\n",
       "           -1088746127,  1084213414],\n",
       "          ...,\n",
       "          [ 1414929868,  1906867708,  -126587652,  ...,   588462484,\n",
       "           -2024114794,  -308243974],\n",
       "          [-1090685025, -1124427829,   829781960,  ...,  -106169200,\n",
       "           -1508118742, -1514918254],\n",
       "          [-1674830917,   935852264,   221530575,  ...,  1301485798,\n",
       "            -435604451,   594124949]]], dtype=torch.int32),\n",
       " 'model.layers.20.mlp.down_proj.perm': tensor([ 9851,  4752,  8771,  ...,   219,  2324, 10226], dtype=torch.int16),\n",
       " 'model.layers.20.mlp.down_proj.weight_bias': tensor([-1.3113e-04,  8.4102e-05, -3.8838e-04,  ..., -2.8634e-04,\n",
       "          9.6560e-04,  6.8367e-05], dtype=torch.float16),\n",
       " 'model.layers.20.mlp.down_proj.weight_scale': tensor([1.1787, 1.1426, 1.1680,  ..., 1.1152, 1.1240, 1.1455],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.mlp.gate_proj.centroids.weight': tensor([[-6.2847e-04, -7.1526e-03,  1.8494e-02,  ...,  5.8258e-02,\n",
       "           9.8407e-05,  5.9700e-04]], dtype=torch.float16),\n",
       " 'model.layers.20.mlp.gate_proj.indices': tensor([[[ -538328980,  2051398057, -1134252358,  ..., -1356379612,\n",
       "           -1669231111,  -833066819],\n",
       "          [-1051737842,  -456283597, -1031330877,  ...,  -982661881,\n",
       "           -1843929761,   751485674],\n",
       "          [-1432029685, -1241117152,  -187776160,  ...,   216149698,\n",
       "             662440775, -1668092082],\n",
       "          ...,\n",
       "          [-1317769078,  -487926508,   522245283,  ...,  1314222001,\n",
       "           -2010127339,  1666198701],\n",
       "          [  561979795, -1903564341, -1695984360,  ...,   657963467,\n",
       "             984347714, -1260787345],\n",
       "          [ -485552970,  -533014331,   271884623,  ...,  1318992117,\n",
       "            1454149623,   429518204]]], dtype=torch.int32),\n",
       " 'model.layers.20.mlp.gate_proj.perm': tensor([1512, 2622, 1793,  ..., 3530, 3130, 3497], dtype=torch.int16),\n",
       " 'model.layers.20.mlp.gate_proj.weight_bias': tensor([-3.2463e-03,  3.2246e-05,  1.5574e-03,  ...,  1.7920e-03,\n",
       "         -1.3685e-04, -3.8838e-04], dtype=torch.float16),\n",
       " 'model.layers.20.mlp.gate_proj.weight_scale': tensor([2.0859, 2.0781, 2.0742,  ..., 2.0801, 2.0605, 2.0312],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.mlp.up_proj.centroids.weight': tensor([[-0.0210, -0.0063,  0.0118,  ...,  0.0086, -0.0079, -0.0059]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.mlp.up_proj.indices': tensor([[[ 1724149165,  1783958737,   138203469,  ...,  2006585536,\n",
       "             597175042, -1654043307],\n",
       "          [ 1687292817,  -801430923,  -103651148,  ...,   -12071739,\n",
       "            1853860859, -1818297904],\n",
       "          [-1221898989,   153988911,   263564899,  ..., -2127212948,\n",
       "            1917061192,  -624823160],\n",
       "          ...,\n",
       "          [  146069106, -1604962484,   598581889,  ..., -1548696097,\n",
       "           -1911564356,  -106864195],\n",
       "          [-1771621772,   927806436,    70185967,  ...,  -310142009,\n",
       "            1077857816,  -808522627],\n",
       "          [  960485986,  1498432767,  1821922439,  ...,  -643234086,\n",
       "            -299012700, -1380161582]]], dtype=torch.int32),\n",
       " 'model.layers.20.mlp.up_proj.perm': tensor([1512, 2622, 1793,  ..., 3530, 3130, 3497], dtype=torch.int16),\n",
       " 'model.layers.20.mlp.up_proj.weight_bias': tensor([-7.3910e-06,  1.3435e-04, -2.2757e-04,  ..., -1.1081e-04,\n",
       "         -5.1260e-06, -4.5002e-05], dtype=torch.float16),\n",
       " 'model.layers.20.mlp.up_proj.weight_scale': tensor([1.9219, 1.9365, 1.9414,  ..., 1.9424, 1.9473, 1.9766],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.post_attention_layernorm.weight': tensor([0.3684, 0.3623, 0.3569,  ..., 0.3667, 0.3608, 0.3572],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.k_proj.centroids.weight': tensor([[0.0314, 0.0074, 0.0123,  ..., 0.0090, 0.0087, 0.0088]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.k_proj.indices': tensor([[[ 1319715535,   886050218,   277008378,  ...,  -402228536,\n",
       "            -932572657,   754250303],\n",
       "          [ 1429011452, -1831882269,   754902627,  ...,  -116387932,\n",
       "           -1270982692,  -284282893],\n",
       "          [ -416726387,  2120834911, -2112871477,  ...,  -116800607,\n",
       "           -1996712724, -1660155715],\n",
       "          ...,\n",
       "          [  -67105453,  1802656791,  -673271919,  ..., -1207644907,\n",
       "           -1161345117,  -683129500],\n",
       "          [ -117916378, -1606117418,   114910867,  ...,  2015827220,\n",
       "             872659415,  -665088464],\n",
       "          [ 1320865554, -1003614799,  1547245564,  ..., -1755526507,\n",
       "              61274925,   950797100]]], dtype=torch.int32),\n",
       " 'model.layers.20.self_attn.k_proj.perm': tensor([1076, 2789, 3209,  ..., 2747, 3530, 1415], dtype=torch.int16),\n",
       " 'model.layers.20.self_attn.k_proj.weight_bias': tensor([ 3.5763e-07,  9.8419e-04, -2.3251e-03,  ...,  8.5402e-04,\n",
       "         -7.0047e-04, -2.9316e-03], dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.k_proj.weight_scale': tensor([1.5020, 1.5371, 1.5029,  ..., 1.4590, 1.4561, 1.4961],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.o_proj.centroids.weight': tensor([[-7.0618e-02, -1.2482e-02,  4.4584e-05,  ..., -1.4359e-02,\n",
       "           1.9318e-02, -1.4648e-02]], dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.o_proj.indices': tensor([[[ -462917014,  1511010631,  -168315176,  ...,    44486503,\n",
       "            -420326962, -1038741099],\n",
       "          [ -307492469,  1319269217,  -154781125,  ..., -1253962368,\n",
       "           -1962675257,  -714074506],\n",
       "          [ 1304417656,  -724961570,  -960963551,  ...,  1715040843,\n",
       "           -1554374763, -1358204331],\n",
       "          ...,\n",
       "          [ -748043489,  1723666313,   793502626,  ...,   128847668,\n",
       "            1022953264,   814893073],\n",
       "          [-1389625788,   604133728,  -344798201,  ...,  -620320042,\n",
       "           -2006648417, -1064398888],\n",
       "          [ -370981053,  -349651846,   794775482,  ...,   160133063,\n",
       "            1268402121,   905197702]]], dtype=torch.int32),\n",
       " 'model.layers.20.self_attn.o_proj.perm': tensor([ 959, 1698, 2890,  ..., 2434, 2494, 2498], dtype=torch.int16),\n",
       " 'model.layers.20.self_attn.o_proj.weight_bias': tensor([-2.8968e-04,  1.8287e-04, -6.1035e-05,  ..., -3.9792e-04,\n",
       "          6.0272e-04, -2.6107e-04], dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.o_proj.weight_scale': tensor([1.0557, 1.0625, 1.0576,  ..., 1.0420, 1.0693, 1.0469],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.q_proj.centroids.weight': tensor([[ 0.0191,  0.0098, -0.0182,  ...,  0.0085, -0.0154,  0.0041]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.q_proj.indices': tensor([[[-1305098576, -1017368300,  1460014883,  ...,    35946384,\n",
       "            -745348806,   881214100],\n",
       "          [ 1207299994, -2119697854, -1182054175,  ...,   208176423,\n",
       "           -2060977694,   823602830],\n",
       "          [-1718775850,  1085374175,  1488576183,  ...,   771982340,\n",
       "            -250801105,  -822140009],\n",
       "          ...,\n",
       "          [ -312110409,  -551787074,  -433487122,  ...,  -569429835,\n",
       "            2036204904,  -287613047],\n",
       "          [ 1132430569,   143681419,   253011138,  ...,  -938337055,\n",
       "            1580013878,   810010686],\n",
       "          [ 1140959698, -1216228060,  2027203699,  ...,   320732613,\n",
       "            1995992467,   542950254]]], dtype=torch.int32),\n",
       " 'model.layers.20.self_attn.q_proj.perm': tensor([1076, 2789, 3209,  ..., 2747, 3530, 1415], dtype=torch.int16),\n",
       " 'model.layers.20.self_attn.q_proj.weight_bias': tensor([ 0.0012,  0.0015, -0.0006,  ...,  0.0010, -0.0009, -0.0028],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.q_proj.weight_scale': tensor([1.4482, 1.4932, 1.4219,  ..., 1.4355, 1.4609, 1.4443],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.v_proj.centroids.weight': tensor([[-0.0023, -0.0098,  0.0087,  ...,  0.0047, -0.0001, -0.0084]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.v_proj.indices': tensor([[[ -856033382,   683844901,  2058964242,  ...,  1844696557,\n",
       "            -386877029,  -373895308],\n",
       "          [ -263802193, -1528383997,  -214621791,  ...,   792200907,\n",
       "            -332334858,   558284004],\n",
       "          [  749837946,  2066525929,   118154824,  ..., -2128308610,\n",
       "             -22996138,  -570828534],\n",
       "          ...,\n",
       "          [ -745182665,  1667427107,  1647711819,  ...,  1754478976,\n",
       "            -703015579,  -910315092],\n",
       "          [ -788468582,  -633034635, -1023848796,  ...,  1038181740,\n",
       "             896895446,  -124150476],\n",
       "          [  430348379,  1724018657,   622801184,  ..., -1148461170,\n",
       "             832231952,  1332853861]]], dtype=torch.int32),\n",
       " 'model.layers.20.self_attn.v_proj.perm': tensor([1076, 2789, 3209,  ..., 2747, 3530, 1415], dtype=torch.int16),\n",
       " 'model.layers.20.self_attn.v_proj.weight_bias': tensor([ 2.4605e-04,  5.3763e-05, -5.5218e-04,  ..., -4.9639e-04,\n",
       "          3.1686e-04, -2.9445e-05], dtype=torch.float16),\n",
       " 'model.layers.20.self_attn.v_proj.weight_scale': tensor([1.1084, 1.0996, 1.1455,  ..., 1.1338, 1.1377, 1.1357],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.input_layernorm.weight': tensor([0.4775, 0.4949, 0.4722,  ..., 0.4619, 0.4641, 0.4814],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.mlp.down_proj.centroids.weight': tensor([[ 0.0048,  0.0153, -0.0233,  ..., -0.0260, -0.0067, -0.0134]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.mlp.down_proj.indices': tensor([[[ -246829633, -1269911555,   -59375645,  ...,  1913478089,\n",
       "           -2106491431, -1537470776],\n",
       "          [ 1664625382, -2072507018,   378471490,  ...,  1625986611,\n",
       "            -134769179,  1235432466],\n",
       "          [ 1593953163,   534582228,  1319352961,  ..., -1361309224,\n",
       "            -942368825,  2112248559],\n",
       "          ...,\n",
       "          [-1485119858, -1584769560,  1661590026,  ...,   605219411,\n",
       "            1291246001,  -204343565],\n",
       "          [-2140453390,  -408580934, -1509438970,  ...,   659509202,\n",
       "            1849248717,  -559568435],\n",
       "          [ 1783318042, -1129435173, -1721622449,  ...,  -390705600,\n",
       "           -1478848652,   183590640]]], dtype=torch.int32),\n",
       " 'model.layers.21.mlp.down_proj.perm': tensor([ 2142,  3900,  2737,  ...,  5319,  4343, 10359], dtype=torch.int16),\n",
       " 'model.layers.21.mlp.down_proj.weight_bias': tensor([-1.1081e-04,  1.4305e-05, -3.5572e-04,  ...,  1.0586e-03,\n",
       "          4.5204e-04,  7.5459e-05], dtype=torch.float16),\n",
       " 'model.layers.21.mlp.down_proj.weight_scale': tensor([1.1650, 1.1699, 1.1602,  ..., 1.1719, 1.0898, 1.1465],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.mlp.gate_proj.centroids.weight': tensor([[-0.0177, -0.0015,  0.0041,  ...,  0.0043,  0.0088,  0.0005]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.mlp.gate_proj.indices': tensor([[[-2089271423,   460146284, -2060149884,  ...,   674187297,\n",
       "            -117059714,  -273889801],\n",
       "          [ 1071136712, -1012778667,   975919550,  ..., -1950898195,\n",
       "           -1632746424,  1866903036],\n",
       "          [-1802346894,  1169577445, -1919489986,  ..., -1243621960,\n",
       "            2017167293,  -349414109],\n",
       "          ...,\n",
       "          [-1691992619, -1873189776,   490919732,  ...,  1147387616,\n",
       "            -631395258,  1479473010],\n",
       "          [ -521925970,  -281581425, -1196447165,  ..., -1764757545,\n",
       "            -590970031, -1224264670],\n",
       "          [-1624050200,  1934598671,   989271536,  ..., -1068718755,\n",
       "             265792386,   271932689]]], dtype=torch.int32),\n",
       " 'model.layers.21.mlp.gate_proj.perm': tensor([1512, 2622, 1793,  ...,  623, 3130, 3497], dtype=torch.int16),\n",
       " 'model.layers.21.mlp.gate_proj.weight_bias': tensor([-2.7122e-03,  7.4625e-05,  1.7538e-03,  ...,  9.6464e-04,\n",
       "          4.3726e-04,  1.6093e-05], dtype=torch.float16),\n",
       " 'model.layers.21.mlp.gate_proj.weight_scale': tensor([2.0938, 2.0820, 2.0781,  ..., 2.0840, 2.0664, 2.0801],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.mlp.up_proj.centroids.weight': tensor([[-0.0028, -0.0037, -0.0100,  ..., -0.0016, -0.0038, -0.0039]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.mlp.up_proj.indices': tensor([[[   96920975,  1709067627,   972634588,  ...,   790453658,\n",
       "           -2100252230,  1501233065],\n",
       "          [ -526633849,  1046040364,  1150943677,  ...,   945096902,\n",
       "            1246329937,  1542853289],\n",
       "          [  507023998, -1729122108,  -170993333,  ...,   241830239,\n",
       "           -1839715883, -2027650875],\n",
       "          ...,\n",
       "          [ 2059538031,   242214177, -1428116209,  ..., -1124307753,\n",
       "           -1617892793, -1670271900],\n",
       "          [ -416417277,  1006822631,  -810065305,  ..., -1208753266,\n",
       "             906142835, -2003102553],\n",
       "          [ 1929716828,   545202382,  -311255888,  ...,  1977358570,\n",
       "            1454687242, -2114836681]]], dtype=torch.int32),\n",
       " 'model.layers.21.mlp.up_proj.perm': tensor([1512, 2622, 1793,  ...,  623, 3130, 3497], dtype=torch.int16),\n",
       " 'model.layers.21.mlp.up_proj.weight_bias': tensor([-1.0431e-04,  2.8491e-04,  1.0592e-04,  ...,  1.6999e-04,\n",
       "         -2.9278e-04,  4.8995e-05], dtype=torch.float16),\n",
       " 'model.layers.21.mlp.up_proj.weight_scale': tensor([1.9189, 1.9385, 1.9443,  ..., 1.9473, 1.9512, 1.9404],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.post_attention_layernorm.weight': tensor([0.3757, 0.3733, 0.3660,  ..., 0.3787, 0.3704, 0.3718],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.k_proj.centroids.weight': tensor([[ 0.0079, -0.0188,  0.0174,  ..., -0.0709,  0.0146,  0.0430]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.k_proj.indices': tensor([[[-1049656112,  1522600602,  1870710851,  ...,  1091279392,\n",
       "            -488653587,  -229889711],\n",
       "          [-1145163943,  -826121831,  1916733880,  ...,   272145775,\n",
       "           -1050283058,   357988765],\n",
       "          [-1457771773,   279893399,  -462028096,  ...,  -495136536,\n",
       "           -1675883366,  1244419292],\n",
       "          ...,\n",
       "          [ 1491178994,   356319873,  1640050607,  ...,  1937001776,\n",
       "           -1507116005,  -147262902],\n",
       "          [ -397893803, -1998282664, -1678495845,  ..., -1856466598,\n",
       "             694056968,  2089979346],\n",
       "          [ 1192468345,  1626881139,   901317476,  ...,  -821463081,\n",
       "             991787025,  1700776043]]], dtype=torch.int32),\n",
       " 'model.layers.21.self_attn.k_proj.perm': tensor([2789, 1076, 3209,  ..., 3985, 2133, 1415], dtype=torch.int16),\n",
       " 'model.layers.21.self_attn.k_proj.weight_bias': tensor([ 0.0013,  0.0020,  0.0011,  ...,  0.0006,  0.0010, -0.0010],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.k_proj.weight_scale': tensor([1.4512, 1.4766, 1.4385,  ..., 1.4121, 1.4336, 1.4326],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.o_proj.centroids.weight': tensor([[ 0.0162, -0.0046,  0.0100,  ...,  0.0038, -0.0376,  0.0011]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.o_proj.indices': tensor([[[  314649380,  1441830938,  -969040477,  ...,    15889243,\n",
       "             348640322,  1230290067],\n",
       "          [ -298384638, -1253741168,  1123510947,  ...,  -514375464,\n",
       "           -1196722112,  -394147088],\n",
       "          [  429475249, -1521756365,   571615283,  ...,  1825316392,\n",
       "            2061817330,  2016234009],\n",
       "          ...,\n",
       "          [ 1489273760,  1160999590,  1445142397,  ...,   973977531,\n",
       "           -1302186786,  -500931394],\n",
       "          [  714039410, -1465670895, -1626249190,  ..., -1969220034,\n",
       "            1984514207,  1165976697],\n",
       "          [ 1340761465, -2135559255,  -868900966,  ...,  1839958275,\n",
       "            1273110658,  2018531820]]], dtype=torch.int32),\n",
       " 'model.layers.21.self_attn.o_proj.perm': tensor([2894, 2191, 3312,  ..., 2341, 2404, 2423], dtype=torch.int16),\n",
       " 'model.layers.21.self_attn.o_proj.weight_bias': tensor([-7.7009e-05, -3.8385e-05,  1.0252e-04,  ..., -7.4208e-05,\n",
       "         -1.5604e-04, -2.5892e-04], dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.o_proj.weight_scale': tensor([1.1055, 1.0859, 1.1260,  ..., 1.1279, 1.1367, 1.1387],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.q_proj.centroids.weight': tensor([[ 0.0270,  0.0038, -0.0187,  ..., -0.0195,  0.0207,  0.0243]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.q_proj.indices': tensor([[[ -806386481,  -481766476, -1350916342,  ...,   850047824,\n",
       "            -606723438,  1347788356],\n",
       "          [ 1320330501,  1043329440,   404706359,  ...,   149474077,\n",
       "             548316792,    11461812],\n",
       "          [-1029749861, -1878180633,  2031499166,  ..., -2088136937,\n",
       "           -1923088714,   204763827],\n",
       "          ...,\n",
       "          [  187082958,  -929678279,  2085602620,  ...,  -973538180,\n",
       "            -451452848,  -470478437],\n",
       "          [-1677376378,  1461397556, -1153520768,  ..., -1762733264,\n",
       "             764637588,  -797075728],\n",
       "          [ -951960446, -1622794846, -1377244573,  ...,  1176161286,\n",
       "           -1975831806,   953647304]]], dtype=torch.int32),\n",
       " 'model.layers.21.self_attn.q_proj.perm': tensor([2789, 1076, 3209,  ..., 3985, 2133, 1415], dtype=torch.int16),\n",
       " 'model.layers.21.self_attn.q_proj.weight_bias': tensor([ 0.0015, -0.0019, -0.0007,  ...,  0.0005, -0.0016,  0.0027],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.q_proj.weight_scale': tensor([1.4180, 1.4414, 1.4160,  ..., 1.3799, 1.4170, 1.3867],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.v_proj.centroids.weight': tensor([[ 0.0019,  0.0150,  0.0004,  ..., -0.0114,  0.0235,  0.0016]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.v_proj.indices': tensor([[[   78765594,   792105240,  1274490921,  ...,  1609337318,\n",
       "            1312018820,   376230083],\n",
       "          [-1938862289,  2033257799, -1863381992,  ...,  2075811844,\n",
       "            1151495379,  -874588438],\n",
       "          [ 2120469325, -1295510348,   194292621,  ...,  -942542939,\n",
       "            1239673114,   -97521098],\n",
       "          ...,\n",
       "          [ 1641399242,  1684990896,  -340030922,  ...,   585780264,\n",
       "            -861594684,   771076303],\n",
       "          [ 1805387100,  2062498924,  -357938599,  ...,  -351091315,\n",
       "             874245251,   728453562],\n",
       "          [  293395806,  1270789700,   975492935,  ..., -1055834118,\n",
       "             727978648,  1023653508]]], dtype=torch.int32),\n",
       " 'model.layers.21.self_attn.v_proj.perm': tensor([2789, 1076, 3209,  ..., 3985, 2133, 1415], dtype=torch.int16),\n",
       " 'model.layers.21.self_attn.v_proj.weight_bias': tensor([-2.8992e-04,  1.1456e-04, -4.3988e-05,  ...,  2.2078e-04,\n",
       "          1.8680e-04,  2.0766e-04], dtype=torch.float16),\n",
       " 'model.layers.21.self_attn.v_proj.weight_scale': tensor([1.1348, 1.1523, 1.1572,  ..., 1.1875, 1.1562, 1.1953],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.input_layernorm.weight': tensor([0.4858, 0.4934, 0.4841,  ..., 0.4695, 0.4883, 0.4868],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.mlp.down_proj.centroids.weight': tensor([[ 0.0042,  0.0233,  0.0120,  ..., -0.0165,  0.0017,  0.0114]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.mlp.down_proj.indices': tensor([[[ -423477049,  -380050745, -1581893062,  ...,  1770021645,\n",
       "           -1223666788, -1120359032],\n",
       "          [-1372886967,  -236688424,  -870085497,  ...,  -239076641,\n",
       "            -505608267,  -321367140],\n",
       "          [ -696931744,  1502148784,  1162118251,  ...,  1649127804,\n",
       "            -786503877, -1328177120],\n",
       "          ...,\n",
       "          [-2126362755,  1720481335, -1436095866,  ...,  -913169095,\n",
       "            1315348463,  1799446090],\n",
       "          [   61253927, -1376440607, -1024468437,  ...,  1366996821,\n",
       "            2037429230,   324802233],\n",
       "          [ 1898330504,  1762712383, -1513167431,  ...,   212279380,\n",
       "            1962880594,  -765410584]]], dtype=torch.int32),\n",
       " 'model.layers.22.mlp.down_proj.perm': tensor([ 3057, 10826,  2194,  ...,  8228,  7910,  3909], dtype=torch.int16),\n",
       " 'model.layers.22.mlp.down_proj.weight_bias': tensor([-3.5214e-04, -1.4782e-04,  2.7585e-04,  ..., -4.5156e-04,\n",
       "          2.0087e-05,  8.0466e-05], dtype=torch.float16),\n",
       " 'model.layers.22.mlp.down_proj.weight_scale': tensor([1.1445, 1.1143, 1.1641,  ..., 1.2285, 1.2021, 1.1396],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.mlp.gate_proj.centroids.weight': tensor([[ 0.0023, -0.0051,  0.0105,  ..., -0.0062, -0.0076,  0.0110]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.mlp.gate_proj.indices': tensor([[[ -456885320, -1667536751,  1606367118,  ...,   718044199,\n",
       "             340949605,  -990894314],\n",
       "          [-2007630654,   646775696,    88950658,  ...,   651834494,\n",
       "           -1868561077,   448293236],\n",
       "          [ -304892284,   -30046780,  1616796751,  ...,  1740477114,\n",
       "            1753550571,  1530488916],\n",
       "          ...,\n",
       "          [ -667408189, -1897080379,   599669337,  ..., -1154565949,\n",
       "           -1819804536, -2051280197],\n",
       "          [ 1840842408,   304488947, -2123853463,  ...,  1419086767,\n",
       "             -82033415,   112489034],\n",
       "          [  676047751,   632143258,  1252757530,  ...,   917021788,\n",
       "            -786851329,  1955558165]]], dtype=torch.int32),\n",
       " 'model.layers.22.mlp.gate_proj.perm': tensor([2622, 1512, 1793,  ..., 3046, 3497, 3431], dtype=torch.int16),\n",
       " 'model.layers.22.mlp.gate_proj.weight_bias': tensor([-0.0034, -0.0001,  0.0026,  ...,  0.0023,  0.0009,  0.0008],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.mlp.gate_proj.weight_scale': tensor([2.1094, 2.1016, 2.1230,  ..., 2.0996, 2.0938, 2.0859],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.mlp.up_proj.centroids.weight': tensor([[-0.0011, -0.0137, -0.0171,  ...,  0.0070, -0.0022, -0.0010]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.mlp.up_proj.indices': tensor([[[ -497108134,   770959874,  -877138029,  ..., -1549120702,\n",
       "             888706080,   922835365],\n",
       "          [ 1922812464,  1026577092,   406168894,  ...,  -551930140,\n",
       "            -994273650,  2073037666],\n",
       "          [ -937482801,   988398863, -1018797290,  ..., -2098462699,\n",
       "            1862461337,   168315989],\n",
       "          ...,\n",
       "          [-1312063890, -2047460827, -1805769954,  ..., -1494537525,\n",
       "           -1541905495, -2052262065],\n",
       "          [-1263852290,  2142784871,   574772380,  ...,  1899487803,\n",
       "           -1890768846,   940730143],\n",
       "          [ -248891666, -1792256515,   237534687,  ...,  1904662129,\n",
       "           -1765573674, -2073448999]]], dtype=torch.int32),\n",
       " 'model.layers.22.mlp.up_proj.perm': tensor([2622, 1512, 1793,  ..., 3046, 3497, 3431], dtype=torch.int16),\n",
       " 'model.layers.22.mlp.up_proj.weight_bias': tensor([-4.8101e-05, -2.1517e-04, -3.8981e-05,  ..., -1.4842e-04,\n",
       "          2.6584e-04, -1.5831e-04], dtype=torch.float16),\n",
       " 'model.layers.22.mlp.up_proj.weight_scale': tensor([1.9209, 1.9277, 1.9141,  ..., 1.9404, 1.9326, 1.9463],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.post_attention_layernorm.weight': tensor([0.3877, 0.3838, 0.3879,  ..., 0.3931, 0.3818, 0.3867],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.k_proj.centroids.weight': tensor([[ 0.0030, -0.0007, -0.0002,  ...,  0.0053, -0.0168,  0.0178]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.k_proj.indices': tensor([[[ 1601631360,   -69915042,  1962881277,  ...,  -918238715,\n",
       "            1316673135,  2047229207],\n",
       "          [ 1117106713,  2133632596,  -793616455,  ...,    75395302,\n",
       "            2029209788,  -915788658],\n",
       "          [ -372925070,  -169237787, -1089226731,  ...,   489972668,\n",
       "            1431325219,  2019107121],\n",
       "          ...,\n",
       "          [  683600047, -1064165982,   498054746,  ..., -2045617886,\n",
       "            -982835867,  1275699949],\n",
       "          [-1750080011,  1529841250,  -884820088,  ...,  1706529186,\n",
       "            -553183052,  -284667980],\n",
       "          [-1330131678,   -62193628,  -195845241,  ...,   786524642,\n",
       "           -1823663253,  -994118883]]], dtype=torch.int32),\n",
       " 'model.layers.22.self_attn.k_proj.perm': tensor([2789, 1076, 3209,  ...,  630, 2918, 1415], dtype=torch.int16),\n",
       " 'model.layers.22.self_attn.k_proj.weight_bias': tensor([ 0.0017,  0.0008, -0.0002,  ...,  0.0032,  0.0001,  0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.k_proj.weight_scale': tensor([1.4736, 1.4854, 1.4893,  ..., 1.4678, 1.4785, 1.4805],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.o_proj.centroids.weight': tensor([[ 0.0205, -0.0013,  0.0021,  ..., -0.0119,  0.0004, -0.0147]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.o_proj.indices': tensor([[[  690787263,  1740769798,  -234533116,  ...,  1963276409,\n",
       "            2124990583,   421642002],\n",
       "          [  108752917, -1052264468,  -716340991,  ...,   -51250904,\n",
       "            1097884661,   119389316],\n",
       "          [ 1533337832, -1440972395,  2003271776,  ...,   243397216,\n",
       "             318178274,   832982382],\n",
       "          ...,\n",
       "          [ -315188647, -1341630011,  -586163920,  ...,  -258107741,\n",
       "           -1095931403, -1148371399],\n",
       "          [  997981841,  1656158840,  1414630849,  ..., -1041674477,\n",
       "            -543693366,   559193260],\n",
       "          [-1498740561,  1980117191,  1087357450,  ..., -1728660621,\n",
       "            1428494444, -1009109179]]], dtype=torch.int32),\n",
       " 'model.layers.22.self_attn.o_proj.perm': tensor([ 610, 2290, 3378,  ..., 1999, 2035, 2044], dtype=torch.int16),\n",
       " 'model.layers.22.self_attn.o_proj.weight_bias': tensor([-2.4796e-04, -1.8585e-04, -1.8239e-04,  ...,  4.4560e-04,\n",
       "         -6.1572e-05,  5.8770e-05], dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.o_proj.weight_scale': tensor([1.1973, 1.2236, 1.2246,  ..., 1.1484, 1.2021, 1.1660],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.q_proj.centroids.weight': tensor([[ 0.0113, -0.0077, -0.0283,  ...,  0.0253, -0.0059, -0.0262]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.q_proj.indices': tensor([[[ -734922732,   719111821,  1578278605,  ..., -2144553906,\n",
       "            1248731213,   591454389],\n",
       "          [-1755612864, -1158277930,  -693429552,  ...,   998026479,\n",
       "           -1972842604,  1608241015],\n",
       "          [   83636386, -1201263414,   -63286645,  ...,   550334637,\n",
       "           -1358018950, -1825953792],\n",
       "          ...,\n",
       "          [  -67970206,  1532007104,  1258579448,  ..., -1207668342,\n",
       "            1808295470,  1180236354],\n",
       "          [-1975768518,  -515740234,   787802695,  ...,  1967509049,\n",
       "            1075919909,  1743701110],\n",
       "          [  -95202600, -1125939671,   957661771,  ..., -1344312178,\n",
       "           -2084880548, -1615976372]]], dtype=torch.int32),\n",
       " 'model.layers.22.self_attn.q_proj.perm': tensor([2789, 1076, 3209,  ...,  630, 2918, 1415], dtype=torch.int16),\n",
       " 'model.layers.22.self_attn.q_proj.weight_bias': tensor([ 0.0008, -0.0011, -0.0017,  ...,  0.0012, -0.0009, -0.0016],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.q_proj.weight_scale': tensor([1.4326, 1.4727, 1.4512,  ..., 1.4404, 1.4346, 1.4434],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.v_proj.centroids.weight': tensor([[-0.0031, -0.0087,  0.0053,  ..., -0.0217,  0.0208, -0.0073]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.v_proj.indices': tensor([[[-1582812915,  -697933499,   954784380,  ..., -2138137729,\n",
       "            1721245633,  -421818716],\n",
       "          [ -695894548,    42872612, -1545378488,  ..., -1889721002,\n",
       "           -1296614748, -1749311811],\n",
       "          [ 1164159071,  1860681697,   866552094,  ...,   805954144,\n",
       "            -741782268, -1837201855],\n",
       "          ...,\n",
       "          [  905497284,  1761352859,   792814917,  ..., -1393916415,\n",
       "           -2078609758, -1173501207],\n",
       "          [ -537280380,  -565564520,  1743798092,  ...,  -846461481,\n",
       "            1911544639,  -572108860],\n",
       "          [ 1604031574,   312694479,  1925350849,  ...,  -999924246,\n",
       "            -232262957,   -20800695]]], dtype=torch.int32),\n",
       " 'model.layers.22.self_attn.v_proj.perm': tensor([2789, 1076, 3209,  ...,  630, 2918, 1415], dtype=torch.int16),\n",
       " 'model.layers.22.self_attn.v_proj.weight_bias': tensor([-4.3988e-04, -2.8157e-04, -2.0182e-04,  ...,  1.0729e-06,\n",
       "         -1.2646e-03, -5.4646e-04], dtype=torch.float16),\n",
       " 'model.layers.22.self_attn.v_proj.weight_scale': tensor([1.1621, 1.1367, 1.1699,  ..., 1.1299, 1.1553, 1.1670],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.input_layernorm.weight': tensor([0.4993, 0.5298, 0.5132,  ..., 0.5015, 0.5205, 0.5386],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.mlp.down_proj.centroids.weight': tensor([[ 0.0142, -0.0008,  0.0005,  ..., -0.0307, -0.0247,  0.0086]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.mlp.down_proj.indices': tensor([[[ -608903208,  1951206548,  1686526279,  ...,   346203160,\n",
       "           -1270407100, -1161181952],\n",
       "          [ 1323888933, -1107884783,  -679076817,  ...,  -950714390,\n",
       "            1204007838,  -248184074],\n",
       "          [   56360431,  1420892594,  -702820598,  ...,  1233532720,\n",
       "            -244596180,  -657339032],\n",
       "          ...,\n",
       "          [ -952747229,  1753282903,   335086235,  ...,  -631335139,\n",
       "            -347750751,  -330254569],\n",
       "          [ 1446343110,   168662856, -2049195843,  ...,  1267274074,\n",
       "            1357853303, -1665267419],\n",
       "          [ -224517647, -1550240511,  1090695230,  ...,   343932613,\n",
       "            2069803267,   169634892]]], dtype=torch.int32),\n",
       " 'model.layers.23.mlp.down_proj.perm': tensor([10092,  6900, 10953,  ...,  6920,  1455,  2533], dtype=torch.int16),\n",
       " 'model.layers.23.mlp.down_proj.weight_bias': tensor([ 2.8467e-04, -2.8324e-04,  2.2113e-05,  ..., -2.6011e-04,\n",
       "         -1.9085e-04,  1.9073e-05], dtype=torch.float16),\n",
       " 'model.layers.23.mlp.down_proj.weight_scale': tensor([1.1650, 1.1797, 1.1904,  ..., 1.1582, 1.1553, 1.1680],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.mlp.gate_proj.centroids.weight': tensor([[ 0.0061, -0.0067,  0.0083,  ...,  0.0050, -0.0084, -0.0088]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.mlp.gate_proj.indices': tensor([[[ 1970164180,    45344918,  1993715165,  ...,  -718030566,\n",
       "            1996591407,  -171468175],\n",
       "          [-1759807025,   623620599, -2113556147,  ...,  1524839252,\n",
       "            1733874093, -1765551234],\n",
       "          [-1535832981,   -42610001,  1061045280,  ...,  1951645478,\n",
       "            1162221756,  -427699668],\n",
       "          ...,\n",
       "          [-2087959031,  -778390591, -1430832133,  ...,  1799727485,\n",
       "           -1121804782,  -525664536],\n",
       "          [ 2002911862,   968277052, -1911842468,  ...,  -952175700,\n",
       "            2030025981,   237310041],\n",
       "          [ 1430258514,  1517362835,  -303350991,  ..., -1075432802,\n",
       "            -830988051,  -309763797]]], dtype=torch.int32),\n",
       " 'model.layers.23.mlp.gate_proj.perm': tensor([1512, 2622, 1793,  ..., 3130, 3497, 3431], dtype=torch.int16),\n",
       " 'model.layers.23.mlp.gate_proj.weight_bias': tensor([-0.0031, -0.0006,  0.0022,  ...,  0.0010,  0.0014,  0.0009],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.mlp.gate_proj.weight_scale': tensor([2.1035, 2.0938, 2.0859,  ..., 2.0918, 2.0898, 2.1133],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.mlp.up_proj.centroids.weight': tensor([[ 0.0099,  0.0236, -0.0003,  ...,  0.0037, -0.0088, -0.0058]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.mlp.up_proj.indices': tensor([[[ 1614490485, -1286235351,  -368251530,  ...,  -216803092,\n",
       "            1662465504, -1781169883],\n",
       "          [ 1742765975,  1501419541,  1919097416,  ...,   159023637,\n",
       "            -627138188,  1489857801],\n",
       "          [  896826732,  -292365917,  -278900113,  ...,  -278125746,\n",
       "            -410900384,    19936445],\n",
       "          ...,\n",
       "          [-2103159631,   571429509, -2054202811,  ...,  -968396725,\n",
       "           -1968524688,   205647153],\n",
       "          [ 1400793296, -1476857211,   502184754,  ...,  1848611449,\n",
       "            -213787363,   184522282],\n",
       "          [  698465488,  1783122414,  -100833198,  ...,  -100056368,\n",
       "            -966064174, -1418821385]]], dtype=torch.int32),\n",
       " 'model.layers.23.mlp.up_proj.perm': tensor([1512, 2622, 1793,  ..., 3130, 3497, 3431], dtype=torch.int16),\n",
       " 'model.layers.23.mlp.up_proj.weight_bias': tensor([-0.0001,  0.0002,  0.0004,  ...,  0.0003, -0.0002,  0.0003],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.mlp.up_proj.weight_scale': tensor([1.9297, 1.9482, 1.9561,  ..., 1.9541, 1.9443, 1.9277],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.post_attention_layernorm.weight': tensor([0.3997, 0.3962, 0.3992,  ..., 0.3999, 0.3943, 0.4023],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.k_proj.centroids.weight': tensor([[-0.0048, -0.0116, -0.0055,  ...,  0.0038,  0.0235,  0.0065]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.k_proj.indices': tensor([[[  684795043, -1831245872,   919212161,  ...,  1039708230,\n",
       "           -1139452537, -1813621759],\n",
       "          [  671254823,  1987798963,  2022511173,  ..., -1189033091,\n",
       "            -376021794, -1120530342],\n",
       "          [-1715088532,  1436099445,  -696312383,  ..., -1954516760,\n",
       "            1386905809,   733554025],\n",
       "          ...,\n",
       "          [-1672732675,   526033001,  -955149691,  ...,  1895741270,\n",
       "             812485566,  -344042128],\n",
       "          [  337884366, -1036269931,  1531882080,  ...,  -268022124,\n",
       "           -2106109265,  1098477466],\n",
       "          [-2059157506,  -323389765,  -208505279,  ...,  1843179466,\n",
       "           -1972033021,  1658498914]]], dtype=torch.int32),\n",
       " 'model.layers.23.self_attn.k_proj.perm': tensor([2789, 1076, 3431,  ..., 2747, 1759, 1415], dtype=torch.int16),\n",
       " 'model.layers.23.self_attn.k_proj.weight_bias': tensor([ 1.3876e-03,  9.1362e-04, -1.4811e-03,  ...,  2.5806e-03,\n",
       "         -4.8280e-04,  7.6473e-05], dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.k_proj.weight_scale': tensor([1.4443, 1.4834, 1.4717,  ..., 1.4766, 1.4521, 1.4775],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.o_proj.centroids.weight': tensor([[ 0.0260, -0.0180, -0.0068,  ..., -0.0069, -0.0205, -0.0232]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.o_proj.indices': tensor([[[ -590507694,   808604194,   777255301,  ..., -1401542453,\n",
       "             719903935, -1993628480],\n",
       "          [  781688239,   545737954, -1112302150,  ..., -1634358600,\n",
       "             -78604104,  -534461906],\n",
       "          [ -993625197,   924392911,  1336468059,  ...,  -563436800,\n",
       "            -440160212,   715444162],\n",
       "          ...,\n",
       "          [ 1653014494,  1148755801, -1736679209,  ...,  -370704277,\n",
       "            1592288780,   636980603],\n",
       "          [  948464704,   456573492,  1470952057,  ...,  -139527042,\n",
       "             173078955,  -356298263],\n",
       "          [ -497135637,  -343114052,  -490409641,  ..., -1017082232,\n",
       "            2123499742,   209381128]]], dtype=torch.int32),\n",
       " 'model.layers.23.self_attn.o_proj.perm': tensor([ 185,  137,  484,  ..., 2869, 2878, 1839], dtype=torch.int16),\n",
       " 'model.layers.23.self_attn.o_proj.weight_bias': tensor([-0.0003, -0.0005, -0.0002,  ...,  0.0002, -0.0004,  0.0003],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.o_proj.weight_scale': tensor([1.0850, 1.0654, 1.1182,  ..., 1.1240, 1.1104, 1.1338],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.q_proj.centroids.weight': tensor([[-0.0204, -0.0106, -0.0126,  ...,  0.0458, -0.0188, -0.0109]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.q_proj.indices': tensor([[[ 1287472134,   910970214, -1248441172,  ..., -2066080812,\n",
       "           -1156064086,  -435762120],\n",
       "          [  565924997, -1572386576,  -403263174,  ...,  1090662273,\n",
       "            1692674633,  -435547862],\n",
       "          [-1886253294, -1407820652,  1831664821,  ..., -1368851200,\n",
       "             163616049,  -436007346],\n",
       "          ...,\n",
       "          [ -193748085, -1660943045,  1447272765,  ...,   403555265,\n",
       "           -2073661557,  1518246310],\n",
       "          [ -778639580, -1609364722, -1925999105,  ..., -1118174152,\n",
       "             731518825, -1925362519],\n",
       "          [ 2000516214,   529304976,  -659641105,  ...,   943740188,\n",
       "            -820585509,   221724883]]], dtype=torch.int32),\n",
       " 'model.layers.23.self_attn.q_proj.perm': tensor([2789, 1076, 3431,  ..., 2747, 1759, 1415], dtype=torch.int16),\n",
       " 'model.layers.23.self_attn.q_proj.weight_bias': tensor([-1.7328e-03,  1.2608e-03, -5.0688e-04,  ..., -2.0611e-04,\n",
       "          8.3160e-04,  7.7248e-05], dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.q_proj.weight_scale': tensor([1.4268, 1.4395, 1.4189,  ..., 1.4619, 1.4033, 1.4395],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.v_proj.centroids.weight': tensor([[ 0.0151,  0.0022,  0.0067,  ..., -0.0217,  0.0295,  0.0182]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.v_proj.indices': tensor([[[ -433419326,   891148020,  1780292919,  ..., -1022028583,\n",
       "             655435571,  -584587831],\n",
       "          [-2011896168,  -309314115,  -860329901,  ...,   530106177,\n",
       "            2105958922,  1787721247],\n",
       "          [ -964376018,  -149309940, -1197609265,  ..., -2105542104,\n",
       "           -1419511640,  1401674582],\n",
       "          ...,\n",
       "          [ -751915958,     6728176,  -479558546,  ...,  1418444364,\n",
       "            1757492193,   539542404],\n",
       "          [-2072619137, -2019002228,  1998215534,  ..., -1578079739,\n",
       "             740018800,   398673534],\n",
       "          [ 1986303710,  -983301230,  1447357629,  ...,   373520679,\n",
       "            -499457476,   547206850]]], dtype=torch.int32),\n",
       " 'model.layers.23.self_attn.v_proj.perm': tensor([2789, 1076, 3431,  ..., 2747, 1759, 1415], dtype=torch.int16),\n",
       " 'model.layers.23.self_attn.v_proj.weight_bias': tensor([-0.0004,  0.0004,  0.0006,  ..., -0.0002,  0.0002, -0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.23.self_attn.v_proj.weight_scale': tensor([1.1846, 1.1904, 1.2324,  ..., 1.1602, 1.2227, 1.2520],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.input_layernorm.weight': tensor([0.4810, 0.5215, 0.5220,  ..., 0.4951, 0.5132, 0.5068],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.mlp.down_proj.centroids.weight': tensor([[ 0.0325,  0.0014,  0.0152,  ..., -0.0174,  0.0168,  0.0065]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.mlp.down_proj.indices': tensor([[[-1020760808,  1788966085,   457192019,  ...,   549101926,\n",
       "           -1196100126,  -535677283],\n",
       "          [ -252383464, -2034396866,   -13537716,  ...,   640670926,\n",
       "           -1250457944,  2086882152],\n",
       "          [ -733706892,  1106174057,  1249774750,  ...,  1324408367,\n",
       "            2015250260,  1860236152],\n",
       "          ...,\n",
       "          [-1413224567, -1582628593, -1975072772,  ...,  -362456098,\n",
       "             986838875, -1844943320],\n",
       "          [ 1048019809,  1670110549,  -815196358,  ..., -1597471254,\n",
       "             465772909, -1550002771],\n",
       "          [-1476953822,  1692898922,  -121820013,  ..., -1492317235,\n",
       "            -992725958,  -595701071]]], dtype=torch.int32),\n",
       " 'model.layers.24.mlp.down_proj.perm': tensor([9414, 4425, 3700,  ..., 9203, 5157, 5251], dtype=torch.int16),\n",
       " 'model.layers.24.mlp.down_proj.weight_bias': tensor([ 3.6454e-04, -3.4738e-04,  2.7394e-04,  ..., -5.8889e-05,\n",
       "          1.8239e-04, -2.3603e-05], dtype=torch.float16),\n",
       " 'model.layers.24.mlp.down_proj.weight_scale': tensor([1.1455, 1.1553, 1.1758,  ..., 1.2412, 1.1553, 1.1592],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.mlp.gate_proj.centroids.weight': tensor([[ 0.0087, -0.0120, -0.0048,  ..., -0.0082, -0.0150,  0.0004]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.mlp.gate_proj.indices': tensor([[[ -128747648,   146198301,   255842725,  ...,  1168652765,\n",
       "           -1605259741,   239858697],\n",
       "          [  925976810, -1865510558, -1741768401,  ..., -1082534186,\n",
       "           -1816777309,  -451940682],\n",
       "          [-1644357514, -1331827262,  1784234685,  ..., -1437842675,\n",
       "           -2062180628,  1297992934],\n",
       "          ...,\n",
       "          [  871012970, -1010748318, -1794690920,  ..., -2115133345,\n",
       "            -711408714,  -610436466],\n",
       "          [-1819890043,   701994157,   245719152,  ...,   170225599,\n",
       "             -42731057,  -400115355],\n",
       "          [  599673168,  -938423283,    22234268,  ..., -1290991330,\n",
       "             604669918,  1920480991]]], dtype=torch.int32),\n",
       " 'model.layers.24.mlp.gate_proj.perm': tensor([2622, 1512,  363,  ..., 3497, 1397,  623], dtype=torch.int16),\n",
       " 'model.layers.24.mlp.gate_proj.weight_bias': tensor([-0.0026, -0.0001,  0.0013,  ...,  0.0005,  0.0016,  0.0015],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.mlp.gate_proj.weight_scale': tensor([2.0977, 2.1035, 2.1152,  ..., 2.1211, 2.0664, 2.1035],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.mlp.up_proj.centroids.weight': tensor([[ 0.0027,  0.0173,  0.0203,  ...,  0.0200,  0.0080, -0.0142]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.mlp.up_proj.indices': tensor([[[ -641077914,  1310227988, -1882855778,  ...,  2033675849,\n",
       "            -133872428,  -459794368],\n",
       "          [   92530515,  -630875591,  -373490375,  ...,  -749115670,\n",
       "            1309918668,  -707394925],\n",
       "          [-1095915260, -1066376591, -1666773766,  ...,  2129960692,\n",
       "            1842186368,  -195807286],\n",
       "          ...,\n",
       "          [-2091647077, -1813175204,  1412866186,  ...,  1275282358,\n",
       "           -2126066713,  -463928178],\n",
       "          [ -799389117,  -397324276, -2132998148,  ...,   202556377,\n",
       "             642425448, -1041556922],\n",
       "          [  747759253, -1532753524,   -91134367,  ...,  -161680959,\n",
       "           -1564769656,  -281033375]]], dtype=torch.int32),\n",
       " 'model.layers.24.mlp.up_proj.perm': tensor([2622, 1512,  363,  ..., 3497, 1397,  623], dtype=torch.int16),\n",
       " 'model.layers.24.mlp.up_proj.weight_bias': tensor([ 1.1325e-05,  9.3877e-05,  2.1338e-04,  ...,  7.7188e-05,\n",
       "          1.0198e-04, -3.0875e-05], dtype=torch.float16),\n",
       " 'model.layers.24.mlp.up_proj.weight_scale': tensor([1.9502, 1.9463, 1.9355,  ..., 1.9414, 1.9688, 1.9561],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.post_attention_layernorm.weight': tensor([0.4133, 0.4089, 0.4087,  ..., 0.4148, 0.4082, 0.4138],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.k_proj.centroids.weight': tensor([[-0.0145,  0.0085,  0.0099,  ..., -0.0297,  0.0453,  0.0034]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.k_proj.indices': tensor([[[  -93696401,   681623078,  1174232510,  ...,  1189901603,\n",
       "             681730662,  1639325214],\n",
       "          [ 1570570781, -1159870963,  1399297366,  ...,  1635227507,\n",
       "             806827341,   -13805020],\n",
       "          [  245844357,   555466286,   392744341,  ..., -2008435536,\n",
       "            -298600978,   329650260],\n",
       "          ...,\n",
       "          [ -491637765, -1059024789,  2036293996,  ...,   739816683,\n",
       "           -1879193279,  -888098121],\n",
       "          [ -937262125,   309444481,  -621668313,  ...,    42621426,\n",
       "            -307536629,   946175536],\n",
       "          [ 1274052922,  -721075214,  2041920904,  ..., -1749028967,\n",
       "           -1013702047, -2113578729]]], dtype=torch.int32),\n",
       " 'model.layers.24.self_attn.k_proj.perm': tensor([2789, 1076, 3431,  ..., 2747,  573, 1415], dtype=torch.int16),\n",
       " 'model.layers.24.self_attn.k_proj.weight_bias': tensor([-0.0042,  0.0011,  0.0013,  ...,  0.0002, -0.0011,  0.0013],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.k_proj.weight_scale': tensor([1.4102, 1.4482, 1.4111,  ..., 1.3975, 1.3672, 1.4043],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.o_proj.centroids.weight': tensor([[-0.0005,  0.0309, -0.0080,  ...,  0.0280, -0.0282, -0.0024]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.o_proj.indices': tensor([[[-1966087532, -1190910187,   887506682,  ...,    65315229,\n",
       "             149974112,  -664192335],\n",
       "          [  415290514,  -368727894,  -822728368,  ...,   -39319977,\n",
       "             299540072, -2020005912],\n",
       "          [-1073382694,  -132965841,  -812983789,  ...,  -626291549,\n",
       "           -1193240497,  -751418351],\n",
       "          ...,\n",
       "          [  766199280, -1477609852, -2083580982,  ...,  -144902996,\n",
       "            1372300966, -1401108862],\n",
       "          [   92619458, -1299340495,  1919721509,  ..., -1687131075,\n",
       "            1160150915, -2064427868],\n",
       "          [ 1563571897,    49593120,  1417443941,  ...,   656732525,\n",
       "            -347439045,  1103542780]]], dtype=torch.int32),\n",
       " 'model.layers.24.self_attn.o_proj.perm': tensor([3054, 1746,  815,  ...,  317, 2824,  336], dtype=torch.int16),\n",
       " 'model.layers.24.self_attn.o_proj.weight_bias': tensor([-7.9751e-05, -8.6188e-05, -8.5056e-05,  ...,  5.8365e-04,\n",
       "         -6.2084e-04, -1.7929e-04], dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.o_proj.weight_scale': tensor([1.2256, 1.2227, 1.2100,  ..., 1.1680, 1.1582, 1.1641],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.q_proj.centroids.weight': tensor([[-0.0026, -0.0174, -0.0073,  ..., -0.0379,  0.0172,  0.0455]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.q_proj.indices': tensor([[[  588607306,  1869725115,   145315736,  ...,   243655974,\n",
       "           -1964689705,  1791251433],\n",
       "          [-1802202221, -1782975281,  1914810740,  ...,  -514276011,\n",
       "            -423437493,  -183685737],\n",
       "          [ -857806591,  -680183116,  1405233201,  ...,  -531047650,\n",
       "            -407570656,  -579856866],\n",
       "          ...,\n",
       "          [  855851081, -1603270910, -1806501322,  ...,   506886655,\n",
       "            1311169100,  1030456300],\n",
       "          [  586876015,  1165932329,   106814564,  ...,   108502410,\n",
       "           -1514599371,  1265238417],\n",
       "          [  205734525, -2115164203, -1421602455,  ..., -1507338134,\n",
       "            -139193434,  1585455419]]], dtype=torch.int32),\n",
       " 'model.layers.24.self_attn.q_proj.perm': tensor([2789, 1076, 3431,  ..., 2747,  573, 1415], dtype=torch.int16),\n",
       " 'model.layers.24.self_attn.q_proj.weight_bias': tensor([ 5.1975e-05,  5.2643e-04,  7.7200e-04,  ...,  8.8692e-04,\n",
       "          5.8126e-04, -1.5774e-03], dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.q_proj.weight_scale': tensor([1.3828, 1.3936, 1.4033,  ..., 1.4229, 1.4082, 1.3848],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.v_proj.centroids.weight': tensor([[-0.0046, -0.0204, -0.0213,  ...,  0.0019, -0.0172, -0.0115]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.v_proj.indices': tensor([[[-2034719817,   386660140, -1699440886,  ...,   864195597,\n",
       "           -1900528916,   572410996],\n",
       "          [ -122439200,  1167378922,  -489571198,  ...,  2093665496,\n",
       "           -1081512044,   758833561],\n",
       "          [ 1299364733,  1592909179,  -485401242,  ...,  -950777537,\n",
       "            1481031679,  1636440919],\n",
       "          ...,\n",
       "          [ -837292170, -1873636100,   -28324765,  ...,  -164120747,\n",
       "            -351859993, -2011312141],\n",
       "          [  202156949,  1868664420,  -774459704,  ...,  1664637813,\n",
       "            -311558243,   135240143],\n",
       "          [ 1259448175,   737526366,   823978881,  ...,   321104825,\n",
       "             925904804,  1971430721]]], dtype=torch.int32),\n",
       " 'model.layers.24.self_attn.v_proj.perm': tensor([2789, 1076, 3431,  ..., 2747,  573, 1415], dtype=torch.int16),\n",
       " 'model.layers.24.self_attn.v_proj.weight_bias': tensor([ 1.0262e-03, -7.2956e-04, -3.1972e-04,  ...,  4.8256e-04,\n",
       "         -5.1439e-05,  2.0230e-04], dtype=torch.float16),\n",
       " 'model.layers.24.self_attn.v_proj.weight_scale': tensor([1.1914, 1.1768, 1.2031,  ..., 1.2275, 1.2051, 1.2178],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.input_layernorm.weight': tensor([0.5562, 0.5596, 0.5488,  ..., 0.5449, 0.5649, 0.5615],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.mlp.down_proj.centroids.weight': tensor([[ 0.0133,  0.0108, -0.0002,  ...,  0.0193,  0.0166,  0.0190]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.mlp.down_proj.indices': tensor([[[  858127634, -1191033115,   788839662,  ...,    56748167,\n",
       "           -2044583639, -1675556320],\n",
       "          [-1148320671, -1237477488,  -879923204,  ...,   -96198170,\n",
       "           -1138150260,   368112800],\n",
       "          [ -203663419,  1493856954, -2094665203,  ...,  1883969157,\n",
       "             736684627,  1313933827],\n",
       "          ...,\n",
       "          [-1589664252,  1275510625,   173338989,  ...,  1234935593,\n",
       "            -977735815, -1955676734],\n",
       "          [-1503721531,  -458596990,   172203825,  ...,   -69730765,\n",
       "            -982721207, -1854842634],\n",
       "          [  -69849847,  -821703181, -1794117006,  ...,   467778762,\n",
       "            1669801223,   146023130]]], dtype=torch.int32),\n",
       " 'model.layers.25.mlp.down_proj.perm': tensor([10041,  5291,  4189,  ...,  2325,  1662,  9091], dtype=torch.int16),\n",
       " 'model.layers.25.mlp.down_proj.weight_bias': tensor([-1.5402e-04, -3.0231e-04, -6.1131e-04,  ..., -1.7655e-04,\n",
       "         -1.3220e-04,  5.8174e-05], dtype=torch.float16),\n",
       " 'model.layers.25.mlp.down_proj.weight_scale': tensor([1.1475, 1.1309, 1.1992,  ..., 1.1621, 1.1650, 1.1748],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.mlp.gate_proj.centroids.weight': tensor([[ 6.8512e-03, -4.0650e-04,  9.4604e-03,  ...,  5.0128e-05,\n",
       "           1.1168e-03, -1.0986e-02]], dtype=torch.float16),\n",
       " 'model.layers.25.mlp.gate_proj.indices': tensor([[[-1489993204,   532253185,  -311796955,  ...,   795926462,\n",
       "            -192206357, -1843416071],\n",
       "          [ 1897512432,  1063305790, -1289369226,  ...,  1438123713,\n",
       "            -542002382,  -864475469],\n",
       "          [ 1941913135, -1687088356,   -79706814,  ...,  -150384028,\n",
       "            1404460633,   391032519],\n",
       "          ...,\n",
       "          [  999351923, -1598484636,  -142571369,  ...,   788823932,\n",
       "           -1162796658, -1264953264],\n",
       "          [ -440673470,  1872050759, -1015291414,  ...,   566511810,\n",
       "            -501606563,  1232997563],\n",
       "          [ -358210633,   583672422,   248687769,  ...,  1559341659,\n",
       "           -1208992903,  -119843697]]], dtype=torch.int32),\n",
       " 'model.layers.25.mlp.gate_proj.perm': tensor([1512, 2622, 2789,  ..., 1187, 3497,  449], dtype=torch.int16),\n",
       " 'model.layers.25.mlp.gate_proj.weight_bias': tensor([-0.0016, -0.0006,  0.0002,  ...,  0.0012,  0.0018,  0.0012],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.mlp.gate_proj.weight_scale': tensor([2.0996, 2.1016, 2.1289,  ..., 2.1250, 2.0762, 2.1152],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.mlp.up_proj.centroids.weight': tensor([[ 0.0032,  0.0077,  0.0104,  ..., -0.0026,  0.0032, -0.0025]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.mlp.up_proj.indices': tensor([[[ 1756056735,  -622707264,  1174024538,  ..., -1947183509,\n",
       "            1972042631,  -923047188],\n",
       "          [-1340783625,  1942170698,  -193531463,  ...,    62694669,\n",
       "            -764084355,  -240900794],\n",
       "          [ 2063049237, -1742981187,  1270742721,  ...,   150747143,\n",
       "            1249362988, -2033046188],\n",
       "          ...,\n",
       "          [-1257023968,     2185699,  1616672463,  ...,   505228751,\n",
       "            1829380510,  1888685573],\n",
       "          [ -467498871,  1801849148,  1379273781,  ..., -1400347348,\n",
       "            1829785290,  1859752870],\n",
       "          [-1145989737,    22786187, -1166612733,  ...,  -730020125,\n",
       "            -793844519,   634424456]]], dtype=torch.int32),\n",
       " 'model.layers.25.mlp.up_proj.perm': tensor([1512, 2622, 2789,  ..., 1187, 3497,  449], dtype=torch.int16),\n",
       " 'model.layers.25.mlp.up_proj.weight_bias': tensor([ 3.7837e-04,  7.5817e-05, -2.3401e-04,  ...,  1.7369e-04,\n",
       "          3.0696e-05, -2.0719e-04], dtype=torch.float16),\n",
       " 'model.layers.25.mlp.up_proj.weight_scale': tensor([1.9590, 1.9609, 1.9395,  ..., 1.9414, 1.9697, 1.9619],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.post_attention_layernorm.weight': tensor([0.4197, 0.4207, 0.4260,  ..., 0.4331, 0.4131, 0.4302],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.k_proj.centroids.weight': tensor([[-0.0154,  0.0031,  0.0157,  ..., -0.0125,  0.0186,  0.0370]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.k_proj.indices': tensor([[[ -865373451,   734925359, -2004667886,  ...,   971789944,\n",
       "           -1824814965,   304690155],\n",
       "          [-1466021404, -1265692116, -1900553583,  ..., -2079534110,\n",
       "            -532823920,   858492896],\n",
       "          [-1002424125, -1189702497,  1587090990,  ..., -1125245262,\n",
       "           -1425478034, -1960472890],\n",
       "          ...,\n",
       "          [ -368665175, -1748532967, -1998515823,  ..., -1636000238,\n",
       "            1741945299,  -771763845],\n",
       "          [ -294822399,   981732845,  -860365276,  ..., -1663695507,\n",
       "             428475660,   582880253],\n",
       "          [ -352421366, -1537771124,  1949156471,  ..., -1547530880,\n",
       "            -577407508,   894646813]]], dtype=torch.int32),\n",
       " 'model.layers.25.self_attn.k_proj.perm': tensor([2789, 1076, 3431,  ...,  573, 3985, 1415], dtype=torch.int16),\n",
       " 'model.layers.25.self_attn.k_proj.weight_bias': tensor([-0.0042, -0.0008, -0.0015,  ..., -0.0023, -0.0001,  0.0011],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.k_proj.weight_scale': tensor([1.4121, 1.4521, 1.4033,  ..., 1.4082, 1.3965, 1.4355],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.o_proj.centroids.weight': tensor([[ 0.0245,  0.0184,  0.0108,  ..., -0.0100, -0.0074, -0.0015]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.o_proj.indices': tensor([[[-1559807440, -1303137934,  -290536913,  ...,   445134942,\n",
       "           -1275547076, -1722917924],\n",
       "          [  569152417,   941336309, -1211537895,  ...,  -317701678,\n",
       "               9240125,  -133840026],\n",
       "          [-1097111394,  -760932062,  -805104600,  ..., -1893276121,\n",
       "           -1496596566,  -408863800],\n",
       "          ...,\n",
       "          [  901765409,   991470181,  -701941187,  ...,  1140312432,\n",
       "           -1830211903, -1932094341],\n",
       "          [ -153427012,  -559494221, -1377016444,  ..., -1384233513,\n",
       "            1730647096,  -426887416],\n",
       "          [  -75141028,  1449281328,   250056240,  ..., -1288329259,\n",
       "             368390558,   917558257]]], dtype=torch.int32),\n",
       " 'model.layers.25.self_attn.o_proj.perm': tensor([ 754, 3634,  703,  ..., 1691, 1757, 1672], dtype=torch.int16),\n",
       " 'model.layers.25.self_attn.o_proj.weight_bias': tensor([ 0.0004, -0.0001, -0.0004,  ..., -0.0004, -0.0001, -0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.o_proj.weight_scale': tensor([1.2529, 1.2412, 1.2773,  ..., 1.2979, 1.3066, 1.2930],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.q_proj.centroids.weight': tensor([[ 0.0229,  0.0066,  0.0248,  ..., -0.0093,  0.0026, -0.0007]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.q_proj.indices': tensor([[[ -242501762,  -816046067, -1021029131,  ..., -1340572144,\n",
       "           -1112401804, -1267318007],\n",
       "          [ 1499726418,  -434820047,  1468406680,  ...,  -812718132,\n",
       "             972942883,  1449233209],\n",
       "          [ 2145404866,   548477111,  1787099022,  ...,   715706602,\n",
       "            1227885551,  -540141712],\n",
       "          ...,\n",
       "          [ 1166552665,  1526535763,  1844236205,  ...,   245918293,\n",
       "             788697556,  1377280744],\n",
       "          [ 1131467699,    84448313,  1454759598,  ...,  -430360095,\n",
       "             563002133,   968537867],\n",
       "          [  131616817,   919702298,  -497024976,  ..., -1790541764,\n",
       "           -1587786512, -1310219616]]], dtype=torch.int32),\n",
       " 'model.layers.25.self_attn.q_proj.perm': tensor([2789, 1076, 3431,  ...,  573, 3985, 1415], dtype=torch.int16),\n",
       " 'model.layers.25.self_attn.q_proj.weight_bias': tensor([ 0.0018,  0.0029, -0.0007,  ...,  0.0005,  0.0017,  0.0005],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.q_proj.weight_scale': tensor([1.4131, 1.4072, 1.4297,  ..., 1.4092, 1.3936, 1.4082],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.v_proj.centroids.weight': tensor([[-0.0199, -0.0209, -0.0090,  ..., -0.0009, -0.0382,  0.0111]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.v_proj.indices': tensor([[[ 1075936024,   227367319,  1532460723,  ...,  -860706774,\n",
       "           -2042308139,  -183987476],\n",
       "          [-1372100011,   556936336,  -160603631,  ...,  1479491131,\n",
       "            -778079851,   275870805],\n",
       "          [   53533531,  1045738525, -1412628404,  ..., -1842612798,\n",
       "           -1299987931,   736914687],\n",
       "          ...,\n",
       "          [ 1487702967,   506619902, -1167113859,  ...,   958129916,\n",
       "              71050702, -1048897045],\n",
       "          [   26656267,  -229017599, -1462224636,  ...,  -712448532,\n",
       "           -2136631202, -1006003738],\n",
       "          [ -925455881, -1297585729,  -419732033,  ...,   160839896,\n",
       "            1011433270,   186804613]]], dtype=torch.int32),\n",
       " 'model.layers.25.self_attn.v_proj.perm': tensor([2789, 1076, 3431,  ...,  573, 3985, 1415], dtype=torch.int16),\n",
       " 'model.layers.25.self_attn.v_proj.weight_bias': tensor([ 0.0002,  0.0005,  0.0003,  ...,  0.0005,  0.0001, -0.0001],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.25.self_attn.v_proj.weight_scale': tensor([1.2773, 1.2451, 1.2461,  ..., 1.2500, 1.2490, 1.2549],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.input_layernorm.weight': tensor([0.5063, 0.5381, 0.5244,  ..., 0.5161, 0.5376, 0.5435],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.mlp.down_proj.centroids.weight': tensor([[-0.0225, -0.0402,  0.0139,  ...,  0.0158,  0.0069,  0.0106]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.mlp.down_proj.indices': tensor([[[ -150001913, -1806853707, -1278356222,  ...,  2027832601,\n",
       "             367119601,  1793945019],\n",
       "          [ 1134281429,   960957630, -2135084671,  ...,  1236889167,\n",
       "            1523169550,  2066825085],\n",
       "          [ -271239774,  1436258680,   557795290,  ...,  1239480870,\n",
       "            1194183934,  2074849936],\n",
       "          ...,\n",
       "          [ -526786576,  -355456378, -1577233571,  ...,  -348904065,\n",
       "            -560420826,  -497421972],\n",
       "          [ -562825485,  -154616005, -1549765022,  ...,   388501282,\n",
       "            1327487833,  -520780785],\n",
       "          [-1995943964,  -804867267, -1425212715,  ...,  -591564970,\n",
       "           -2006551907, -1431147885]]], dtype=torch.int32),\n",
       " 'model.layers.26.mlp.down_proj.perm': tensor([ 6753, 10155,  7843,  ...,  9923,  1494,  2890], dtype=torch.int16),\n",
       " 'model.layers.26.mlp.down_proj.weight_bias': tensor([ 1.2326e-04, -2.1434e-04,  2.8825e-04,  ...,  8.1062e-05,\n",
       "          1.5068e-04, -3.9434e-04], dtype=torch.float16),\n",
       " 'model.layers.26.mlp.down_proj.weight_scale': tensor([1.1787, 1.1846, 1.0840,  ..., 1.1738, 1.1631, 1.1865],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.mlp.gate_proj.centroids.weight': tensor([[ 0.0058, -0.0168, -0.0008,  ..., -0.0001,  0.0204, -0.0032]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.mlp.gate_proj.indices': tensor([[[-1193928950,   145718138,  -603463335,  ..., -1944807601,\n",
       "            2120598443,  -989016769],\n",
       "          [   -6858891,  -954676498,   203193730,  ...,   751754839,\n",
       "             293376601,  -607162182],\n",
       "          [ 1220832706,  1614755117,  -437919843,  ...,  1816937381,\n",
       "            1054542721, -1510384458],\n",
       "          ...,\n",
       "          [-1477621096,    -8529898,   545805831,  ...,   478125239,\n",
       "           -1874285354,   805000961],\n",
       "          [ -293873779,  2043939283,  -357319285,  ...,  2086425811,\n",
       "             -25665877,  1384403117],\n",
       "          [ -437200603, -1901908656,   295379376,  ...,  -233727411,\n",
       "            -675438359,   988505211]]], dtype=torch.int32),\n",
       " 'model.layers.26.mlp.gate_proj.perm': tensor([2622,  363, 1512,  ..., 3046, 1397, 1076], dtype=torch.int16),\n",
       " 'model.layers.26.mlp.gate_proj.weight_bias': tensor([-0.0018, -0.0003, -0.0003,  ...,  0.0012,  0.0018,  0.0009],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.mlp.gate_proj.weight_scale': tensor([2.1230, 2.0820, 2.1133,  ..., 2.1113, 2.0723, 2.1113],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.mlp.up_proj.centroids.weight': tensor([[ 0.0106,  0.0074, -0.0091,  ...,  0.0047, -0.0027, -0.0158]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.mlp.up_proj.indices': tensor([[[ -960258605,    28735249,  -471265705,  ...,  1131115000,\n",
       "            -726310826,   813440002],\n",
       "          [-1863621126,  -119949966,  2011144174,  ...,  1297474871,\n",
       "            1255680827,  1366927683],\n",
       "          [-1497906465,  -835662683,  -784587340,  ..., -1577358324,\n",
       "            -625404646, -1449571198],\n",
       "          ...,\n",
       "          [ -936261194, -1517305722,   300560619,  ...,  -597660440,\n",
       "             634400533, -2009655403],\n",
       "          [ 1194806836,   497254394,  1929948240,  ...,  2052979488,\n",
       "            2006527634, -1314288269],\n",
       "          [ -834314325,  1486911733, -1774553815,  ...,  2050657189,\n",
       "            2145437852,  -202962375]]], dtype=torch.int32),\n",
       " 'model.layers.26.mlp.up_proj.perm': tensor([2622,  363, 1512,  ..., 3046, 1397, 1076], dtype=torch.int16),\n",
       " 'model.layers.26.mlp.up_proj.weight_bias': tensor([-6.9141e-05,  1.4377e-04,  4.8828e-04,  ..., -9.6262e-05,\n",
       "          5.7268e-04, -6.6996e-05], dtype=torch.float16),\n",
       " 'model.layers.26.mlp.up_proj.weight_scale': tensor([1.9463, 1.9932, 1.9707,  ..., 1.9824, 1.9736, 1.9707],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.post_attention_layernorm.weight': tensor([0.4341, 0.4377, 0.4368,  ..., 0.4468, 0.4292, 0.4414],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.k_proj.centroids.weight': tensor([[ 0.0094, -0.0207,  0.0458,  ..., -0.0106, -0.0048, -0.0075]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.k_proj.indices': tensor([[[  692387156,  2092336505,     4583301,  ...,   137155359,\n",
       "            2031519095, -1972364533],\n",
       "          [ 2035603207, -1853804878,  1364121746,  ...,  -858428188,\n",
       "             344393880,  1873713436],\n",
       "          [ 1942009402,  -434876292, -1677020214,  ..., -1808376792,\n",
       "           -1684091354,  1121775394],\n",
       "          ...,\n",
       "          [-1916607089,  -357943384, -1694635408,  ...,  -280280547,\n",
       "           -2141645409,   427587409],\n",
       "          [ 2018407846, -1380433513,   379884452,  ...,  -298136302,\n",
       "           -1986266882,  -990098539],\n",
       "          [ 1220226229,  -609028210, -1154901174,  ..., -1648900926,\n",
       "             969780067,  -460777580]]], dtype=torch.int32),\n",
       " 'model.layers.26.self_attn.k_proj.perm': tensor([2789, 1076, 3431,  ..., 1301,  573, 1415], dtype=torch.int16),\n",
       " 'model.layers.26.self_attn.k_proj.weight_bias': tensor([ 0.0023,  0.0006, -0.0002,  ...,  0.0012, -0.0003,  0.0011],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.k_proj.weight_scale': tensor([1.3691, 1.4443, 1.3945,  ..., 1.3965, 1.3926, 1.3877],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.o_proj.centroids.weight': tensor([[ 0.0072,  0.0163,  0.0328,  ..., -0.0079,  0.0036, -0.0057]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.o_proj.indices': tensor([[[ 1928802162,  1801674255,  1796334267,  ..., -1044322169,\n",
       "             457428873, -1576418501],\n",
       "          [-1932997492,  -421427812,  -768378128,  ...,   795258909,\n",
       "           -1389095976,  1044752418],\n",
       "          [ 1118407320,  1419682230, -1961322357,  ...,   887088690,\n",
       "             366723509,   614861341],\n",
       "          ...,\n",
       "          [ 1416972116,  1019373911, -1838705925,  ..., -1150539137,\n",
       "           -1152058609,   212162317],\n",
       "          [-1143226949,   143807597,  -602645547,  ..., -1547053200,\n",
       "           -1283094497,  -574140585],\n",
       "          [ 1741356207,   -44701545,  1921202202,  ..., -1977151092,\n",
       "             604919740,   656038653]]], dtype=torch.int32),\n",
       " 'model.layers.26.self_attn.o_proj.perm': tensor([2498, 2491, 2556,  ..., 1587, 1556, 1582], dtype=torch.int16),\n",
       " 'model.layers.26.self_attn.o_proj.weight_bias': tensor([ 2.5678e-04,  2.1338e-04,  3.8600e-04,  ..., -1.8668e-04,\n",
       "          3.6240e-04,  1.5080e-05], dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.o_proj.weight_scale': tensor([1.3223, 1.3047, 1.3037,  ..., 1.2480, 1.2373, 1.2256],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.q_proj.centroids.weight': tensor([[ 0.0070,  0.0233, -0.0108,  ...,  0.0042, -0.0205,  0.0015]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.q_proj.indices': tensor([[[ -138664550,  1926481248,   733321964,  ..., -2097654081,\n",
       "             478464503,  1423000261],\n",
       "          [-1662329728, -1795893253,   660725670,  ...,   615958771,\n",
       "             831869470,  1423064196],\n",
       "          [ 1472147110,  -781151740,   855883481,  ...,  -307756449,\n",
       "            1343657684,  1423561009],\n",
       "          ...,\n",
       "          [ 1161591519,   100521193,  -464483723,  ..., -1515621520,\n",
       "            1212200455,  -406458827],\n",
       "          [ -656732606,   464951997, -1576085204,  ..., -1895992817,\n",
       "           -2035757505,  -163667861],\n",
       "          [  740277199,  1855152838,   799639071,  ...,  2001594641,\n",
       "            1750659544,  -332576775]]], dtype=torch.int32),\n",
       " 'model.layers.26.self_attn.q_proj.perm': tensor([2789, 1076, 3431,  ..., 1301,  573, 1415], dtype=torch.int16),\n",
       " 'model.layers.26.self_attn.q_proj.weight_bias': tensor([-0.0002,  0.0012, -0.0027,  ...,  0.0002,  0.0008, -0.0019],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.q_proj.weight_scale': tensor([1.3838, 1.3955, 1.4043,  ..., 1.3838, 1.3623, 1.4277],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.v_proj.centroids.weight': tensor([[ 0.0108,  0.0028, -0.0136,  ...,  0.0338, -0.0766,  0.0190]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.v_proj.indices': tensor([[[ 1037436202, -1976470823,   836038570,  ..., -1498708016,\n",
       "           -2096130648, -1848699312],\n",
       "          [ 1511656860, -1104459311,  -818110851,  ...,  1056101527,\n",
       "            -226666280,  -834973166],\n",
       "          [  651765766,  1052559858,  2082331109,  ...,   135007683,\n",
       "             528982073, -1334653659],\n",
       "          ...,\n",
       "          [ 1296986195,   322615828,  1351348487,  ..., -1361127140,\n",
       "            -539633199, -1362689295],\n",
       "          [ 2087868960,  1890791145,  1951503849,  ...,  1549005138,\n",
       "            1107100946,  1614066233],\n",
       "          [ -475166422,  1091452619,   868582641,  ..., -1515881935,\n",
       "             441956620, -1824725243]]], dtype=torch.int32),\n",
       " 'model.layers.26.self_attn.v_proj.perm': tensor([2789, 1076, 3431,  ..., 1301,  573, 1415], dtype=torch.int16),\n",
       " 'model.layers.26.self_attn.v_proj.weight_bias': tensor([-4.9925e-04,  3.1519e-04, -5.9795e-04,  ...,  4.6539e-04,\n",
       "          3.3450e-04,  1.3590e-05], dtype=torch.float16),\n",
       " 'model.layers.26.self_attn.v_proj.weight_scale': tensor([1.2715, 1.2480, 1.2373,  ..., 1.2939, 1.2334, 1.2520],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.input_layernorm.weight': tensor([0.5444, 0.5527, 0.5537,  ..., 0.5527, 0.5542, 0.5435],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.mlp.down_proj.centroids.weight': tensor([[ 0.0277, -0.0038, -0.0275,  ...,  0.0055,  0.0127,  0.0018]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.mlp.down_proj.indices': tensor([[[   62733653,   497705386,  -463022508,  ..., -1720863614,\n",
       "            1709371186,  -186433412],\n",
       "          [ 1663151062, -1229630677,  1312874893,  ..., -1040828662,\n",
       "             729440910, -1307374117],\n",
       "          [  930097666,   627337669,  1383281791,  ..., -1113963043,\n",
       "            -411512245,   542392001],\n",
       "          ...,\n",
       "          [ 1768120034,  -826039706,  -424319224,  ...,   183508224,\n",
       "           -2143331635, -2016871384],\n",
       "          [ -232092887, -1067714206, -1207275880,  ...,  -884614903,\n",
       "            1521941794,  1918391472],\n",
       "          [-1730214395, -1231951511,  2034979365,  ..., -1568980751,\n",
       "           -1634336628,  -969737687]]], dtype=torch.int32),\n",
       " 'model.layers.27.mlp.down_proj.perm': tensor([  166, 10756,  8434,  ...,   658,    94,  1464], dtype=torch.int16),\n",
       " 'model.layers.27.mlp.down_proj.weight_bias': tensor([ 1.6725e-04, -6.1083e-04,  1.7583e-05,  ..., -8.3637e-04,\n",
       "         -3.4976e-04, -9.3222e-05], dtype=torch.float16),\n",
       " 'model.layers.27.mlp.down_proj.weight_scale': tensor([1.1729, 1.1924, 1.1826,  ..., 1.1982, 1.1846, 1.1582],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.mlp.gate_proj.centroids.weight': tensor([[ 0.0101,  0.0202,  0.0073,  ...,  0.0124, -0.0168, -0.0111]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.mlp.gate_proj.indices': tensor([[[-2113343846,  1189682762,  -823940997,  ..., -1867005940,\n",
       "           -1671706544,  2112016663],\n",
       "          [  -23734921,  -119903442,  -318678920,  ..., -1380346871,\n",
       "            1679003329,  -723661425],\n",
       "          [  326775181,   657724331,   350555812,  ..., -1926254328,\n",
       "            -931107114,  1769886641],\n",
       "          ...,\n",
       "          [-1338782458,  1183987107,  2108738904,  ..., -1453765825,\n",
       "            1452882575,  -594988178],\n",
       "          [-1781523357, -2006145371,  -130921207,  ..., -1696767237,\n",
       "            1260898710, -1701250215],\n",
       "          [ 1304481282,   657519241,     5460666,  ...,  -909853478,\n",
       "            -893874730,    69828305]]], dtype=torch.int32),\n",
       " 'model.layers.27.mlp.gate_proj.perm': tensor([2622,  363, 2298,  ..., 3046, 3497, 1397], dtype=torch.int16),\n",
       " 'model.layers.27.mlp.gate_proj.weight_bias': tensor([-0.0014, -0.0004, -0.0004,  ...,  0.0015,  0.0017,  0.0008],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.mlp.gate_proj.weight_scale': tensor([2.1406, 2.1230, 2.1074,  ..., 2.1211, 2.0762, 2.1133],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.mlp.up_proj.centroids.weight': tensor([[0.0010, 0.0001, 0.0114,  ..., 0.0111, 0.0050, 0.0013]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.mlp.up_proj.indices': tensor([[[  290491500,  -960338230,    94172434,  ...,  -130038014,\n",
       "            -682935870,   836333228],\n",
       "          [  535688046,  2065235270,   934696262,  ...,  1639133194,\n",
       "           -1253721580,   443918068],\n",
       "          [ 1689631365,  1270042202,  -303967322,  ...,   522775646,\n",
       "           -1362855146,    38556389],\n",
       "          ...,\n",
       "          [-1403764868,   159697591,  1320333046,  ...,  -479352515,\n",
       "             598819890,   365740801],\n",
       "          [  415784273,  1023852260, -1072711407,  ...,  1169871652,\n",
       "             577714544,   467316703],\n",
       "          [-1404702627,    25193201,  -527311981,  ..., -1004627457,\n",
       "            -271599779,  -896963352]]], dtype=torch.int32),\n",
       " 'model.layers.27.mlp.up_proj.perm': tensor([2622,  363, 2298,  ..., 3046, 3497, 1397], dtype=torch.int16),\n",
       " 'model.layers.27.mlp.up_proj.weight_bias': tensor([ 1.4496e-04, -2.0897e-04, -1.4353e-04,  ...,  4.8041e-05,\n",
       "         -2.5368e-04, -1.4961e-04], dtype=torch.float16),\n",
       " 'model.layers.27.mlp.up_proj.weight_scale': tensor([1.9502, 1.9658, 1.9902,  ..., 1.9707, 1.9727, 1.9795],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.post_attention_layernorm.weight': tensor([0.4531, 0.4470, 0.4529,  ..., 0.4519, 0.4443, 0.4497],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.k_proj.centroids.weight': tensor([[-0.0087,  0.0265,  0.0084,  ...,  0.0345,  0.0128, -0.0096]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.k_proj.indices': tensor([[[ -384798197,   742127376,  -489141662,  ..., -1397369596,\n",
       "            2044812061, -1523648783],\n",
       "          [-1727537189, -1697096341,   336493667,  ..., -1248357028,\n",
       "             659127368,   403872465],\n",
       "          [ 1768136094,  1367142043,  1975562218,  ..., -1158193350,\n",
       "            -802486240,  -947503997],\n",
       "          ...,\n",
       "          [-1406333885,   441587027, -1704653828,  ...,   300705155,\n",
       "             145161960, -2117662283],\n",
       "          [ -423049196,  -845213171,  -524373991,  ...,   178671799,\n",
       "             876600022,  -909916848],\n",
       "          [ -957926757, -2103742676,  -196966366,  ...,  -617547383,\n",
       "             206343140,  1706109433]]], dtype=torch.int32),\n",
       " 'model.layers.27.self_attn.k_proj.perm': tensor([2789, 1076, 1512,  ..., 3817, 3985, 1415], dtype=torch.int16),\n",
       " 'model.layers.27.self_attn.k_proj.weight_bias': tensor([ 0.0012,  0.0006, -0.0001,  ...,  0.0002, -0.0002, -0.0009],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.k_proj.weight_scale': tensor([1.4453, 1.4678, 1.4590,  ..., 1.4570, 1.4629, 1.4385],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.o_proj.centroids.weight': tensor([[ 0.0115, -0.0319,  0.0043,  ..., -0.0212,  0.0015, -0.0056]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.o_proj.indices': tensor([[[  120278374, -1186688704, -2012652110,  ...,   375752414,\n",
       "            1343514503,  1953729547],\n",
       "          [ -211447108,  1065198144,  2119459080,  ...,  1623262331,\n",
       "            -932785120,  1312861618],\n",
       "          [   -1466510,  -140515355,  -550353165,  ...,     6426692,\n",
       "            2036473353,  -584170299],\n",
       "          ...,\n",
       "          [  916292833,  1437004565, -2093619593,  ...,   138225811,\n",
       "             -79131467,  1875585817],\n",
       "          [ 1013407452,   491047272,  -189521786,  ...,   823520632,\n",
       "             -32828646,   942358932],\n",
       "          [ -530357873,  1992342081,  1143756109,  ...,  2018344020,\n",
       "            -476542706,    14539261]]], dtype=torch.int32),\n",
       " 'model.layers.27.self_attn.o_proj.perm': tensor([2253,  340, 2029,  ..., 3576, 3513, 3543], dtype=torch.int16),\n",
       " 'model.layers.27.self_attn.o_proj.weight_bias': tensor([ 3.2425e-04,  2.8133e-04, -3.5787e-04,  ...,  9.1195e-06,\n",
       "         -5.0497e-04, -4.1056e-04], dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.o_proj.weight_scale': tensor([1.2510, 1.2842, 1.2666,  ..., 1.5381, 1.5059, 1.5781],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.q_proj.centroids.weight': tensor([[-0.0074, -0.0092,  0.0021,  ...,  0.0062, -0.0145,  0.0079]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.q_proj.indices': tensor([[[  597439006,  1275348982,    79845779,  ...,  1953402564,\n",
       "            1196233273,    79868327],\n",
       "          [  852295395, -2046136792, -1884087317,  ...,  -817924387,\n",
       "            -679805051,    80012977],\n",
       "          [  584024931,  1503250549,  1799182651,  ...,  1993272199,\n",
       "           -1114018706,  1910130043],\n",
       "          ...,\n",
       "          [  814097543, -1393016275,   779110581,  ...,  -191954290,\n",
       "             944711873,  1796081321],\n",
       "          [  253020297,  1454737241,   321233757,  ...,  1508040058,\n",
       "            -506045430,  -628681569],\n",
       "          [ 1308898707,   276165738,   758631663,  ...,  1362903245,\n",
       "           -1042901668,  -608024972]]], dtype=torch.int32),\n",
       " 'model.layers.27.self_attn.q_proj.perm': tensor([2789, 1076, 1512,  ..., 3817, 3985, 1415], dtype=torch.int16),\n",
       " 'model.layers.27.self_attn.q_proj.weight_bias': tensor([ 0.0006,  0.0017, -0.0002,  ...,  0.0003, -0.0003,  0.0013],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.q_proj.weight_scale': tensor([1.4150, 1.4746, 1.4404,  ..., 1.4551, 1.4531, 1.4707],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.v_proj.centroids.weight': tensor([[ 0.0024, -0.0008, -0.0396,  ...,  0.0018, -0.0051, -0.0009]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.v_proj.indices': tensor([[[  -33617940,  -810899933,  -973104662,  ...,   199844122,\n",
       "             127358944, -1078627375],\n",
       "          [ -561681960,    48122686, -1040187981,  ..., -1811015482,\n",
       "             951654639,  -917428637],\n",
       "          [  -16668014, -1245140052, -1108408279,  ...,  1616442848,\n",
       "           -1987867943,   512201166],\n",
       "          ...,\n",
       "          [ -706143869,   112615271,   582410161,  ...,  1594157516,\n",
       "            1236241685,   509402424],\n",
       "          [  254392849, -1455574334,  1894534944,  ...,   757512756,\n",
       "             110828923,  1779434464],\n",
       "          [  990587265, -1792876809, -1163611792,  ...,  -406622209,\n",
       "           -1968143007, -1321462801]]], dtype=torch.int32),\n",
       " 'model.layers.27.self_attn.v_proj.perm': tensor([2789, 1076, 1512,  ..., 3817, 3985, 1415], dtype=torch.int16),\n",
       " 'model.layers.27.self_attn.v_proj.weight_bias': tensor([ 0.0010, -0.0006,  0.0003,  ..., -0.0001, -0.0003, -0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.27.self_attn.v_proj.weight_scale': tensor([1.2617, 1.2451, 1.2891,  ..., 1.2510, 1.2334, 1.2441],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.input_layernorm.weight': tensor([0.5586, 0.5635, 0.5664,  ..., 0.5420, 0.5684, 0.5693],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.mlp.down_proj.centroids.weight': tensor([[-0.0003, -0.0343, -0.0328,  ..., -0.0051,  0.0060, -0.0248]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.mlp.down_proj.indices': tensor([[[  941555775,  1564875343,   241410547,  ...,  1406976448,\n",
       "            1250510670, -1807316053],\n",
       "          [ 2048945598,  1692080898, -1820477940,  ...,  1554950757,\n",
       "             833583682,  -512420975],\n",
       "          [-2020606333,   409906417,  -213224225,  ...,  1832056032,\n",
       "            -406857739,  -234852811],\n",
       "          ...,\n",
       "          [-2053198469,   563743465, -1858529442,  ...,  1038756405,\n",
       "             578461880, -1661780531],\n",
       "          [-1163141489,   748117346,   746741592,  ...,   859159271,\n",
       "            1406537685,  -366725015],\n",
       "          [ 1598696350,  1412671754, -1298974576,  ...,  -661841572,\n",
       "             503453214, -1866506905]]], dtype=torch.int32),\n",
       " 'model.layers.28.mlp.down_proj.perm': tensor([ 8160, 10605,  2393,  ...,  9061,  3780,  2374], dtype=torch.int16),\n",
       " 'model.layers.28.mlp.down_proj.weight_bias': tensor([-3.1543e-04, -1.5855e-04,  4.2856e-05,  ...,  4.3917e-04,\n",
       "          3.7646e-04,  6.3419e-05], dtype=torch.float16),\n",
       " 'model.layers.28.mlp.down_proj.weight_scale': tensor([1.1895, 1.2217, 1.1865,  ..., 1.2109, 1.1875, 1.1904],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.mlp.gate_proj.centroids.weight': tensor([[ 0.0078, -0.0100, -0.0122,  ...,  0.0126,  0.0022,  0.0018]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.mlp.gate_proj.indices': tensor([[[ 1985691571,  1441019755, -1983618821,  ..., -1814241631,\n",
       "           -1254469800,   639342242],\n",
       "          [ 1977133717,    47811452,  1556129569,  ...,  1927262607,\n",
       "             738975171,  -430901626],\n",
       "          [ 1407014770,   362784056,   590650144,  ...,   455787711,\n",
       "           -1032985860,  1234156376],\n",
       "          ...,\n",
       "          [-1138503134,  1049050076, -1462311412,  ...,  -154436768,\n",
       "            -863281629,   571928274],\n",
       "          [-1150627516,   -92798941,   646021498,  ...,  -824174583,\n",
       "            -710125681,  1666560790],\n",
       "          [-1440895769,   772689203,  -280943981,  ...,  1808605164,\n",
       "             124840062, -1407606975]]], dtype=torch.int32),\n",
       " 'model.layers.28.mlp.gate_proj.perm': tensor([2622, 2298,  363,  ..., 3046, 2620, 1397], dtype=torch.int16),\n",
       " 'model.layers.28.mlp.gate_proj.weight_bias': tensor([-0.0012, -0.0004, -0.0005,  ...,  0.0012,  0.0009,  0.0003],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.mlp.gate_proj.weight_scale': tensor([2.1094, 2.1152, 2.1289,  ..., 2.1035, 2.0879, 2.1230],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.mlp.up_proj.centroids.weight': tensor([[ 0.0141,  0.0008, -0.0024,  ...,  0.0091,  0.0079,  0.0025]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.mlp.up_proj.indices': tensor([[[-1754101324, -1201906630, -1570536416,  ...,   286230556,\n",
       "            -899620347,   973379059],\n",
       "          [-1971782887,   121338882,  -683195850,  ...,  1373756608,\n",
       "            -297378377,  1449017351],\n",
       "          [ 1554324933, -1437828186,  -838986317,  ...,  -776567860,\n",
       "            1162371282,   587955660],\n",
       "          ...,\n",
       "          [-1446865064,  2083111580, -1938037176,  ...,   716414132,\n",
       "           -1818053405,   834967628],\n",
       "          [ -670300820, -1843363481,  1532265209,  ...,   -43886471,\n",
       "            -934067396,  1522040239],\n",
       "          [   42868722,  -353754360, -1053007101,  ...,  -968749808,\n",
       "            1538006246,  1092972419]]], dtype=torch.int32),\n",
       " 'model.layers.28.mlp.up_proj.perm': tensor([2622, 2298,  363,  ..., 3046, 2620, 1397], dtype=torch.int16),\n",
       " 'model.layers.28.mlp.up_proj.weight_bias': tensor([ 1.1921e-04,  2.0862e-05, -1.7631e-04,  ..., -4.3035e-05,\n",
       "          1.0741e-04, -8.5056e-05], dtype=torch.float16),\n",
       " 'model.layers.28.mlp.up_proj.weight_scale': tensor([1.9912, 1.9756, 1.9814,  ..., 1.9980, 1.9795, 1.9893],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.post_attention_layernorm.weight': tensor([0.4646, 0.4644, 0.4656,  ..., 0.4690, 0.4519, 0.4624],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.k_proj.centroids.weight': tensor([[ 0.0331,  0.0255,  0.0016,  ..., -0.0258, -0.0129,  0.0292]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.k_proj.indices': tensor([[[ 1144807580,  2011302651,  -934569132,  ...,   501404308,\n",
       "            -620083889,  -882188348],\n",
       "          [  -33894244,  1890686459,  2049387158,  ...,   416555593,\n",
       "            -517804334,   631841916],\n",
       "          [ 1911819458,   673160779, -1778870180,  ...,  1704560982,\n",
       "            2049761121,   686161653],\n",
       "          ...,\n",
       "          [ -609930679,   -13028737, -1411631642,  ...,  -272060946,\n",
       "            1310846989,  -356036519],\n",
       "          [  234990392,  -653123617, -2013462753,  ...,  -772150859,\n",
       "            -338381423,   898881240],\n",
       "          [-1129380187,    75793980,    41920223,  ..., -1024336174,\n",
       "            -200905492,  1368097300]]], dtype=torch.int32),\n",
       " 'model.layers.28.self_attn.k_proj.perm': tensor([2789, 1076, 3431,  ..., 3985, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.28.self_attn.k_proj.weight_bias': tensor([ 0.0001, -0.0007,  0.0011,  ...,  0.0009,  0.0004, -0.0022],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.k_proj.weight_scale': tensor([1.4170, 1.4316, 1.4268,  ..., 1.4287, 1.4033, 1.4453],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.o_proj.centroids.weight': tensor([[-0.0379,  0.0226, -0.0089,  ..., -0.0229,  0.0078, -0.0271]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.o_proj.indices': tensor([[[ -623054421,   451055411,  -260751472,  ...,  1105167770,\n",
       "            1266152696,  1982989085],\n",
       "          [  666365075,  -639480729,  -583628085,  ..., -2073774590,\n",
       "             511418124,  2142568228],\n",
       "          [ 1518399572, -1095167816,   121786394,  ...,  -744614901,\n",
       "           -1742576656,   182125852],\n",
       "          ...,\n",
       "          [ 1636931082,   229603354,  1768530884,  ...,   975394614,\n",
       "            1420923420,  -997222859],\n",
       "          [  360150946,  -891481252,   753933408,  ...,  -914124131,\n",
       "            -880292873,  1416221132],\n",
       "          [ -253085186, -1092271360,  -853928724,  ...,   484256100,\n",
       "             888539444, -1364447363]]], dtype=torch.int32),\n",
       " 'model.layers.28.self_attn.o_proj.perm': tensor([1763, 1284,  964,  ...,    8,  112,  100], dtype=torch.int16),\n",
       " 'model.layers.28.self_attn.o_proj.weight_bias': tensor([-3.6776e-05,  3.7599e-04,  4.4107e-06,  ..., -3.3665e-04,\n",
       "          3.1900e-04, -1.6797e-04], dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.o_proj.weight_scale': tensor([1.5059, 1.4990, 1.5117,  ..., 1.4395, 1.4453, 1.4707],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.q_proj.centroids.weight': tensor([[ 0.0423, -0.0155, -0.0018,  ..., -0.0238,  0.0114,  0.0038]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.q_proj.indices': tensor([[[ 2120183948,   369982249,  -107967334,  ...,  -556349447,\n",
       "           -1004752713,  1205485625],\n",
       "          [ -492137044,   -35080807, -1258438956,  ...,   677084216,\n",
       "           -1409330548,  1599873381],\n",
       "          [  153806592,  -405183443,   321799054,  ...,   521684104,\n",
       "            -250417681,  1873416710],\n",
       "          ...,\n",
       "          [ 1825795213,  1278858854, -1059110480,  ...,  1267926744,\n",
       "           -1596346287,  1623230046],\n",
       "          [ 1417973223,   855827697,   984278369,  ...,  -938791217,\n",
       "            1639787495,  -533402601],\n",
       "          [ 1217119959,   -82877498,  1315273693,  ...,  -360150183,\n",
       "             792430884,   116208265]]], dtype=torch.int32),\n",
       " 'model.layers.28.self_attn.q_proj.perm': tensor([2789, 1076, 3431,  ..., 3985, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.28.self_attn.q_proj.weight_bias': tensor([-9.0837e-05,  9.1267e-04, -9.0790e-04,  ..., -2.2488e-03,\n",
       "          7.9060e-04, -1.1997e-03], dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.q_proj.weight_scale': tensor([1.3877, 1.4053, 1.4258,  ..., 1.3945, 1.3779, 1.3945],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.v_proj.centroids.weight': tensor([[ 0.0009, -0.0066,  0.0172,  ...,  0.0255, -0.0123, -0.0086]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.v_proj.indices': tensor([[[-1946618507,  1625783032, -1396050880,  ...,   585114878,\n",
       "           -1436616344, -1721333915],\n",
       "          [-1769094090,   902649904,  1732634531,  ..., -1175549266,\n",
       "              -8293617,   310022710],\n",
       "          [ 2138250452,   412613984, -1105901775,  ...,   956713848,\n",
       "            1995548579,  -601616089],\n",
       "          ...,\n",
       "          [-1406984625, -1682197296,  1612689056,  ...,  -641804139,\n",
       "            -990777054,   225535461],\n",
       "          [-1058390513,   -28049958, -1020360635,  ..., -2004863938,\n",
       "           -1772784387, -1143977110],\n",
       "          [-2040393740,  1604357410,  1808384381,  ...,  1182252294,\n",
       "              64614225, -1156177822]]], dtype=torch.int32),\n",
       " 'model.layers.28.self_attn.v_proj.perm': tensor([2789, 1076, 3431,  ..., 3985, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.28.self_attn.v_proj.weight_bias': tensor([-1.7524e-05,  1.5831e-04,  2.7370e-04,  ...,  1.0115e-04,\n",
       "         -1.4472e-04, -4.6968e-04], dtype=torch.float16),\n",
       " 'model.layers.28.self_attn.v_proj.weight_scale': tensor([1.2891, 1.2832, 1.3320,  ..., 1.2754, 1.3281, 1.3320],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.input_layernorm.weight': tensor([0.5142, 0.5337, 0.5405,  ..., 0.5342, 0.5308, 0.5527],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.mlp.down_proj.centroids.weight': tensor([[ 0.0363, -0.0075, -0.0037,  ..., -0.0028,  0.0076,  0.0483]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.mlp.down_proj.indices': tensor([[[ -151158018, -2090564938, -1176217198,  ...,    11150453,\n",
       "           -1694350984, -1425772423],\n",
       "          [ -871165317,   875873926,  -687092872,  ...,  -707838846,\n",
       "             -75243194,   747459532],\n",
       "          [ -241710993,   373931367,   877424227,  ..., -1579095845,\n",
       "            -722190090, -1685887431],\n",
       "          ...,\n",
       "          [ 1422946632,  -737261783,   972180052,  ...,   777772558,\n",
       "           -1945511174, -1572069788],\n",
       "          [-1626033488,  1491978018,  1849778407,  ..., -1055274351,\n",
       "           -1225374796, -1248203917],\n",
       "          [ 1337522487, -1914843921, -1324795990,  ..., -1775339633,\n",
       "            1201988129,   673671553]]], dtype=torch.int32),\n",
       " 'model.layers.29.mlp.down_proj.perm': tensor([ 2741,  9028, 10544,  ..., 10960,  3451,  2599], dtype=torch.int16),\n",
       " 'model.layers.29.mlp.down_proj.weight_bias': tensor([ 2.0468e-04,  4.5419e-04, -5.2500e-04,  ...,  4.7278e-04,\n",
       "          1.9670e-04, -9.8765e-05], dtype=torch.float16),\n",
       " 'model.layers.29.mlp.down_proj.weight_scale': tensor([1.2178, 1.2373, 1.2764,  ..., 1.2021, 1.1787, 1.2158],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.mlp.gate_proj.centroids.weight': tensor([[ 0.0089,  0.0036, -0.0175,  ..., -0.0037,  0.0145,  0.0255]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.mlp.gate_proj.indices': tensor([[[  450543422,   303318471,    90623981,  ..., -1562697856,\n",
       "             123967328,  1752692131],\n",
       "          [ 2125870503,   439655074,  1831193512,  ..., -1804235011,\n",
       "             936261754,   298575055],\n",
       "          [ -913877577,  -279624495,  1381285120,  ...,  -392220999,\n",
       "             449940825, -1749907858],\n",
       "          ...,\n",
       "          [-1558391663,   663859828,  1771146246,  ...,   998204103,\n",
       "             941601242,   754152445],\n",
       "          [ -302086980,   380613722,   471949379,  ..., -1167951825,\n",
       "            1580594115, -1465279841],\n",
       "          [ 1486388383,   248643449, -1736636057,  ...,  1237863785,\n",
       "             200679817,  2015925855]]], dtype=torch.int32),\n",
       " 'model.layers.29.mlp.gate_proj.perm': tensor([2298, 2622,  363,  ..., 3380, 1397, 2235], dtype=torch.int16),\n",
       " 'model.layers.29.mlp.gate_proj.weight_bias': tensor([-4.0293e-04,  3.3677e-05, -8.5652e-05,  ...,  9.4032e-04,\n",
       "          2.0206e-04,  4.5943e-04], dtype=torch.float16),\n",
       " 'model.layers.29.mlp.gate_proj.weight_scale': tensor([2.1270, 2.1133, 2.1172,  ..., 2.1152, 2.1074, 2.1191],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.mlp.up_proj.centroids.weight': tensor([[ 0.0022, -0.0197,  0.0057,  ...,  0.0072,  0.0052, -0.0012]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.mlp.up_proj.indices': tensor([[[-1062238759,  1703935008,  -641603872,  ..., -1032921405,\n",
       "            -485066379,  -763174742],\n",
       "          [-1908687138,  1969294545,  -503710559,  ...,  -353673560,\n",
       "             873019193,  1043657294],\n",
       "          [-1460348061, -1919994290,   277679023,  ...,   823340168,\n",
       "            -572266606,   596157270],\n",
       "          ...,\n",
       "          [-1934082049, -1469517577,   729340356,  ..., -1499855744,\n",
       "            -561529472, -1932642024],\n",
       "          [  749161975,  2137634367,  1665498375,  ...,  1124753983,\n",
       "           -1233628151,  1113817186],\n",
       "          [  898856267,  -457525904,   498554702,  ...,    52165628,\n",
       "             192334549,  1278802516]]], dtype=torch.int32),\n",
       " 'model.layers.29.mlp.up_proj.perm': tensor([2298, 2622,  363,  ..., 3380, 1397, 2235], dtype=torch.int16),\n",
       " 'model.layers.29.mlp.up_proj.weight_bias': tensor([-1.7750e-04,  1.2851e-04,  8.7559e-05,  ..., -3.7313e-04,\n",
       "          2.0456e-04,  3.5930e-04], dtype=torch.float16),\n",
       " 'model.layers.29.mlp.up_proj.weight_scale': tensor([1.9883, 2.0156, 2.0312,  ..., 2.0195, 1.9980, 2.0098],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.post_attention_layernorm.weight': tensor([0.4651, 0.4714, 0.4771,  ..., 0.4795, 0.4697, 0.4714],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.k_proj.centroids.weight': tensor([[-0.0037,  0.0053,  0.0248,  ..., -0.0538, -0.0319, -0.0084]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.k_proj.indices': tensor([[[-1036230182,  1611628710,    90489653,  ...,   197249840,\n",
       "            1153618816,  -672574837],\n",
       "          [-1731600019,  2137269412, -1618662903,  ...,   150231317,\n",
       "            1512358288,  1908446576],\n",
       "          [-1320277465,  1747497583, -1292284880,  ...,   232692777,\n",
       "             415476415, -1700028988],\n",
       "          ...,\n",
       "          [ 1376705563,  -234045661,  -604746258,  ...,   817314642,\n",
       "            1805935681,   211912564],\n",
       "          [ -763467454,  1451874253, -1911644810,  ...,  1658214794,\n",
       "           -1230522076,  1109386636],\n",
       "          [-1983673173,  1239466117,  -749182052,  ...,  1471910168,\n",
       "            2031212753,  1466224478]]], dtype=torch.int32),\n",
       " 'model.layers.29.self_attn.k_proj.perm': tensor([2789, 1076, 3431,  ..., 2747, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.29.self_attn.k_proj.weight_bias': tensor([-0.0019,  0.0002, -0.0025,  ...,  0.0004,  0.0012,  0.0003],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.k_proj.weight_scale': tensor([1.3555, 1.4170, 1.3945,  ..., 1.4131, 1.3467, 1.3926],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.o_proj.centroids.weight': tensor([[-0.0020,  0.0252, -0.0162,  ...,  0.0326, -0.0130,  0.0020]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.o_proj.indices': tensor([[[ -684042835,  1126135310, -1980915529,  ...,   850089698,\n",
       "             223338802, -1507130282],\n",
       "          [ -667482531,  1388991420, -1309152439,  ..., -2132077269,\n",
       "             137965606,  -622496519],\n",
       "          [ -142162880,  1965898421,  1371175511,  ...,  1823674633,\n",
       "            1880819554,  -595478721],\n",
       "          ...,\n",
       "          [  584002319,  1518254734,   176539127,  ..., -1991994159,\n",
       "            -119575447,  1169715532],\n",
       "          [  360105557, -2002796741, -1295397846,  ...,  -657520404,\n",
       "             261023241,   122196277],\n",
       "          [  694677360,  -953033348, -1343258903,  ...,   922867065,\n",
       "             870520676,  2091371255]]], dtype=torch.int32),\n",
       " 'model.layers.29.self_attn.o_proj.perm': tensor([2022,  978, 2366,  ..., 3240, 3234, 3322], dtype=torch.int16),\n",
       " 'model.layers.29.self_attn.o_proj.weight_bias': tensor([-0.0007,  0.0002, -0.0001,  ..., -0.0006,  0.0001, -0.0004],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.o_proj.weight_scale': tensor([1.2676, 1.2598, 1.2852,  ..., 1.2471, 1.2588, 1.2549],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.q_proj.centroids.weight': tensor([[ 1.0956e-02, -3.2604e-05, -2.1839e-03,  ..., -1.3695e-02,\n",
       "          -1.0170e-02, -2.6398e-02]], dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.q_proj.indices': tensor([[[  510811189,  1418206630,   477607363,  ..., -1955885199,\n",
       "             -42369022,  -247310907],\n",
       "          [  366024415, -2043463099, -1248000973,  ...,  1276859891,\n",
       "           -1060899771,  1410913367],\n",
       "          [-1357047904, -1995702496,  1224417859,  ...,   -97913036,\n",
       "             892712555,  -834143093],\n",
       "          ...,\n",
       "          [ -881377461,   -48614623,  1528516691,  ...,   313506142,\n",
       "            1690000798,   723205572],\n",
       "          [ -147364040,   603857547,  1785834711,  ..., -1573078783,\n",
       "            1797897126,  1337898382],\n",
       "          [  624774946, -1536391741,  -584044068,  ...,  1888462432,\n",
       "              85994179,  -476070586]]], dtype=torch.int32),\n",
       " 'model.layers.29.self_attn.q_proj.perm': tensor([2789, 1076, 3431,  ..., 2747, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.29.self_attn.q_proj.weight_bias': tensor([ 0.0007, -0.0004,  0.0004,  ..., -0.0006, -0.0006,  0.0009],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.q_proj.weight_scale': tensor([1.3828, 1.4014, 1.3867,  ..., 1.3662, 1.3184, 1.3408],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.v_proj.centroids.weight': tensor([[ 0.0124,  0.0057, -0.0290,  ...,  0.0315, -0.0047, -0.0975]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.v_proj.indices': tensor([[[  277487554, -1321362711, -1724172084,  ...,  1444805767,\n",
       "            1920618785,  -183631120],\n",
       "          [ -851054289,   443223029, -1835620880,  ...,  1725503725,\n",
       "             608808247,  1552642300],\n",
       "          [ 1466243586, -1820706450,  2058453537,  ...,   747441897,\n",
       "            1957706745,    66248080],\n",
       "          ...,\n",
       "          [ 1610763299, -1678283015,  1175357649,  ...,    89090896,\n",
       "            -832155752, -1335325590],\n",
       "          [  645985321, -1127686539, -2131352617,  ..., -1691176882,\n",
       "           -2036978923, -1871262229],\n",
       "          [  326481358,   363256081,   196847761,  ...,  -138722371,\n",
       "           -1953108685,  1686823808]]], dtype=torch.int32),\n",
       " 'model.layers.29.self_attn.v_proj.perm': tensor([2789, 1076, 3431,  ..., 2747, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.29.self_attn.v_proj.weight_bias': tensor([ 3.4523e-04,  4.3273e-04,  9.2220e-04,  ..., -3.5286e-05,\n",
       "         -1.6236e-04,  4.3035e-04], dtype=torch.float16),\n",
       " 'model.layers.29.self_attn.v_proj.weight_scale': tensor([1.3115, 1.2705, 1.3223,  ..., 1.2891, 1.2998, 1.3047],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.input_layernorm.weight': tensor([0.2839, 0.2849, 0.2859,  ..., 0.2847, 0.2981, 0.3057],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.mlp.down_proj.centroids.weight': tensor([[-0.0063,  0.0071,  0.0148,  ...,  0.0015, -0.0011,  0.0102]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.mlp.down_proj.indices': tensor([[[ 1126703861,  -508339200,   480486965,  ...,   299979226,\n",
       "            1344448491, -1809569791],\n",
       "          [  395998932,  1121396014,   240076811,  ...,   419667127,\n",
       "            1389911751,     2641569],\n",
       "          [  961138166,   878408038, -1283444236,  ...,  1808957563,\n",
       "           -1055553000, -1211232514],\n",
       "          ...,\n",
       "          [ 1929275334,   501797877,  1744025850,  ..., -1934781972,\n",
       "             378567950, -1413803587],\n",
       "          [  967840516, -1713805010,  1626061229,  ...,   -93576739,\n",
       "            1688799892,   814933581],\n",
       "          [-1741769468,   561007712,   285951928,  ..., -1701244052,\n",
       "            -466324922,  1281444170]]], dtype=torch.int32),\n",
       " 'model.layers.3.mlp.down_proj.perm': tensor([7780, 8680, 4388,  ..., 5640, 2262, 3070], dtype=torch.int16),\n",
       " 'model.layers.3.mlp.down_proj.weight_bias': tensor([-3.9601e-04,  9.9599e-05, -1.7917e-04,  ..., -3.0541e-04,\n",
       "         -5.0020e-04,  1.6701e-04], dtype=torch.float16),\n",
       " 'model.layers.3.mlp.down_proj.weight_scale': tensor([1.1084, 1.1416, 1.1377,  ..., 1.1221, 0.8447, 1.1289],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.mlp.gate_proj.centroids.weight': tensor([[ 0.0043, -0.0145,  0.0018,  ...,  0.0053,  0.0025,  0.0079]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.mlp.gate_proj.indices': tensor([[[-1274623495,   861553578,  2116925424,  ..., -1661057363,\n",
       "            1124327921,  -509361476],\n",
       "          [  697131806,   602436127,  2064913369,  ..., -1961887570,\n",
       "            -628798329,  -641364104],\n",
       "          [ 1262090331, -1472411247,   797281389,  ...,   673017523,\n",
       "            1093317512,  -829288652],\n",
       "          ...,\n",
       "          [  517277419,   598752577,  1093790471,  ...,   696343392,\n",
       "            -255656475,   563653761],\n",
       "          [-1080333156,   266567214, -1971879069,  ...,  -150956029,\n",
       "           -1068594607,   122619776],\n",
       "          [ 2138974128,  1927850054,  -477282769,  ..., -1489574129,\n",
       "            2063060385,  -245370990]]], dtype=torch.int32),\n",
       " 'model.layers.3.mlp.gate_proj.perm': tensor([3209, 2298, 2393,  ..., 2235,  339, 1512], dtype=torch.int16),\n",
       " 'model.layers.3.mlp.gate_proj.weight_bias': tensor([ 0.0008,  0.0004,  0.0009,  ...,  0.0010, -0.0008, -0.0015],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.mlp.gate_proj.weight_scale': tensor([1.9883, 1.9932, 1.9854,  ..., 2.0176, 1.9902, 1.9951],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.mlp.up_proj.centroids.weight': tensor([[ 0.0056,  0.0048, -0.0173,  ..., -0.0125,  0.0051,  0.0054]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.mlp.up_proj.indices': tensor([[[ 1930548792,  1513836452,  1473352537,  ..., -1256802389,\n",
       "            -250005230,  -990561133],\n",
       "          [ 1688460465,    74476119, -1544732884,  ..., -1095344972,\n",
       "            -530967517,  1804894228],\n",
       "          [ -829720273,   951994831, -1307816746,  ..., -2093093711,\n",
       "            -927483060,  1320482232],\n",
       "          ...,\n",
       "          [  605209083, -1920799869,  -102164458,  ...,  1376733449,\n",
       "            -721975099,    -3488729],\n",
       "          [ 1781142617,  1707085169,  1167136497,  ...,     1925582,\n",
       "           -1397799534,   706505494],\n",
       "          [ 1288476418,    54861629,  1921249209,  ...,  1643926735,\n",
       "             207662498,  1468178886]]], dtype=torch.int32),\n",
       " 'model.layers.3.mlp.up_proj.perm': tensor([3209, 2298, 2393,  ..., 2235,  339, 1512], dtype=torch.int16),\n",
       " 'model.layers.3.mlp.up_proj.weight_bias': tensor([ 7.1108e-05, -1.0675e-04, -6.3062e-05,  ..., -1.5068e-04,\n",
       "          2.9922e-05, -1.4186e-04], dtype=torch.float16),\n",
       " 'model.layers.3.mlp.up_proj.weight_scale': tensor([1.8594, 1.8516, 1.8633,  ..., 1.8359, 1.8574, 1.8555],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.post_attention_layernorm.weight': tensor([0.1770, 0.1783, 0.1727,  ..., 0.1755, 0.1733, 0.1764],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.k_proj.centroids.weight': tensor([[-0.0376, -0.0083,  0.0164,  ...,  0.0168, -0.0134, -0.0358]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.k_proj.indices': tensor([[[  955525960, -1927679195, -2102174462,  ..., -1382298153,\n",
       "             403627604,   529765848],\n",
       "          [ 1857810472, -2051308988, -1169692763,  ...,  1737852064,\n",
       "            1370728455,  -959378821],\n",
       "          [  563485172,  2000385493,  1043973925,  ...,   519641019,\n",
       "            1185029680, -2118395413],\n",
       "          ...,\n",
       "          [ 1017423450,   445384254,   637715351,  ..., -1668345062,\n",
       "            -475722034,  1747095469],\n",
       "          [  422480045,  -192159309,  2091467795,  ...,  2129240417,\n",
       "            -324143674,   113652148],\n",
       "          [-1694185056,     3857737, -1535659953,  ...,  1750446292,\n",
       "            -806564750, -1720571323]]], dtype=torch.int32),\n",
       " 'model.layers.3.self_attn.k_proj.perm': tensor([2393, 1076, 3209,  ..., 2533, 1415,  310], dtype=torch.int16),\n",
       " 'model.layers.3.self_attn.k_proj.weight_bias': tensor([-0.0015, -0.0005, -0.0006,  ..., -0.0019,  0.0037,  0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.k_proj.weight_scale': tensor([1.6475, 1.6768, 1.6670,  ..., 1.6494, 1.6621, 1.6895],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.o_proj.centroids.weight': tensor([[-0.0098,  0.0077, -0.0087,  ..., -0.0018,  0.0121,  0.0245]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.o_proj.indices': tensor([[[   39894764,  -799146689,  1220993995,  ..., -1210182039,\n",
       "              69332172, -1512849657],\n",
       "          [ -657985971,  -916110119,   576885593,  ..., -1823822308,\n",
       "            1487507123,  -966133004],\n",
       "          [-1165000829,  -483260244,   984435303,  ...,  2138302783,\n",
       "           -1161359029,  -905345292],\n",
       "          ...,\n",
       "          [ -337465174, -1172454910,   730452768,  ..., -1568361273,\n",
       "            -513784339,  1671000100],\n",
       "          [  980962268,   467445103,  1867559486,  ..., -1905891086,\n",
       "           -1734259859,   928204843],\n",
       "          [ 1137034252,   264630471, -1843662175,  ..., -1325712941,\n",
       "             -23976940,   787647600]]], dtype=torch.int32),\n",
       " 'model.layers.3.self_attn.o_proj.perm': tensor([4067, 4092, 3370,  ..., 2292, 2209, 2298], dtype=torch.int16),\n",
       " 'model.layers.3.self_attn.o_proj.weight_bias': tensor([ 6.2418e-04,  2.4509e-04, -3.7861e-04,  ..., -3.0756e-05,\n",
       "         -4.7505e-05,  1.4174e-04], dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.o_proj.weight_scale': tensor([0.8120, 0.8184, 0.7827,  ..., 0.3157, 0.3447, 0.3083],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.q_proj.centroids.weight': tensor([[ 0.0054, -0.0210,  0.0078,  ..., -0.0051, -0.0106,  0.0336]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.q_proj.indices': tensor([[[  536956920,  1313253850, -2023964089,  ..., -2019773180,\n",
       "             791070479, -1486953674],\n",
       "          [ 1245694545, -1204177405, -1427233386,  ..., -2026178181,\n",
       "             479756505,  2022480806],\n",
       "          [   35672346,   335338689,   760606555,  ...,  -734229168,\n",
       "             359707013,  1129712675],\n",
       "          ...,\n",
       "          [-1449569137,   366697616,   292890538,  ..., -1712377186,\n",
       "           -1189149156,  1324312319],\n",
       "          [ 2051469045,  1058236108,  -824241167,  ..., -1749720570,\n",
       "              76326481,  -816709391],\n",
       "          [-1097467069,  -111184848,  -277538155,  ...,   -11645156,\n",
       "           -1376662124, -1050816837]]], dtype=torch.int32),\n",
       " 'model.layers.3.self_attn.q_proj.perm': tensor([2393, 1076, 3209,  ..., 2533, 1415,  310], dtype=torch.int16),\n",
       " 'model.layers.3.self_attn.q_proj.weight_bias': tensor([ 0.0003,  0.0014, -0.0009,  ...,  0.0013, -0.0007,  0.0010],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.q_proj.weight_scale': tensor([1.5576, 1.6191, 1.6123,  ..., 1.6211, 1.6055, 1.6240],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.v_proj.centroids.weight': tensor([[ 0.0238, -0.0446,  0.0049,  ..., -0.0036,  0.0020, -0.0123]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.v_proj.indices': tensor([[[ -398186912, -1882803684,  1407860680,  ...,  -347630761,\n",
       "            -127467391,  -109882259],\n",
       "          [   17332225, -1862115959,  1057729395,  ..., -1329208833,\n",
       "           -1490225054,  1515411682],\n",
       "          [   69352180,  -733105421,  -533745179,  ...,  1521265031,\n",
       "              47807004,  -568885516],\n",
       "          ...,\n",
       "          [ 1354328213,   612602827,   944274999,  ...,   443850417,\n",
       "            1439506486,   609711498],\n",
       "          [-1616598002,  -190011525,  2021860354,  ...,   971263795,\n",
       "            1642949350, -2092742963],\n",
       "          [ -895918639,  1405773523, -1920491879,  ...,  1028867168,\n",
       "            1536610084,   103741081]]], dtype=torch.int32),\n",
       " 'model.layers.3.self_attn.v_proj.perm': tensor([2393, 1076, 3209,  ..., 2533, 1415,  310], dtype=torch.int16),\n",
       " 'model.layers.3.self_attn.v_proj.weight_bias': tensor([ 6.8426e-05, -1.3852e-04, -1.4579e-04,  ..., -4.4489e-04,\n",
       "          1.5020e-04, -2.1482e-04], dtype=torch.float16),\n",
       " 'model.layers.3.self_attn.v_proj.weight_scale': tensor([0.8989, 0.8765, 0.8887,  ..., 0.8853, 0.8916, 0.8916],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.input_layernorm.weight': tensor([0.5796, 0.5869, 0.5762,  ..., 0.5527, 0.5601, 0.5791],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.mlp.down_proj.centroids.weight': tensor([[-0.0099,  0.0192, -0.0024,  ...,  0.0376, -0.0040, -0.0074]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.mlp.down_proj.indices': tensor([[[  497741111, -1331979889,   955833833,  ...,  -946555006,\n",
       "            1225483682,   533638197],\n",
       "          [ 2087831614, -1702579949, -1638518005,  ...,  1950902716,\n",
       "            1287250214,  1498029064],\n",
       "          [  -22582456,   284358426, -1678083459,  ...,  1166054429,\n",
       "            2139928730,  1852695918],\n",
       "          ...,\n",
       "          [ 1843293495, -1822332104, -2130994099,  ..., -1411700335,\n",
       "             766960097, -1583701427],\n",
       "          [-1733629322,  -626354517,  1235013341,  ...,  -507202130,\n",
       "            -152050380,  -394846916],\n",
       "          [ -457930690,  -414610759, -2033551562,  ...,  -238366534,\n",
       "           -1079165257,   -73071227]]], dtype=torch.int32),\n",
       " 'model.layers.30.mlp.down_proj.perm': tensor([ 3721,  7006,  4131,  ..., 10428,  6434,  8697], dtype=torch.int16),\n",
       " 'model.layers.30.mlp.down_proj.weight_bias': tensor([-9.2864e-05,  3.4380e-04,  1.1176e-04,  ...,  2.8348e-04,\n",
       "          3.5191e-04,  2.1064e-04], dtype=torch.float16),\n",
       " 'model.layers.30.mlp.down_proj.weight_scale': tensor([1.2432, 1.2275, 1.2227,  ..., 1.1143, 1.0654, 1.2363],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.mlp.gate_proj.centroids.weight': tensor([[-0.0104,  0.0141, -0.0101,  ...,  0.0113,  0.0042, -0.0084]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.mlp.gate_proj.indices': tensor([[[ 1367284842,  1445374631,  1542644012,  ...,  -777127138,\n",
       "            1512053554, -2143248888],\n",
       "          [ -251464743,    32218239,  1045789178,  ..., -1412850457,\n",
       "             145576429, -2052535475],\n",
       "          [ 1178889792,   602403252,  1649523615,  ..., -1416831686,\n",
       "             719710143, -1068352790],\n",
       "          ...,\n",
       "          [ 2030535715,  -977169762,  -274352181,  ...,  1171109021,\n",
       "           -1100791514,  -822758548],\n",
       "          [   32239607, -1659152557,  1190165408,  ...,  1356204647,\n",
       "             491199890,   778612023],\n",
       "          [ -759281840,  -492357775,  -302103964,  ...,  -340222152,\n",
       "            1572247360,   733205096]]], dtype=torch.int32),\n",
       " 'model.layers.30.mlp.gate_proj.perm': tensor([1512, 2622, 2789,  ..., 2673, 1493, 2235], dtype=torch.int16),\n",
       " 'model.layers.30.mlp.gate_proj.weight_bias': tensor([-0.0016,  0.0005, -0.0003,  ...,  0.0012,  0.0002, -0.0004],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.mlp.gate_proj.weight_scale': tensor([2.1816, 2.1387, 2.1699,  ..., 2.1250, 2.1289, 2.1426],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.mlp.up_proj.centroids.weight': tensor([[ 1.9274e-03, -7.2837e-05,  3.1681e-03,  ..., -3.3455e-03,\n",
       "          -4.8218e-03,  1.2245e-02]], dtype=torch.float16),\n",
       " 'model.layers.30.mlp.up_proj.indices': tensor([[[ 2014301320,  1670767828,    19890366,  ...,  -157385149,\n",
       "              85067842,  -732834292],\n",
       "          [ -334076526,   391166009, -1159878312,  ...,  1133335915,\n",
       "            1385205005,  1950551425],\n",
       "          [ 1453753316,  -136854820,  1998249795,  ...,   147775862,\n",
       "            1451765752,   735922212],\n",
       "          ...,\n",
       "          [  857061841,  -458357221,  2013007942,  ..., -2143504847,\n",
       "            1761241635, -1573719567],\n",
       "          [ -814365424,  1388823813,  -144080169,  ..., -1327425641,\n",
       "            -888790608, -1399901368],\n",
       "          [-1295902351,   303694895,   974517655,  ..., -1608768847,\n",
       "             840997122,  1268421437]]], dtype=torch.int32),\n",
       " 'model.layers.30.mlp.up_proj.perm': tensor([1512, 2622, 2789,  ..., 2673, 1493, 2235], dtype=torch.int16),\n",
       " 'model.layers.30.mlp.up_proj.weight_bias': tensor([ 2.3150e-04, -5.3585e-05, -1.0270e-04,  ..., -2.4021e-05,\n",
       "         -4.5872e-04, -3.5501e-04], dtype=torch.float16),\n",
       " 'model.layers.30.mlp.up_proj.weight_scale': tensor([2.0156, 2.0449, 2.0566,  ..., 2.0410, 2.0625, 2.0137],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.post_attention_layernorm.weight': tensor([0.4749, 0.4919, 0.4863,  ..., 0.4788, 0.4927, 0.4729],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.k_proj.centroids.weight': tensor([[-0.0049, -0.0263,  0.0110,  ..., -0.0164, -0.0086, -0.0100]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.k_proj.indices': tensor([[[-1507586943,  1442434792,  -857393667,  ...,  1681757602,\n",
       "            1639769529,  1605532414],\n",
       "          [ 1096101033,   492138800, -1824396826,  ...,  1681270440,\n",
       "           -1027105215, -1439001021],\n",
       "          [-1487161938,   362338308,  1383415906,  ...,   232539245,\n",
       "           -1253073392, -1077961326],\n",
       "          ...,\n",
       "          [ 1746147668, -1433675315,  1176469599,  ...,  2069568040,\n",
       "            1961886038,  -592159797],\n",
       "          [ -679023662,   697918675,  -224874146,  ...,  1271269407,\n",
       "             658777672, -1414884585],\n",
       "          [  570212789,  -261718666,  -834368215,  ...,  1037138387,\n",
       "           -1582336251,  1576513388]]], dtype=torch.int32),\n",
       " 'model.layers.30.self_attn.k_proj.perm': tensor([1512, 2789, 1076,  ..., 3008, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.30.self_attn.k_proj.weight_bias': tensor([ 0.0012, -0.0012, -0.0008,  ...,  0.0007,  0.0025,  0.0001],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.k_proj.weight_scale': tensor([1.3936, 1.4189, 1.4131,  ..., 1.3857, 1.3643, 1.3975],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.o_proj.centroids.weight': tensor([[-0.0190,  0.0037,  0.0060,  ...,  0.0081,  0.0042,  0.0045]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.o_proj.indices': tensor([[[ -956506139,  -600914718, -1738842670,  ...,  1641458862,\n",
       "            1544319764,  -109646310],\n",
       "          [ 1448243643,   985180629,  2034324112,  ...,  -718641848,\n",
       "            -872534218, -1394845851],\n",
       "          [ -450357553,  1538421368,  2041889399,  ..., -1079047550,\n",
       "            -801356084,   879490017],\n",
       "          ...,\n",
       "          [ 1798288379,   643051284,  1609285341,  ...,  -748016930,\n",
       "            1617126088, -1025724983],\n",
       "          [ -585176565,  2137725512,   -51342993,  ...,  1988986852,\n",
       "            -143314535,  1519570149],\n",
       "          [  117993552,  1813117734, -1260972799,  ...,   877773180,\n",
       "           -1964647761, -1949121822]]], dtype=torch.int32),\n",
       " 'model.layers.30.self_attn.o_proj.perm': tensor([1574,  328, 2268,  ..., 2849, 3486, 3496], dtype=torch.int16),\n",
       " 'model.layers.30.self_attn.o_proj.weight_bias': tensor([-1.3626e-04, -1.0687e-04,  2.4867e-04,  ...,  3.7217e-04,\n",
       "         -5.8234e-05,  5.1594e-04], dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.o_proj.weight_scale': tensor([1.3584, 1.4180, 1.3643,  ..., 1.4746, 1.4971, 1.4629],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.q_proj.centroids.weight': tensor([[ 0.0141,  0.0126,  0.0398,  ..., -0.0326,  0.0131,  0.0011]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.q_proj.indices': tensor([[[  826682726, -1691226085,   554496131,  ...,   815383083,\n",
       "            1325482535,   572974433],\n",
       "          [ 1452485271,  -176278239,  1703210373,  ..., -1765658124,\n",
       "           -1785818450, -1949590694],\n",
       "          [ -277656634,   244986102, -1669957811,  ...,   518559497,\n",
       "           -1567149565,   553507711],\n",
       "          ...,\n",
       "          [ -150069254, -1549141504,  -854340835,  ..., -1899873586,\n",
       "            1197354758,   606827617],\n",
       "          [ -873134761,   250196092,  -425388273,  ...,  -981785454,\n",
       "               1764453,  1885223706],\n",
       "          [ 1872927206,  -553568992,   871912940,  ..., -1461924321,\n",
       "             116377994,  1454918299]]], dtype=torch.int32),\n",
       " 'model.layers.30.self_attn.q_proj.perm': tensor([1512, 2789, 1076,  ..., 3008, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.30.self_attn.q_proj.weight_bias': tensor([ 0.0007,  0.0011, -0.0003,  ...,  0.0001,  0.0005,  0.0005],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.q_proj.weight_scale': tensor([1.3750, 1.4395, 1.4043,  ..., 1.3594, 1.3262, 1.3428],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.v_proj.centroids.weight': tensor([[ 0.0008, -0.0160, -0.0237,  ..., -0.0223,  0.0253, -0.0078]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.v_proj.indices': tensor([[[ -788770192,    46265797,   610635826,  ...,  -820046489,\n",
       "           -1134203598,  -548226491],\n",
       "          [ -218075723,   -47796949,  -646040076,  ...,  -254044275,\n",
       "             899178205, -1797324509],\n",
       "          [ 2071498443, -1601346373,  -855112307,  ...,  1446225447,\n",
       "             296358627,  -690740905],\n",
       "          ...,\n",
       "          [ -679000507,  -955550739, -1445337735,  ...,  -170989252,\n",
       "           -1139051330,  -757637929],\n",
       "          [  932593405, -1920134170,  -248204877,  ...,  -516050596,\n",
       "             869711054,   379518331],\n",
       "          [-1286966659,    80959909, -1492044727,  ...,  -747484207,\n",
       "            1586165972,  1295822076]]], dtype=torch.int32),\n",
       " 'model.layers.30.self_attn.v_proj.perm': tensor([1512, 2789, 1076,  ..., 3008, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.30.self_attn.v_proj.weight_bias': tensor([-1.2648e-04, -2.5654e-04,  2.8610e-06,  ...,  6.0272e-04,\n",
       "         -5.5647e-04, -1.2684e-04], dtype=torch.float16),\n",
       " 'model.layers.30.self_attn.v_proj.weight_scale': tensor([1.3701, 1.3125, 1.3496,  ..., 1.3389, 1.3594, 1.3623],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.input_layernorm.weight': tensor([0.4910, 0.4875, 0.4324,  ..., 0.4326, 0.4541, 0.4814],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.mlp.down_proj.centroids.weight': tensor([[ 0.0450, -0.0077, -0.0151,  ...,  0.0078,  0.0082,  0.0045]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.mlp.down_proj.indices': tensor([[[ -820652159,  1742718845,  1101811397,  ..., -1814349264,\n",
       "            -882097241,  2121298351],\n",
       "          [ 1289082753,   497420868,   698840757,  ..., -1719195923,\n",
       "              61751699, -1163444255],\n",
       "          [ -514858578,  -248523462,   460174515,  ...,  -807793505,\n",
       "             555059524,  -874014104],\n",
       "          ...,\n",
       "          [ -885950591,   604038538, -1240940832,  ...,   323174936,\n",
       "            1233622393, -1194556379],\n",
       "          [ 1026656129,   784587737,  1697425262,  ...,  1561140529,\n",
       "             704894104,  -566732179],\n",
       "          [-1396656342,  -836505506, -1834063075,  ...,  1044973370,\n",
       "           -1017787053,   404663011]]], dtype=torch.int32),\n",
       " 'model.layers.31.mlp.down_proj.perm': tensor([ 3228,  1134,  2818,  ..., 10478,  6661,  2035], dtype=torch.int16),\n",
       " 'model.layers.31.mlp.down_proj.weight_bias': tensor([ 1.2732e-04,  3.3712e-04,  4.1628e-04,  ..., -3.3319e-05,\n",
       "         -2.9731e-04,  6.5422e-04], dtype=torch.float16),\n",
       " 'model.layers.31.mlp.down_proj.weight_scale': tensor([1.3105, 1.2910, 1.0566,  ..., 1.2725, 1.0205, 1.0557],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.mlp.gate_proj.centroids.weight': tensor([[-0.0011, -0.0137,  0.0071,  ..., -0.0044,  0.0118,  0.0009]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.mlp.gate_proj.indices': tensor([[[-1351657098,  -603250345, -1555391982,  ..., -1247884445,\n",
       "           -1218303065,   902649207],\n",
       "          [   69416303,   629444347,  -882395345,  ..., -1615467019,\n",
       "            1443085331,   499164396],\n",
       "          [  957317107, -1133628164,  -165949046,  ...,  2127844603,\n",
       "             470995478, -1526982296],\n",
       "          ...,\n",
       "          [ -504029864, -1838367073,  1343351518,  ...,   144823968,\n",
       "           -1911117253, -1654273695],\n",
       "          [ -634156764,    30508119, -1168507398,  ..., -1393704227,\n",
       "            1757008113,  -508927644],\n",
       "          [-2003271505,  -960797781,  -760490124,  ..., -1850741612,\n",
       "             344720325,   611114342]]], dtype=torch.int32),\n",
       " 'model.layers.31.mlp.gate_proj.perm': tensor([1512,  310, 2622,  ...,  923, 2235, 1999], dtype=torch.int16),\n",
       " 'model.layers.31.mlp.gate_proj.weight_bias': tensor([-0.0008,  0.0012, -0.0009,  ..., -0.0004, -0.0015,  0.0007],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.mlp.gate_proj.weight_scale': tensor([2.1641, 2.2188, 2.2129,  ..., 2.2500, 2.2461, 2.2422],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.mlp.up_proj.centroids.weight': tensor([[ 0.0094, -0.0255, -0.0037,  ..., -0.0021,  0.0039, -0.0061]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.mlp.up_proj.indices': tensor([[[-1922450583,    70775829,  1716759897,  ...,  1179612586,\n",
       "            -473036954,  -509696452],\n",
       "          [  655369682,  1747103471,  1916270833,  ...,  1475102653,\n",
       "             528875925,  1722104754],\n",
       "          [-1687673427,  1483103981,  -215037457,  ...,  1528786637,\n",
       "           -1033613919, -1992021420],\n",
       "          ...,\n",
       "          [  926892446,   594194580, -1166052600,  ...,   161580794,\n",
       "            1464963011,      166427],\n",
       "          [ -550336247,  -953512190, -2088584167,  ..., -2083427448,\n",
       "            1547163435,  1942344980],\n",
       "          [ -849243470,  -779523458,  1247624216,  ...,   593585907,\n",
       "           -1875486217,  1929999141]]], dtype=torch.int32),\n",
       " 'model.layers.31.mlp.up_proj.perm': tensor([1512,  310, 2622,  ...,  923, 2235, 1999], dtype=torch.int16),\n",
       " 'model.layers.31.mlp.up_proj.weight_bias': tensor([ 1.5938e-04, -1.0233e-03, -4.3511e-04,  ...,  4.5037e-04,\n",
       "          9.7656e-04,  4.8399e-05], dtype=torch.float16),\n",
       " 'model.layers.31.mlp.up_proj.weight_scale': tensor([2.0586, 2.1094, 2.1133,  ..., 2.1016, 2.1777, 2.0684],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.post_attention_layernorm.weight': tensor([0.4312, 0.4365, 0.4480,  ..., 0.4165, 0.4153, 0.4202],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.k_proj.centroids.weight': tensor([[ 0.0193,  0.0188, -0.0082,  ..., -0.0037, -0.0084,  0.0195]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.k_proj.indices': tensor([[[-1038581089, -1113384134, -1824696225,  ...,  -566358114,\n",
       "           -1909135606,  -449244458],\n",
       "          [ 1489935670, -1667820905,  1482984437,  ...,  -532766721,\n",
       "             570771855,   240502220],\n",
       "          [ 1028677478,  1803367598,  -770187012,  ...,  1619568154,\n",
       "             576209241,  1148918775],\n",
       "          ...,\n",
       "          [ 1278089499, -1830454558,   714364634,  ...,   -47258183,\n",
       "            -464078453,  -820132961],\n",
       "          [  122375962,  -527511234,   491946665,  ...,  -331992263,\n",
       "            -230119078, -1877098397],\n",
       "          [ 1610728317,  1179338475,  1906255432,  ..., -2025396558,\n",
       "           -1874641934,  1317263065]]], dtype=torch.int32),\n",
       " 'model.layers.31.self_attn.k_proj.perm': tensor([2789, 2393, 3209,  ...,  788, 2573,  972], dtype=torch.int16),\n",
       " 'model.layers.31.self_attn.k_proj.weight_bias': tensor([-0.0008, -0.0006, -0.0009,  ..., -0.0007, -0.0012,  0.0003],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.k_proj.weight_scale': tensor([1.4463, 1.4551, 1.4355,  ..., 1.4365, 1.4092, 1.4111],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.o_proj.centroids.weight': tensor([[-0.0176,  0.0154, -0.0093,  ...,  0.0080,  0.0221,  0.0035]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.o_proj.indices': tensor([[[  -79655443,  -305122670, -1735932472,  ...,   800532612,\n",
       "            -454926172,  1885561813],\n",
       "          [-1453471686,   247325526,   -26308311,  ...,   749766463,\n",
       "            1259362163,   871181847],\n",
       "          [-1773838664, -1681111460,    -8210897,  ...,   533979565,\n",
       "            2001190462,   722478983],\n",
       "          ...,\n",
       "          [ 2063972821, -2116492042,   978493798,  ...,  -498381747,\n",
       "            1809072787,  1113871535],\n",
       "          [ -120889038,  2123213519,   400497983,  ..., -1205800961,\n",
       "              70651909,  -143460448],\n",
       "          [ 1509425423, -2119570988,   303648122,  ..., -2034509916,\n",
       "            -739169257,   615430059]]], dtype=torch.int32),\n",
       " 'model.layers.31.self_attn.o_proj.perm': tensor([1393, 2884, 2922,  ...,  875,  842,  854], dtype=torch.int16),\n",
       " 'model.layers.31.self_attn.o_proj.weight_bias': tensor([ 7.6294e-04,  2.1267e-04,  5.2881e-04,  ..., -2.0385e-04,\n",
       "          5.6922e-05,  9.8050e-05], dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.o_proj.weight_scale': tensor([1.2383, 1.2061, 1.2109,  ..., 1.2285, 1.2314, 1.2314],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.q_proj.centroids.weight': tensor([[ 0.0117,  0.0094,  0.0159,  ..., -0.0468,  0.0081, -0.0012]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.q_proj.indices': tensor([[[-1646992793, -1472536352,   823298009,  ...,  1112517614,\n",
       "            -741196702,   679309735],\n",
       "          [-1713718781,   601027832, -1415972625,  ...,  1825301701,\n",
       "            -714900249, -1554833343],\n",
       "          [-1843853551, -2102460127,  1977864847,  ...,  -860453870,\n",
       "             697646199,   935251074],\n",
       "          ...,\n",
       "          [ 1300410841,  -198408827, -1870767612,  ..., -1620016113,\n",
       "            1046415859,   968917647],\n",
       "          [ -189208027, -1703580088,  1265760133,  ..., -1686956644,\n",
       "            1852309036,  1503318469],\n",
       "          [ 1583464471,  -424550259, -1648619154,  ..., -1905853520,\n",
       "            1100770025, -1534893973]]], dtype=torch.int32),\n",
       " 'model.layers.31.self_attn.q_proj.perm': tensor([2789, 2393, 3209,  ...,  788, 2573,  972], dtype=torch.int16),\n",
       " 'model.layers.31.self_attn.q_proj.weight_bias': tensor([ 1.7071e-04,  1.1044e-03,  3.8528e-04,  ..., -7.4744e-05,\n",
       "          1.1997e-03, -2.6207e-03], dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.q_proj.weight_scale': tensor([1.3613, 1.4033, 1.4102,  ..., 1.4277, 1.3545, 1.3447],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.v_proj.centroids.weight': tensor([[-0.0395, -0.0040,  0.0046,  ...,  0.0126,  0.0001, -0.0023]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.v_proj.indices': tensor([[[  247465368, -1305901275, -1483933124,  ..., -1042319261,\n",
       "            1918198125,  1598094146],\n",
       "          [ -949271099, -2027511492,  -675974963,  ...,  -648625989,\n",
       "             992656038,  1306710375],\n",
       "          [ 1391560803,  1970116749,   872865988,  ...,  1394865523,\n",
       "           -1302471727,  1652645125],\n",
       "          ...,\n",
       "          [  825580553,  -901843622,  -659022495,  ...,  -940970657,\n",
       "           -1237471504, -1827687686],\n",
       "          [-1061068043,  -958297149, -1999890710,  ...,  1596350475,\n",
       "            1808370815, -1441755330],\n",
       "          [ -368698169, -1818811898, -1814634173,  ...,  -175444568,\n",
       "            -441104689, -1141913879]]], dtype=torch.int32),\n",
       " 'model.layers.31.self_attn.v_proj.perm': tensor([2789, 2393, 3209,  ...,  788, 2573,  972], dtype=torch.int16),\n",
       " 'model.layers.31.self_attn.v_proj.weight_bias': tensor([ 8.2314e-05,  2.0885e-04, -4.4990e-04,  ...,  3.2008e-05,\n",
       "         -5.8651e-04,  5.5313e-04], dtype=torch.float16),\n",
       " 'model.layers.31.self_attn.v_proj.weight_scale': tensor([1.1836, 1.2217, 1.2959,  ..., 1.1953, 1.2607, 1.2188],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.input_layernorm.weight': tensor([0.2654, 0.2607, 0.2656,  ..., 0.2598, 0.2756, 0.2764],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.mlp.down_proj.centroids.weight': tensor([[-0.0230,  0.0007,  0.0034,  ...,  0.0268, -0.0094, -0.0083]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.mlp.down_proj.indices': tensor([[[ -158225324,   -58398399, -1395521968,  ...,  -389237725,\n",
       "            -357740567, -2079421934],\n",
       "          [ 1867250877,  1647341781,  -793641970,  ...,  1804879608,\n",
       "           -2068267083,  1559137605],\n",
       "          [ 1067813750,  1984492571,   -65558703,  ..., -1449129272,\n",
       "            1716459383,   161230161],\n",
       "          ...,\n",
       "          [-1659836785, -1123772754, -1953389125,  ...,  1541775651,\n",
       "            1877414824,  1458300370],\n",
       "          [-1195547994,   892032091, -1454724898,  ...,   814925560,\n",
       "              61690901,   360455393],\n",
       "          [  154233482,  -692554044,   989688275,  ...,   497231586,\n",
       "             961234442,  1793678272]]], dtype=torch.int32),\n",
       " 'model.layers.4.mlp.down_proj.perm': tensor([1542, 2618, 2982,  ..., 8813, 6095,  391], dtype=torch.int16),\n",
       " 'model.layers.4.mlp.down_proj.weight_bias': tensor([-3.1209e-04, -2.4199e-04, -2.4676e-05,  ...,  2.4366e-04,\n",
       "          1.6689e-04,  4.5538e-05], dtype=torch.float16),\n",
       " 'model.layers.4.mlp.down_proj.weight_scale': tensor([1.1104, 1.1377, 1.1328,  ..., 1.0869, 1.1348, 1.1436],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.mlp.gate_proj.centroids.weight': tensor([[-0.0166, -0.0157,  0.0008,  ...,  0.0210,  0.0217, -0.0094]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.mlp.gate_proj.indices': tensor([[[ 1201965284,  -410220585, -1883053753,  ...,   969796861,\n",
       "            -292353833,  1639601241],\n",
       "          [   44335559,  -680601440, -1142385059,  ...,  1699009565,\n",
       "             275384586,     3687486],\n",
       "          [ 1516539561, -1688269349,  -907228416,  ...,  2017058129,\n",
       "            -972788620,   130807422],\n",
       "          ...,\n",
       "          [ -225541976, -1907133135,    92574094,  ...,   506495554,\n",
       "           -2076022180,   790252999],\n",
       "          [  249062867,   -46170424,   651306678,  ..., -1324141890,\n",
       "            2099925732, -1007072668],\n",
       "          [ 2106054781,  1115195352, -1235605250,  ..., -1699788708,\n",
       "            1942913113,  1466614553]]], dtype=torch.int32),\n",
       " 'model.layers.4.mlp.gate_proj.perm': tensor([3209, 2393, 4071,  ..., 1349,  246, 2683], dtype=torch.int16),\n",
       " 'model.layers.4.mlp.gate_proj.weight_bias': tensor([ 0.0007, -0.0004,  0.0006,  ...,  0.0012,  0.0004, -0.0008],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.mlp.gate_proj.weight_scale': tensor([2.0293, 2.0430, 2.0430,  ..., 2.0371, 2.0215, 2.0449],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.mlp.up_proj.centroids.weight': tensor([[-0.0069,  0.0084, -0.0173,  ..., -0.0120, -0.0057, -0.0034]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.mlp.up_proj.indices': tensor([[[  364384213,  -708113314,   277861820,  ...,  -669893163,\n",
       "            -559457015, -1498142063],\n",
       "          [ 1895823782,   661537635,   -63693870,  ..., -1258805670,\n",
       "            -705766908,  1633571073],\n",
       "          [  154961012,  2077744954,     5562184,  ...,   699310364,\n",
       "           -2104991928,  2096649459],\n",
       "          ...,\n",
       "          [ -508644766,  1270625992, -1243130720,  ...,  1850665118,\n",
       "            -830860291,  1188969956],\n",
       "          [ 2140943805, -1120127434, -1781754345,  ...,  1633216018,\n",
       "             687186357,  -950048860],\n",
       "          [-1010300383,  1353188265,  -122135397,  ...,    39321998,\n",
       "           -1450737525,   102063928]]], dtype=torch.int32),\n",
       " 'model.layers.4.mlp.up_proj.perm': tensor([3209, 2393, 4071,  ..., 1349,  246, 2683], dtype=torch.int16),\n",
       " 'model.layers.4.mlp.up_proj.weight_bias': tensor([-4.5478e-05,  1.5342e-04,  2.2054e-04,  ...,  2.9147e-05,\n",
       "         -1.5140e-05,  1.0192e-05], dtype=torch.float16),\n",
       " 'model.layers.4.mlp.up_proj.weight_scale': tensor([1.8447, 1.8330, 1.8330,  ..., 1.8418, 1.8486, 1.8291],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.post_attention_layernorm.weight': tensor([0.1892, 0.1887, 0.1837,  ..., 0.1899, 0.1906, 0.1886],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.k_proj.centroids.weight': tensor([[ 0.0135,  0.0266, -0.0429,  ...,  0.0330,  0.0054, -0.0147]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.k_proj.indices': tensor([[[ 1343448244,  1832922810,  -736390805,  ...,  -798937027,\n",
       "           -1865214695,  -309001581],\n",
       "          [ -799582826,   560233735,  -948775259,  ..., -2092142993,\n",
       "           -1604782451, -1103292383],\n",
       "          [ -637924744, -1760626551,   782301154,  ...,  1397473768,\n",
       "            -717003609,  -391927825],\n",
       "          ...,\n",
       "          [ 1246390820,  -877526595,  -519626501,  ...,   740692926,\n",
       "             570148985,   184439475],\n",
       "          [  841892058,  -845905033,   691869684,  ..., -1220611736,\n",
       "           -1940771847,   299653591],\n",
       "          [-1637455840,   731757555,   908975128,  ...,  2002533908,\n",
       "            -297193143,  -665500777]]], dtype=torch.int32),\n",
       " 'model.layers.4.self_attn.k_proj.perm': tensor([2393, 1076, 3209,  ...,  216, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.4.self_attn.k_proj.weight_bias': tensor([-0.0011, -0.0022, -0.0008,  ..., -0.0027,  0.0006, -0.0021],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.k_proj.weight_scale': tensor([1.6924, 1.7227, 1.7188,  ..., 1.6758, 1.7168, 1.7148],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.o_proj.centroids.weight': tensor([[-0.0095, -0.0166, -0.0075,  ..., -0.0107, -0.0361,  0.0124]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.o_proj.indices': tensor([[[  110492880,  -814811793,  1652224708,  ...,   486113074,\n",
       "            -981430975,  1513613070],\n",
       "          [-1679856292, -1590496297,  1291060935,  ...,  1068889102,\n",
       "            1970043249,  1530015419],\n",
       "          [  701919314,   797915712,  -279324624,  ...,  1351672119,\n",
       "           -1735717722,  -247791679],\n",
       "          ...,\n",
       "          [-1330081415,  1976802985,  -849574000,  ..., -1198550861,\n",
       "            -788175591,   884231210],\n",
       "          [ 1025485600, -1344042027,  2073293010,  ...,  -459358535,\n",
       "            -994910661,  1054849582],\n",
       "          [ 1865603337,  1368043025,   431955234,  ...,  1030288324,\n",
       "            1300151285,  1520177906]]], dtype=torch.int32),\n",
       " 'model.layers.4.self_attn.o_proj.perm': tensor([3922, 3643,  720,  ...,  744,  702,  757], dtype=torch.int16),\n",
       " 'model.layers.4.self_attn.o_proj.weight_bias': tensor([ 4.0174e-05, -3.1233e-04, -3.8218e-04,  ..., -7.2598e-05,\n",
       "          1.3030e-04,  5.8293e-05], dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.o_proj.weight_scale': tensor([0.8379, 0.8301, 0.8394,  ..., 0.9248, 0.9116, 0.9326],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.q_proj.centroids.weight': tensor([[-0.0072,  0.0020,  0.0482,  ..., -0.0019,  0.0078,  0.0193]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.q_proj.indices': tensor([[[ 1937112318,  -713059797,  2061440564,  ...,  1942006910,\n",
       "            1130346443,  1617943927],\n",
       "          [-1605955282,  -137166088, -1235891568,  ...,  1464524465,\n",
       "            -945144262,   533795423],\n",
       "          [  906803160, -1456902702,  1565713945,  ..., -1444090978,\n",
       "             496568355, -1529353577],\n",
       "          ...,\n",
       "          [-1169275761,  1724214362, -1368628818,  ...,  -964425075,\n",
       "           -1383256847, -1362934757],\n",
       "          [-1990580231,   167677410,  -310040100,  ..., -1371530919,\n",
       "             347403901,  1083849377],\n",
       "          [ -205954496,  1529568255, -1183992047,  ...,  1975255050,\n",
       "           -1322831442, -2094374952]]], dtype=torch.int32),\n",
       " 'model.layers.4.self_attn.q_proj.perm': tensor([2393, 1076, 3209,  ...,  216, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.4.self_attn.q_proj.weight_bias': tensor([0.0012, 0.0011, 0.0004,  ..., 0.0050, 0.0004, 0.0009],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.q_proj.weight_scale': tensor([1.6572, 1.6807, 1.6338,  ..., 1.6631, 1.7080, 1.7158],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.v_proj.centroids.weight': tensor([[-0.0289, -0.0197, -0.0060,  ...,  0.0064, -0.0364,  0.0210]],\n",
       "        dtype=torch.float16),\n",
       " 'model.layers.4.self_attn.v_proj.indices': tensor([[[  307598649,  1335856446,  1223555411,  ...,  2097448143,\n",
       "             298790608,    51926983],\n",
       "          [  845961569,  -335474990,  1121040727,  ...,  1289781048,\n",
       "            1798606507,  1102174560],\n",
       "          [ 1237399355,  -307002842,  1624821572,  ...,   -82836493,\n",
       "            1537471331,   110530399],\n",
       "          ...,\n",
       "          [-2092099829,   417731812,  -385908396,  ..., -1010101757,\n",
       "            -848132094, -1020495350],\n",
       "          [-1634913511,    49627187,  -664757515,  ...,  -826443679,\n",
       "             558252484, -1992577142],\n",
       "          [ 1658499708, -2081099107,  1660813778,  ...,   692292337,\n",
       "             844696314,  -986908479]]], dtype=torch.int32),\n",
       " 'model.layers.4.self_attn.v_proj.perm': tensor([2393, 1076, 3209,  ...,  216, 2533, 1415], dtype=torch.int16),\n",
       " 'model.layers.4.self_attn.v_proj.weight_bias': tensor([-5.1081e-05,  2.4152e-04,  2.3246e-04,  ...,  3.9768e-04,\n",
       "          6.5374e-04,  2.4307e-04], dtype=torch.float16),\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import safetensors\n",
    "\n",
    "c = safetensors.torch.load_file('/home/msst/repo/Quantization/notebooks/vptq_checkpoint/model.safetensors')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_351381/709289361.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  c = torch.load('/home/msst/repo/Quantization/notebooks/vptq_checkpoint/model.safetensors')\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "unpickling stack underflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/msst/repo/Quantization/notebooks/vptq_checkpoint/model.safetensors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/serialization.py:1384\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qenv/lib/python3.10/site-packages/torch/serialization.py:1628\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m   1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1623\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1624\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1625\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1626\u001b[0m     )\n\u001b[0;32m-> 1628\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: unpickling stack underflow"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "c = torch.load('/home/msst/repo/Quantization/notebooks/vptq_checkpoint/model.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8534/2624179838.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  block = torch.load('/mnt/ssd_storage/ml/weights/vc_data/Llama2-7b-hf/per_block_q/model.layers.0')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/msst/repo/Quantization\")\n",
    "import qlib\n",
    "import torch\n",
    "\n",
    "block = torch.load('/mnt/ssd_storage/ml/weights/vc_data/Llama2-7b-hf/per_block_q/model.layers.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaDecoderLayer(\n",
       "  (self_attn): LlamaAttention(\n",
       "    (q_proj): HQLinear()\n",
       "    (k_proj): HQLinear()\n",
       "    (v_proj): HQLinear()\n",
       "    (o_proj): HQLinear()\n",
       "  )\n",
       "  (mlp): LlamaMLP(\n",
       "    (gate_proj): HQLinear()\n",
       "    (up_proj): HQLinear()\n",
       "    (down_proj): HQLinear()\n",
       "    (act_fn): SiLU()\n",
       "  )\n",
       "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VQLinear()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.self_attn.q_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "block.additions = torch.nn.Parameter(torch.randn(10))\n",
    "print(hasattr(block, 'additions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "del block.additions\n",
    "print(hasattr(block, 'additions'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
